{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image Classification on Chromagram and Spectrogram",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nupursjsu/Advanced-Deep-Learning/blob/master/Image_Classification_on_Chromagram_and_Spectrogram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpx6ezO9UrEB"
      },
      "source": [
        "# *Appriciating Indian Music using AI*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##### Chetan | Nupur | Lokesh\n",
        "##### **Advisor : Vishnu Pendyala**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Image Classification Approach\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Image Classification using multiple techniques:\n",
        "\n",
        "1.  Conv neural net\n",
        "2. Transfer Learning\n",
        "    *   Resnet\n",
        "    *   VGG\n",
        "    *   Xception\n",
        "    \n",
        "3. PhonoNet Arch\n",
        "\n",
        "```\n",
        "Training Hyper Parameters\n",
        "\n",
        "Optimizer = Adam\n",
        "\n",
        "loss = categorical_crossentropy\n",
        "\n",
        "metrics = accuracy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA14G4QlVvxd"
      },
      "source": [
        "# Connecting to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8vA0iHYa8it",
        "outputId": "c7736341-53cf-44a8-ba4d-ea75fff8f0cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BrF8IorVyvq"
      },
      "source": [
        "# Insralling required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPy8wgT4aAQT",
        "outputId": "9ac11096-86ec-4574-d05b-e25f237b4eea"
      },
      "source": [
        "# feature extractoring and preprocessing data\n",
        "!apt install ffmpeg\n",
        "!sudo apt-get install libav-tools\n",
        "!sudo apt-get install ffmpeg \n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import csv\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "#Keras\n",
        "import keras\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import pandas\n",
        "from fastai.vision import *\n",
        "from keras.preprocessing import image\n",
        "import urllib.request\n",
        "from keras.preprocessing.image import *\n",
        "import keras\n",
        "from keras.layers import *\n",
        "\n",
        "import random\n",
        "random.seed(1)\n",
        "\n",
        "import pydot\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "\n",
        "\n",
        "from keras.applications import *\n",
        "from keras.utils import *\n",
        "from keras.models import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libav-tools is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  ffmpeg\n",
            "\n",
            "E: Package 'libav-tools' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8p4UYUdA_-"
      },
      "source": [
        "global train_generator,validation_generator,img_height,img_width,batch_size,nb_epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgVF5R7Wdv3z"
      },
      "source": [
        "  img_height=150\n",
        "  img_width=150\n",
        "  batch_size=10\n",
        "  nb_epochs=150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAkExIM3V3f7"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "\n",
        "1.   Sheer Range :\n",
        "\n",
        "  'Shear' means that the image will be distorted along an axis, mostly to create or rectify the perception angles. It's usually used to augment images so that computers can see how humans see things from different angles.\n",
        "2.   Zoom Range \n",
        "3.   Horizontal Flip\n",
        "4.   Vertical Flip\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA9q-T8saJwb"
      },
      "source": [
        "def load_data(path_to_folder,preprocessing_function=None):\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      validation_split=0.1,\n",
        "      preprocessing_function=preprocessing_function) # set validation split\n",
        "  train_data_dir=path_to_folder\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode=\"categorical\",\n",
        "      subset='training') # set as training data\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir, # same directory as training data\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode=\"categorical\",\n",
        "      subset='validation') # set as validation data\n",
        "\n",
        "  return train_generator,validation_generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi0vN4FSXAVq"
      },
      "source": [
        "# Neural Network Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIgcJAK_cYfT"
      },
      "source": [
        "def deep_conv():\n",
        "    # build network topology\n",
        "    classifier = keras.models.Sequential()\n",
        "    classifier.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3),\n",
        "                  activation='relu'))\n",
        "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    classifier.add(Flatten())\n",
        "    classifier.add(Dense(units=128, activation='relu'))\n",
        "    classifier.add(Dense(units=64, activation='relu'))\n",
        "    classifier.add(Dense(units=5, activation='softmax'))\n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgQH8uSmfzM1"
      },
      "source": [
        "def res_net_model():\n",
        "  res_model=ResNet50V2(include_top=False,weights='imagenet',input_shape=(img_height,img_width,3))\n",
        "  for layer in res_model.layers[:140]:\n",
        "    layer.trainable=False\n",
        "  model = Sequential()\n",
        "  model.add(res_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyCl-RqyowkN"
      },
      "source": [
        "def VGG_model():\n",
        "  res_model=VGG19(include_top=False,weights='imagenet',input_shape=(img_height,img_width,3))\n",
        "  for layer in res_model.layers[:140]:\n",
        "    layer.trainable=False\n",
        "  model = Sequential()\n",
        "  model.add(res_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Sgpdjvjduw"
      },
      "source": [
        "def xception_net_model():\n",
        "  res_model=Xception(include_top=False,weights='imagenet',input_shape=(img_height,img_width,3))\n",
        "  for layer in res_model.layers[:140]:\n",
        "    layer.trainable=False\n",
        "  model = Sequential()\n",
        "  model.add(res_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGHVgErLgCS2"
      },
      "source": [
        "def phono_net_arch():\n",
        "  classifier = keras.models.Sequential()\n",
        "  classifier.add(Conv2D(2, (3, 3), input_shape=(img_height, img_width, 3), activation='relu'))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "  classifier.add(Dropout(rate=0.1))\n",
        "\n",
        "\n",
        "  classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size=(1, 3)))\n",
        "  classifier.add(Dropout(rate=0.1))\n",
        "\n",
        "  classifier.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size=(4, 2)))\n",
        "  classifier.add(Dropout(rate=0.1))\n",
        "\n",
        "  classifier.add(Conv2D(150, (3, 3), activation='relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(units=64, activation='relu'))\n",
        "  classifier.add(Dense(units=16, activation='relu'))\n",
        "  classifier.add(Dense(units=5, activation='softmax'))\n",
        "  return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6mpnbb8XHhd"
      },
      "source": [
        "# Training on Chromagram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S-gCWsIgdPJs",
        "outputId": "d65bb826-2512-4900-9abd-0a204651ff40"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Chromagram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder)\n",
        "classifier=deep_conv()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 99 images belonging to 5 classes.\n",
            "Found 22 images belonging to 5 classes.\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 99ms/step - batch: 4.0000 - size: 9.8889 - loss: 419.4485 - accuracy: 0.2135 - val_loss: 46.4733 - val_accuracy: 0.1500\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 22.4389 - accuracy: 0.1348 - val_loss: 1.7299 - val_accuracy: 0.3000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5651 - accuracy: 0.3483 - val_loss: 1.6582 - val_accuracy: 0.1500\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5766 - accuracy: 0.2921 - val_loss: 1.6493 - val_accuracy: 0.1500\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.5551 - accuracy: 0.3889 - val_loss: 1.6120 - val_accuracy: 0.4000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.5582 - accuracy: 0.3409 - val_loss: 1.6242 - val_accuracy: 0.2000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4575 - accuracy: 0.3820 - val_loss: 1.7251 - val_accuracy: 0.2000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5183 - accuracy: 0.3371 - val_loss: 1.6548 - val_accuracy: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.3640 - accuracy: 0.4333 - val_loss: 1.5833 - val_accuracy: 0.2500\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4368 - accuracy: 0.4045 - val_loss: 1.9214 - val_accuracy: 0.1500\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3083 - accuracy: 0.4719 - val_loss: 1.7133 - val_accuracy: 0.2500\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2356 - accuracy: 0.5056 - val_loss: 1.5929 - val_accuracy: 0.2000\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3073 - accuracy: 0.4494 - val_loss: 2.0577 - val_accuracy: 0.1000\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0510 - accuracy: 0.6517 - val_loss: 1.9711 - val_accuracy: 0.2000\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8787 - accuracy: 0.6556 - val_loss: 2.6668 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0980 - accuracy: 0.6517 - val_loss: 1.6745 - val_accuracy: 0.2000\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0106 - accuracy: 0.6292 - val_loss: 2.0191 - val_accuracy: 0.3000\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0611 - accuracy: 0.6742 - val_loss: 2.3128 - val_accuracy: 0.1500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8241 - accuracy: 0.6854 - val_loss: 1.9244 - val_accuracy: 0.2500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 1s 120ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9323 - accuracy: 0.7079 - val_loss: 1.7333 - val_accuracy: 0.3000\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8177 - accuracy: 0.7416 - val_loss: 2.0359 - val_accuracy: 0.2000\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8178 - accuracy: 0.6966 - val_loss: 1.9847 - val_accuracy: 0.0500\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7087 - accuracy: 0.8000 - val_loss: 1.9870 - val_accuracy: 0.3000\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6265 - accuracy: 0.7727 - val_loss: 1.9290 - val_accuracy: 0.2000\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7180 - accuracy: 0.7667 - val_loss: 1.8815 - val_accuracy: 0.2000\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7144 - accuracy: 0.7978 - val_loss: 2.2308 - val_accuracy: 0.2500\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7146 - accuracy: 0.7416 - val_loss: 2.0942 - val_accuracy: 0.2000\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6180 - accuracy: 0.7841 - val_loss: 2.3940 - val_accuracy: 0.3000\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9896 - accuracy: 0.6667 - val_loss: 2.0454 - val_accuracy: 0.0500\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6707 - accuracy: 0.7528 - val_loss: 1.8350 - val_accuracy: 0.2500\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7235 - accuracy: 0.7978 - val_loss: 2.3213 - val_accuracy: 0.1500\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6010 - accuracy: 0.8202 - val_loss: 2.5822 - val_accuracy: 0.3000\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4267 - accuracy: 0.8315 - val_loss: 3.3272 - val_accuracy: 0.4500\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3952 - accuracy: 0.8652 - val_loss: 3.1970 - val_accuracy: 0.2000\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6135 - accuracy: 0.7978 - val_loss: 2.2408 - val_accuracy: 0.1500\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5246 - accuracy: 0.8111 - val_loss: 2.1626 - val_accuracy: 0.3500\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5310 - accuracy: 0.8652 - val_loss: 3.6946 - val_accuracy: 0.1000\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5084 - accuracy: 0.8315 - val_loss: 2.1757 - val_accuracy: 0.3000\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4398 - accuracy: 0.8539 - val_loss: 2.5855 - val_accuracy: 0.2000\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5571 - accuracy: 0.8539 - val_loss: 3.1324 - val_accuracy: 0.1500\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3024 - accuracy: 0.8652 - val_loss: 2.2526 - val_accuracy: 0.2000\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2492 - accuracy: 0.9326 - val_loss: 3.6275 - val_accuracy: 0.2000\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3289 - accuracy: 0.9326 - val_loss: 4.1249 - val_accuracy: 0.2500\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2304 - accuracy: 0.8876 - val_loss: 4.2643 - val_accuracy: 0.1500\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 1s 137ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5052 - accuracy: 0.8333 - val_loss: 3.7900 - val_accuracy: 0.3000\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5076 - accuracy: 0.8090 - val_loss: 2.8524 - val_accuracy: 0.2000\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5754 - accuracy: 0.7753 - val_loss: 3.0773 - val_accuracy: 0.1000\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6115 - accuracy: 0.8090 - val_loss: 2.2838 - val_accuracy: 0.1500\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2366 - accuracy: 0.9101 - val_loss: 3.2955 - val_accuracy: 0.2500\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2710 - accuracy: 0.9101 - val_loss: 3.8222 - val_accuracy: 0.3000\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4227 - accuracy: 0.8652 - val_loss: 3.0538 - val_accuracy: 0.1000\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3975 - accuracy: 0.8989 - val_loss: 2.1100 - val_accuracy: 0.2500\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2304 - accuracy: 0.8989 - val_loss: 4.6029 - val_accuracy: 0.2500\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2906 - accuracy: 0.8989 - val_loss: 2.1439 - val_accuracy: 0.4000\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3092 - accuracy: 0.8652 - val_loss: 2.9058 - val_accuracy: 0.3000\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.4306 - accuracy: 0.8556 - val_loss: 4.5782 - val_accuracy: 0.1500\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2412 - accuracy: 0.9213 - val_loss: 2.6166 - val_accuracy: 0.3500\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3393 - accuracy: 0.8989 - val_loss: 2.7403 - val_accuracy: 0.3000\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1310 - accuracy: 0.9551 - val_loss: 4.5764 - val_accuracy: 0.2000\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 1s 119ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2823 - accuracy: 0.9213 - val_loss: 4.2784 - val_accuracy: 0.1500\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5640 - accuracy: 0.8876 - val_loss: 3.1726 - val_accuracy: 0.3500\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 1s 157ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2569 - accuracy: 0.9551 - val_loss: 3.7549 - val_accuracy: 0.1000\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3572 - accuracy: 0.9101 - val_loss: 2.9141 - val_accuracy: 0.3000\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2278 - accuracy: 0.9326 - val_loss: 3.8868 - val_accuracy: 0.1000\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2845 - accuracy: 0.9222 - val_loss: 3.5843 - val_accuracy: 0.3000\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.3057 - accuracy: 0.8977 - val_loss: 4.8991 - val_accuracy: 0.1500\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1041 - accuracy: 0.9663 - val_loss: 4.8985 - val_accuracy: 0.2000\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1684 - accuracy: 0.9556 - val_loss: 6.3761 - val_accuracy: 0.1500\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2965 - accuracy: 0.9101 - val_loss: 4.6792 - val_accuracy: 0.2000\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3394 - accuracy: 0.8989 - val_loss: 3.7725 - val_accuracy: 0.1500\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2648 - accuracy: 0.8876 - val_loss: 3.3802 - val_accuracy: 0.2000\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4265 - accuracy: 0.8427 - val_loss: 2.8869 - val_accuracy: 0.1500\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2013 - accuracy: 0.9551 - val_loss: 3.8273 - val_accuracy: 0.0500\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2484 - accuracy: 0.9101 - val_loss: 4.2076 - val_accuracy: 0.2000\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3382 - accuracy: 0.8764 - val_loss: 3.0258 - val_accuracy: 0.2000\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2644 - accuracy: 0.9556 - val_loss: 2.5990 - val_accuracy: 0.3000\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1000 - accuracy: 0.9663 - val_loss: 3.6762 - val_accuracy: 0.1500\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1189 - accuracy: 0.9438 - val_loss: 4.5183 - val_accuracy: 0.1000\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1959 - accuracy: 0.9438 - val_loss: 5.9327 - val_accuracy: 0.1500\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1633 - accuracy: 0.9213 - val_loss: 7.7921 - val_accuracy: 0.2000\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3173 - accuracy: 0.9326 - val_loss: 3.8972 - val_accuracy: 0.1500\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 1s 149ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2095 - accuracy: 0.9111 - val_loss: 2.9439 - val_accuracy: 0.2000\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.1905 - accuracy: 0.9432 - val_loss: 4.3680 - val_accuracy: 0.0500\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1441 - accuracy: 0.9326 - val_loss: 6.3233 - val_accuracy: 0.1000\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2606 - accuracy: 0.9438 - val_loss: 4.1479 - val_accuracy: 0.2000\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.3299 - accuracy: 0.9111 - val_loss: 3.9974 - val_accuracy: 0.2000\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1547 - accuracy: 0.9326 - val_loss: 5.6736 - val_accuracy: 0.1000\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1016 - accuracy: 0.9663 - val_loss: 4.9410 - val_accuracy: 0.0500\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2215 - accuracy: 0.9318 - val_loss: 4.3449 - val_accuracy: 0.0500\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1070 - accuracy: 0.9667 - val_loss: 5.7010 - val_accuracy: 0.1000\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1015 - accuracy: 0.9551 - val_loss: 5.0979 - val_accuracy: 0.2000\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1402 - accuracy: 0.9775 - val_loss: 7.4439 - val_accuracy: 0.2000\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1470 - accuracy: 0.9438 - val_loss: 4.5027 - val_accuracy: 0.2000\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2484 - accuracy: 0.9213 - val_loss: 4.8789 - val_accuracy: 0.1000\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2442 - accuracy: 0.9326 - val_loss: 3.8102 - val_accuracy: 0.2500\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2857 - accuracy: 0.9444 - val_loss: 4.1938 - val_accuracy: 0.2000\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2836 - accuracy: 0.9091 - val_loss: 4.9212 - val_accuracy: 0.2000\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0090 - accuracy: 1.0000 - val_loss: 6.5055 - val_accuracy: 0.1000\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.0504 - accuracy: 0.9773 - val_loss: 5.7391 - val_accuracy: 0.2000\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0684 - accuracy: 0.9556 - val_loss: 4.7245 - val_accuracy: 0.2500\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0709 - accuracy: 0.9663 - val_loss: 5.6203 - val_accuracy: 0.1500\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0966 - accuracy: 0.9551 - val_loss: 7.3263 - val_accuracy: 0.2000\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1119 - accuracy: 0.9888 - val_loss: 8.5065 - val_accuracy: 0.1000\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1648 - accuracy: 0.9438 - val_loss: 4.7862 - val_accuracy: 0.1000\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0694 - accuracy: 0.9775 - val_loss: 4.3345 - val_accuracy: 0.3000\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0409 - accuracy: 0.9889 - val_loss: 5.8659 - val_accuracy: 0.1500\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0885 - accuracy: 0.9663 - val_loss: 5.9806 - val_accuracy: 0.1000\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.0773 - accuracy: 0.9773 - val_loss: 4.7599 - val_accuracy: 0.1500\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1271 - accuracy: 0.9556 - val_loss: 4.9079 - val_accuracy: 0.1000\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2014 - accuracy: 0.9551 - val_loss: 3.8262 - val_accuracy: 0.2500\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1898 - accuracy: 0.9326 - val_loss: 5.0871 - val_accuracy: 0.2000\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1433 - accuracy: 0.9551 - val_loss: 6.8081 - val_accuracy: 0.2500\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0503 - accuracy: 0.9888 - val_loss: 6.0105 - val_accuracy: 0.1500\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1849 - accuracy: 0.9778 - val_loss: 3.3535 - val_accuracy: 0.0500\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2394 - accuracy: 0.9432 - val_loss: 2.9133 - val_accuracy: 0.1500\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0306 - accuracy: 1.0000 - val_loss: 4.2238 - val_accuracy: 0.2500\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1279 - accuracy: 0.9888 - val_loss: 4.5376 - val_accuracy: 0.1500\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0770 - accuracy: 0.9663 - val_loss: 3.7659 - val_accuracy: 0.1000\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1031 - accuracy: 0.9775 - val_loss: 6.2146 - val_accuracy: 0.1000\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 1s 120ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1127 - accuracy: 0.9663 - val_loss: 8.0423 - val_accuracy: 0.1500\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1984 - accuracy: 0.9101 - val_loss: 4.2148 - val_accuracy: 0.2500\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 1s 150ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1039 - accuracy: 0.9663 - val_loss: 4.9439 - val_accuracy: 0.1500\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - ETA: 0s - batch: 4.0000 - size: 10.0000 - loss: 0.2117 - accuracy: 0.9333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4dfde0a31e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# callbacks=[tensorboard_callback]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    351\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU4G5d-IalfH",
        "outputId": "ab2e4849-d322-4c1f-94b8-d374042f5d7b"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Chromagram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder=path_to_folder,preprocessing_function=resnet.preprocess_input)\n",
        "classifier=res_net_model()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 99 images belonging to 5 classes.\n",
            "Found 22 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "Epoch 1/150\n",
            "9/9 [==============================] - 6s 200ms/step - batch: 4.0000 - size: 10.0000 - loss: 3.1710 - accuracy: 0.1667 - val_loss: 83.7033 - val_accuracy: 0.1500\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 2.1548 - accuracy: 0.2841 - val_loss: 189.0347 - val_accuracy: 0.1500\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.0743 - accuracy: 0.3778 - val_loss: 642.1295 - val_accuracy: 0.1500\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9106 - accuracy: 0.4045 - val_loss: 973.3035 - val_accuracy: 0.1500\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0209 - accuracy: 0.3708 - val_loss: 212.9694 - val_accuracy: 0.2500\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.7244 - accuracy: 0.4773 - val_loss: 182.6325 - val_accuracy: 0.2000\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5656 - accuracy: 0.4831 - val_loss: 173.4431 - val_accuracy: 0.2500\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.0085 - accuracy: 0.3444 - val_loss: 158.3128 - val_accuracy: 0.2000\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5343 - accuracy: 0.4045 - val_loss: 250.1531 - val_accuracy: 0.3000\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0537 - accuracy: 0.4607 - val_loss: 174.7511 - val_accuracy: 0.1500\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 139ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5431 - accuracy: 0.5281 - val_loss: 67.7890 - val_accuracy: 0.2000\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 165ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4146 - accuracy: 0.4607 - val_loss: 29.2714 - val_accuracy: 0.2000\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 155ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.4458 - accuracy: 0.5222 - val_loss: 29.6196 - val_accuracy: 0.1500\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.3167 - accuracy: 0.4886 - val_loss: 23.1910 - val_accuracy: 0.2000\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.4933 - accuracy: 0.4889 - val_loss: 31.9072 - val_accuracy: 0.3000\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.1950 - accuracy: 0.6136 - val_loss: 13.6778 - val_accuracy: 0.2000\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0141 - accuracy: 0.6333 - val_loss: 14.5463 - val_accuracy: 0.2000\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9297 - accuracy: 0.6854 - val_loss: 14.9903 - val_accuracy: 0.2500\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2216 - accuracy: 0.6180 - val_loss: 28.9775 - val_accuracy: 0.2000\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0975 - accuracy: 0.6404 - val_loss: 30.3741 - val_accuracy: 0.2000\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.6771 - accuracy: 0.6444 - val_loss: 18.4103 - val_accuracy: 0.2500\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 158ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.1599 - accuracy: 0.5909 - val_loss: 71.1967 - val_accuracy: 0.3500\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2740 - accuracy: 0.6292 - val_loss: 34.7255 - val_accuracy: 0.2000\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.8522 - accuracy: 0.7222 - val_loss: 26.1382 - val_accuracy: 0.1500\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4637 - accuracy: 0.6629 - val_loss: 7.0977 - val_accuracy: 0.4500\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9409 - accuracy: 0.7500 - val_loss: 12.3449 - val_accuracy: 0.4500\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9254 - accuracy: 0.6000 - val_loss: 52.5261 - val_accuracy: 0.2500\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 155ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8606 - accuracy: 0.6742 - val_loss: 6.9060 - val_accuracy: 0.4000\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9309 - accuracy: 0.7191 - val_loss: 7.6460 - val_accuracy: 0.3000\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8012 - accuracy: 0.7640 - val_loss: 5.1910 - val_accuracy: 0.3000\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7233 - accuracy: 0.7865 - val_loss: 6.2723 - val_accuracy: 0.1500\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 159ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8186 - accuracy: 0.7528 - val_loss: 9.1406 - val_accuracy: 0.2000\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6913 - accuracy: 0.7865 - val_loss: 4.0468 - val_accuracy: 0.2500\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8746 - accuracy: 0.8000 - val_loss: 5.2693 - val_accuracy: 0.3000\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1405 - accuracy: 0.7191 - val_loss: 3.9196 - val_accuracy: 0.3000\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5183 - accuracy: 0.8090 - val_loss: 4.5676 - val_accuracy: 0.2500\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7136 - accuracy: 0.8090 - val_loss: 2.6545 - val_accuracy: 0.4000\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3982 - accuracy: 0.8315 - val_loss: 2.4634 - val_accuracy: 0.3500\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 139ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6413 - accuracy: 0.7978 - val_loss: 1.7409 - val_accuracy: 0.3500\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6163 - accuracy: 0.8202 - val_loss: 2.8269 - val_accuracy: 0.3000\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4686 - accuracy: 0.8989 - val_loss: 2.5820 - val_accuracy: 0.4500\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 157ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3029 - accuracy: 0.8652 - val_loss: 2.3950 - val_accuracy: 0.4500\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2533 - accuracy: 0.9333 - val_loss: 4.7103 - val_accuracy: 0.2000\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.1919 - accuracy: 0.9205 - val_loss: 5.9356 - val_accuracy: 0.1500\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2105 - accuracy: 0.9222 - val_loss: 4.3788 - val_accuracy: 0.1500\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3139 - accuracy: 0.8876 - val_loss: 3.1860 - val_accuracy: 0.3000\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4764 - accuracy: 0.8652 - val_loss: 3.8718 - val_accuracy: 0.2500\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2965 - accuracy: 0.9101 - val_loss: 3.5002 - val_accuracy: 0.2000\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4320 - accuracy: 0.8427 - val_loss: 4.0715 - val_accuracy: 0.3500\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5549 - accuracy: 0.8539 - val_loss: 9.0456 - val_accuracy: 0.3000\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3643 - accuracy: 0.9326 - val_loss: 9.0476 - val_accuracy: 0.1000\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 165ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7302 - accuracy: 0.7778 - val_loss: 11.0904 - val_accuracy: 0.2500\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.1385 - accuracy: 0.9773 - val_loss: 10.7796 - val_accuracy: 0.2500\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3332 - accuracy: 0.8652 - val_loss: 21.4532 - val_accuracy: 0.2500\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5163 - accuracy: 0.8876 - val_loss: 18.0018 - val_accuracy: 0.3000\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.4899 - accuracy: 0.9111 - val_loss: 5.7208 - val_accuracy: 0.2500\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.5173 - accuracy: 0.8636 - val_loss: 4.5742 - val_accuracy: 0.4000\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2867 - accuracy: 0.9000 - val_loss: 5.1615 - val_accuracy: 0.2000\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3615 - accuracy: 0.9326 - val_loss: 3.2323 - val_accuracy: 0.3000\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4872 - accuracy: 0.8652 - val_loss: 3.3349 - val_accuracy: 0.3500\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3384 - accuracy: 0.8764 - val_loss: 3.5447 - val_accuracy: 0.4500\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 162ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1620 - accuracy: 0.9556 - val_loss: 3.9699 - val_accuracy: 0.2000\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2337 - accuracy: 0.9101 - val_loss: 5.2070 - val_accuracy: 0.3000\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.7210 - accuracy: 0.8750 - val_loss: 8.4948 - val_accuracy: 0.5000\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2664 - accuracy: 0.9111 - val_loss: 9.8108 - val_accuracy: 0.3500\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6078 - accuracy: 0.8864 - val_loss: 10.4603 - val_accuracy: 0.2500\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2214 - accuracy: 0.9333 - val_loss: 19.6096 - val_accuracy: 0.4000\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9819 - accuracy: 0.8652 - val_loss: 7.4896 - val_accuracy: 0.2500\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3206 - accuracy: 0.8427 - val_loss: 6.1286 - val_accuracy: 0.2500\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4478 - accuracy: 0.8876 - val_loss: 3.1830 - val_accuracy: 0.4000\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2595 - accuracy: 0.9000 - val_loss: 9.9959 - val_accuracy: 0.3000\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 158ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.3802 - accuracy: 0.9318 - val_loss: 9.4782 - val_accuracy: 0.2500\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2986 - accuracy: 0.8778 - val_loss: 10.3528 - val_accuracy: 0.2000\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4742 - accuracy: 0.8876 - val_loss: 9.1382 - val_accuracy: 0.2500\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4657 - accuracy: 0.8652 - val_loss: 15.5409 - val_accuracy: 0.1500\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 139ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2811 - accuracy: 0.9432 - val_loss: 13.4671 - val_accuracy: 0.2000\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.4691 - accuracy: 0.9111 - val_loss: 11.0628 - val_accuracy: 0.3500\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8106 - accuracy: 0.8989 - val_loss: 7.7857 - val_accuracy: 0.2500\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7812 - accuracy: 0.9101 - val_loss: 14.4020 - val_accuracy: 0.1500\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2778 - accuracy: 0.9326 - val_loss: 11.5916 - val_accuracy: 0.2000\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4775 - accuracy: 0.8652 - val_loss: 7.8798 - val_accuracy: 0.2500\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 163ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1784 - accuracy: 0.9551 - val_loss: 9.9854 - val_accuracy: 0.2500\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5692 - accuracy: 0.8444 - val_loss: 7.1136 - val_accuracy: 0.2500\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2783 - accuracy: 0.9326 - val_loss: 9.3866 - val_accuracy: 0.2000\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2487 - accuracy: 0.9205 - val_loss: 6.7068 - val_accuracy: 0.1500\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2227 - accuracy: 0.8989 - val_loss: 6.6095 - val_accuracy: 0.1000\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1153 - accuracy: 0.9663 - val_loss: 5.9634 - val_accuracy: 0.3000\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4168 - accuracy: 0.8876 - val_loss: 6.1236 - val_accuracy: 0.2000\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3574 - accuracy: 0.9326 - val_loss: 5.5848 - val_accuracy: 0.2500\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0583 - accuracy: 0.9556 - val_loss: 5.6797 - val_accuracy: 0.2500\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6235 - accuracy: 0.9213 - val_loss: 5.4223 - val_accuracy: 0.1500\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 161ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1312 - accuracy: 0.9778 - val_loss: 8.5680 - val_accuracy: 0.2500\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2805 - accuracy: 0.9432 - val_loss: 9.7939 - val_accuracy: 0.3000\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1398 - accuracy: 0.9551 - val_loss: 13.3859 - val_accuracy: 0.2000\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0981 - accuracy: 0.9667 - val_loss: 14.8552 - val_accuracy: 0.2000\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.3055 - accuracy: 0.9318 - val_loss: 14.4538 - val_accuracy: 0.2000\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5752 - accuracy: 0.9667 - val_loss: 8.3220 - val_accuracy: 0.2500\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2998 - accuracy: 0.9551 - val_loss: 5.1940 - val_accuracy: 0.2500\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2053 - accuracy: 0.9101 - val_loss: 6.4867 - val_accuracy: 0.2500\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5970 - accuracy: 0.8876 - val_loss: 4.6999 - val_accuracy: 0.3500\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3049 - accuracy: 0.8876 - val_loss: 8.5581 - val_accuracy: 0.1000\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 160ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3678 - accuracy: 0.8876 - val_loss: 13.2781 - val_accuracy: 0.3000\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2578 - accuracy: 0.9111 - val_loss: 17.8970 - val_accuracy: 0.2500\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.8074 - accuracy: 0.8864 - val_loss: 28.1688 - val_accuracy: 0.4000\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5171 - accuracy: 0.9213 - val_loss: 7.5970 - val_accuracy: 0.3000\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0563 - accuracy: 0.9778 - val_loss: 5.2166 - val_accuracy: 0.2500\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3782 - accuracy: 0.8876 - val_loss: 4.3774 - val_accuracy: 0.3000\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4053 - accuracy: 0.9438 - val_loss: 4.7847 - val_accuracy: 0.3500\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.5028 - accuracy: 0.9545 - val_loss: 12.3968 - val_accuracy: 0.2500\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0147 - accuracy: 0.9333 - val_loss: 10.1207 - val_accuracy: 0.2500\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4268 - accuracy: 0.8764 - val_loss: 9.8553 - val_accuracy: 0.3000\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 164ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4658 - accuracy: 0.9101 - val_loss: 12.2651 - val_accuracy: 0.2500\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0881 - accuracy: 0.9888 - val_loss: 6.9942 - val_accuracy: 0.3000\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.2894 - accuracy: 0.9444 - val_loss: 6.4386 - val_accuracy: 0.2500\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0998 - accuracy: 0.9663 - val_loss: 5.4502 - val_accuracy: 0.3000\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.1113 - accuracy: 0.9659 - val_loss: 6.8172 - val_accuracy: 0.2500\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0507 - accuracy: 0.9889 - val_loss: 6.3847 - val_accuracy: 0.3000\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2360 - accuracy: 0.9551 - val_loss: 6.4140 - val_accuracy: 0.3000\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0869 - accuracy: 0.9888 - val_loss: 5.6103 - val_accuracy: 0.3500\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0740 - accuracy: 0.9663 - val_loss: 5.4455 - val_accuracy: 0.2500\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 140ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0800 - accuracy: 0.9775 - val_loss: 6.5292 - val_accuracy: 0.2000\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 161ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1079 - accuracy: 0.9551 - val_loss: 4.6360 - val_accuracy: 0.3500\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0331 - accuracy: 0.9778 - val_loss: 6.8660 - val_accuracy: 0.3000\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0266 - accuracy: 0.9775 - val_loss: 5.7495 - val_accuracy: 0.3000\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0346 - accuracy: 0.9888 - val_loss: 5.8813 - val_accuracy: 0.2500\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0716 - accuracy: 0.9663 - val_loss: 4.4772 - val_accuracy: 0.3500\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1462 - accuracy: 0.9775 - val_loss: 4.8427 - val_accuracy: 0.3500\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1099 - accuracy: 0.9775 - val_loss: 6.3756 - val_accuracy: 0.3000\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1849 - accuracy: 0.9551 - val_loss: 6.5413 - val_accuracy: 0.2500\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1692 - accuracy: 0.9326 - val_loss: 7.9401 - val_accuracy: 0.2000\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2490 - accuracy: 0.9326 - val_loss: 7.3222 - val_accuracy: 0.2500\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 155ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0901 - accuracy: 0.9888 - val_loss: 5.0916 - val_accuracy: 0.3000\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.4172 - accuracy: 0.9326 - val_loss: 5.6125 - val_accuracy: 0.3000\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0342 - accuracy: 0.9778 - val_loss: 13.3915 - val_accuracy: 0.2000\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1469 - accuracy: 0.9775 - val_loss: 14.7841 - val_accuracy: 0.2500\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1481 - accuracy: 0.9551 - val_loss: 6.1664 - val_accuracy: 0.4000\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.2044 - accuracy: 0.9659 - val_loss: 8.1597 - val_accuracy: 0.2500\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2232 - accuracy: 0.9663 - val_loss: 4.8328 - val_accuracy: 0.3500\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1769 - accuracy: 0.9438 - val_loss: 5.0574 - val_accuracy: 0.3500\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1848 - accuracy: 0.9667 - val_loss: 5.7025 - val_accuracy: 0.5000\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 149ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.1343 - accuracy: 0.9775 - val_loss: 3.9944 - val_accuracy: 0.3500\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 167ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0144 - accuracy: 0.9888 - val_loss: 5.5628 - val_accuracy: 0.4500\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 155ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.0394 - accuracy: 0.9889 - val_loss: 5.1811 - val_accuracy: 0.3000\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.0204 - accuracy: 0.9886 - val_loss: 4.6707 - val_accuracy: 0.4500\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0482 - accuracy: 0.9775 - val_loss: 5.8123 - val_accuracy: 0.2500\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.1172 - accuracy: 0.9889 - val_loss: 3.8586 - val_accuracy: 0.3500\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2456 - accuracy: 0.9663 - val_loss: 3.1648 - val_accuracy: 0.5500\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0434 - accuracy: 0.9888 - val_loss: 3.9566 - val_accuracy: 0.3500\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0522 - accuracy: 0.9888 - val_loss: 4.2201 - val_accuracy: 0.4000\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.0563 - accuracy: 0.9775 - val_loss: 3.2888 - val_accuracy: 0.3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQJwJq4FhtJL",
        "outputId": "45c62515-45a4-43c3-943e-a00224d3b286"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Chromagram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder=path_to_folder,preprocessing_function=xception.preprocess_input)\n",
        "classifier=xception_net_model()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 99 images belonging to 5 classes.\n",
            "Found 22 images belonging to 5 classes.\n",
            "Epoch 1/150\n",
            "9/9 [==============================] - 5s 234ms/step - batch: 4.0000 - size: 9.8889 - loss: 7.2237 - accuracy: 0.1798 - val_loss: 10.7856 - val_accuracy: 0.1500\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 7.1730 - accuracy: 0.2135 - val_loss: 3.1947 - val_accuracy: 0.3000\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.7633 - accuracy: 0.2360 - val_loss: 2.7534 - val_accuracy: 0.5000\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.2229 - accuracy: 0.2472 - val_loss: 3.8019 - val_accuracy: 0.2000\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 119ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.6287 - accuracy: 0.4270 - val_loss: 3.4194 - val_accuracy: 0.3000\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.8587 - accuracy: 0.3222 - val_loss: 3.6246 - val_accuracy: 0.2500\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 2.4528 - accuracy: 0.3636 - val_loss: 3.2462 - val_accuracy: 0.2500\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.2752 - accuracy: 0.3778 - val_loss: 3.2269 - val_accuracy: 0.2000\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.8101 - accuracy: 0.2921 - val_loss: 2.9147 - val_accuracy: 0.2000\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0063 - accuracy: 0.4157 - val_loss: 2.1700 - val_accuracy: 0.3000\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0406 - accuracy: 0.4719 - val_loss: 3.0978 - val_accuracy: 0.3000\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.3767 - accuracy: 0.4045 - val_loss: 3.2958 - val_accuracy: 0.3500\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.8412 - accuracy: 0.5281 - val_loss: 3.0253 - val_accuracy: 0.3000\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.9537 - accuracy: 0.4889 - val_loss: 4.0913 - val_accuracy: 0.2500\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4607 - accuracy: 0.5730 - val_loss: 2.1334 - val_accuracy: 0.3500\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.4118 - accuracy: 0.5227 - val_loss: 2.9856 - val_accuracy: 0.2500\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.8168 - accuracy: 0.5111 - val_loss: 2.8515 - val_accuracy: 0.3500\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1043 - accuracy: 0.6180 - val_loss: 3.2524 - val_accuracy: 0.4500\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5391 - accuracy: 0.5056 - val_loss: 2.8393 - val_accuracy: 0.4000\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9418 - accuracy: 0.5056 - val_loss: 3.6296 - val_accuracy: 0.2500\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9703 - accuracy: 0.5169 - val_loss: 2.4209 - val_accuracy: 0.2500\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6158 - accuracy: 0.4831 - val_loss: 2.6800 - val_accuracy: 0.3500\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.3950 - accuracy: 0.5222 - val_loss: 2.3014 - val_accuracy: 0.4000\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.4484 - accuracy: 0.6591 - val_loss: 3.1498 - val_accuracy: 0.1500\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6009 - accuracy: 0.5281 - val_loss: 2.2962 - val_accuracy: 0.4500\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.7360 - accuracy: 0.5778 - val_loss: 2.5421 - val_accuracy: 0.2500\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3517 - accuracy: 0.5843 - val_loss: 3.5001 - val_accuracy: 0.3500\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.4049 - accuracy: 0.6250 - val_loss: 3.5542 - val_accuracy: 0.3000\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0954 - accuracy: 0.6222 - val_loss: 2.9969 - val_accuracy: 0.3500\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5207 - accuracy: 0.5618 - val_loss: 2.8749 - val_accuracy: 0.3500\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3897 - accuracy: 0.6067 - val_loss: 3.5099 - val_accuracy: 0.2500\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3574 - accuracy: 0.6404 - val_loss: 4.3362 - val_accuracy: 0.2500\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1287 - accuracy: 0.6292 - val_loss: 3.4163 - val_accuracy: 0.4000\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2782 - accuracy: 0.6742 - val_loss: 2.9316 - val_accuracy: 0.2000\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5813 - accuracy: 0.5281 - val_loss: 2.8588 - val_accuracy: 0.3500\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.1394 - accuracy: 0.6889 - val_loss: 2.9137 - val_accuracy: 0.3000\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1330 - accuracy: 0.5843 - val_loss: 2.9706 - val_accuracy: 0.3500\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2707 - accuracy: 0.5730 - val_loss: 2.7757 - val_accuracy: 0.4500\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2404 - accuracy: 0.5955 - val_loss: 3.2740 - val_accuracy: 0.3000\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1319 - accuracy: 0.6629 - val_loss: 2.4030 - val_accuracy: 0.4000\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1566 - accuracy: 0.6742 - val_loss: 2.6693 - val_accuracy: 0.4000\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 151ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7140 - accuracy: 0.7528 - val_loss: 2.8937 - val_accuracy: 0.2500\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8403 - accuracy: 0.7667 - val_loss: 2.3559 - val_accuracy: 0.3500\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8819 - accuracy: 0.7640 - val_loss: 2.8381 - val_accuracy: 0.5000\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6651 - accuracy: 0.7528 - val_loss: 3.0166 - val_accuracy: 0.4000\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1503 - accuracy: 0.6180 - val_loss: 2.7627 - val_accuracy: 0.3000\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5418 - accuracy: 0.5955 - val_loss: 4.2288 - val_accuracy: 0.3000\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3370 - accuracy: 0.6517 - val_loss: 2.9815 - val_accuracy: 0.5000\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0314 - accuracy: 0.6517 - val_loss: 2.4663 - val_accuracy: 0.3500\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8293 - accuracy: 0.7303 - val_loss: 4.4626 - val_accuracy: 0.2000\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9224 - accuracy: 0.7444 - val_loss: 3.1174 - val_accuracy: 0.3500\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.8285 - accuracy: 0.7386 - val_loss: 2.5213 - val_accuracy: 0.2500\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7781 - accuracy: 0.7416 - val_loss: 2.7115 - val_accuracy: 0.3500\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.6049 - accuracy: 0.8111 - val_loss: 3.8452 - val_accuracy: 0.2500\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.7795 - accuracy: 0.7273 - val_loss: 2.6377 - val_accuracy: 0.3500\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7884 - accuracy: 0.7333 - val_loss: 3.2932 - val_accuracy: 0.2000\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9640 - accuracy: 0.6742 - val_loss: 3.5224 - val_accuracy: 0.3000\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8650 - accuracy: 0.7079 - val_loss: 2.9843 - val_accuracy: 0.2500\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9805 - accuracy: 0.7191 - val_loss: 3.2325 - val_accuracy: 0.4500\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8058 - accuracy: 0.6629 - val_loss: 3.1504 - val_accuracy: 0.3500\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8807 - accuracy: 0.7753 - val_loss: 3.4545 - val_accuracy: 0.2500\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.6754 - accuracy: 0.6444 - val_loss: 3.1714 - val_accuracy: 0.3000\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.3360 - accuracy: 0.6250 - val_loss: 5.9926 - val_accuracy: 0.2500\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8939 - accuracy: 0.7111 - val_loss: 3.8489 - val_accuracy: 0.3500\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.3740 - accuracy: 0.6364 - val_loss: 2.6229 - val_accuracy: 0.5500\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0195 - accuracy: 0.7222 - val_loss: 3.2836 - val_accuracy: 0.4000\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0620 - accuracy: 0.7191 - val_loss: 4.0399 - val_accuracy: 0.1500\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.2294 - accuracy: 0.7159 - val_loss: 4.2828 - val_accuracy: 0.2500\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0572 - accuracy: 0.7000 - val_loss: 3.2321 - val_accuracy: 0.3500\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2314 - accuracy: 0.7303 - val_loss: 3.9440 - val_accuracy: 0.4500\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4419 - accuracy: 0.5506 - val_loss: 5.3785 - val_accuracy: 0.3500\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9495 - accuracy: 0.7889 - val_loss: 4.0228 - val_accuracy: 0.4000\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9131 - accuracy: 0.6932 - val_loss: 3.8248 - val_accuracy: 0.5000\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2205 - accuracy: 0.6180 - val_loss: 3.5812 - val_accuracy: 0.4000\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1578 - accuracy: 0.6629 - val_loss: 5.3266 - val_accuracy: 0.3500\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.6962 - accuracy: 0.6222 - val_loss: 3.5943 - val_accuracy: 0.2500\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1135 - accuracy: 0.7191 - val_loss: 5.0015 - val_accuracy: 0.4500\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.8213 - accuracy: 0.7045 - val_loss: 4.5315 - val_accuracy: 0.2000\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.1660 - accuracy: 0.7333 - val_loss: 4.1414 - val_accuracy: 0.4000\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5545 - accuracy: 0.8202 - val_loss: 4.8473 - val_accuracy: 0.3500\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6496 - accuracy: 0.6292 - val_loss: 5.4167 - val_accuracy: 0.1500\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2484 - accuracy: 0.6966 - val_loss: 3.6700 - val_accuracy: 0.3500\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 144ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0909 - accuracy: 0.6854 - val_loss: 3.3074 - val_accuracy: 0.3000\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6432 - accuracy: 0.7753 - val_loss: 5.6542 - val_accuracy: 0.2500\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5846 - accuracy: 0.8222 - val_loss: 4.8665 - val_accuracy: 0.2000\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5187 - accuracy: 0.8652 - val_loss: 2.9527 - val_accuracy: 0.3000\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9477 - accuracy: 0.7191 - val_loss: 2.9265 - val_accuracy: 0.5500\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7986 - accuracy: 0.7303 - val_loss: 4.3656 - val_accuracy: 0.2000\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9312 - accuracy: 0.7528 - val_loss: 4.0465 - val_accuracy: 0.5000\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6287 - accuracy: 0.7865 - val_loss: 3.5096 - val_accuracy: 0.4500\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0288 - accuracy: 0.7416 - val_loss: 4.5153 - val_accuracy: 0.3500\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9032 - accuracy: 0.7889 - val_loss: 4.1890 - val_accuracy: 0.3500\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.3832 - accuracy: 0.6477 - val_loss: 5.2572 - val_accuracy: 0.2500\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 141ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3927 - accuracy: 0.6629 - val_loss: 6.7885 - val_accuracy: 0.3500\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9162 - accuracy: 0.5955 - val_loss: 4.1257 - val_accuracy: 0.2500\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.7251 - accuracy: 0.7444 - val_loss: 4.4891 - val_accuracy: 0.3000\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3026 - accuracy: 0.7191 - val_loss: 3.2069 - val_accuracy: 0.3000\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6647 - accuracy: 0.7955 - val_loss: 3.3691 - val_accuracy: 0.4000\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7383 - accuracy: 0.7667 - val_loss: 4.2282 - val_accuracy: 0.2500\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7484 - accuracy: 0.7528 - val_loss: 3.9111 - val_accuracy: 0.4500\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 128ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5645 - accuracy: 0.8315 - val_loss: 3.8943 - val_accuracy: 0.3500\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7538 - accuracy: 0.8202 - val_loss: 3.9470 - val_accuracy: 0.3500\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8501 - accuracy: 0.7640 - val_loss: 3.3039 - val_accuracy: 0.3000\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7476 - accuracy: 0.7978 - val_loss: 2.0375 - val_accuracy: 0.4500\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9790 - accuracy: 0.7222 - val_loss: 3.7619 - val_accuracy: 0.5000\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6205 - accuracy: 0.7727 - val_loss: 4.3779 - val_accuracy: 0.3500\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2266 - accuracy: 0.6854 - val_loss: 4.1843 - val_accuracy: 0.3000\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7861 - accuracy: 0.7889 - val_loss: 3.6253 - val_accuracy: 0.3500\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8023 - accuracy: 0.7753 - val_loss: 3.2726 - val_accuracy: 0.4500\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6599 - accuracy: 0.8652 - val_loss: 3.3929 - val_accuracy: 0.4500\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5984 - accuracy: 0.7978 - val_loss: 3.9730 - val_accuracy: 0.4500\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8067 - accuracy: 0.7753 - val_loss: 3.8658 - val_accuracy: 0.3000\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0020 - accuracy: 0.7556 - val_loss: 2.7596 - val_accuracy: 0.4000\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9870 - accuracy: 0.7841 - val_loss: 2.7882 - val_accuracy: 0.5000\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8922 - accuracy: 0.7444 - val_loss: 5.0559 - val_accuracy: 0.2500\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7709 - accuracy: 0.7528 - val_loss: 3.5079 - val_accuracy: 0.3500\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6789 - accuracy: 0.8315 - val_loss: 2.7688 - val_accuracy: 0.4500\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3997 - accuracy: 0.8652 - val_loss: 3.2387 - val_accuracy: 0.4000\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.2344 - accuracy: 0.8989 - val_loss: 3.3826 - val_accuracy: 0.4500\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5404 - accuracy: 0.8539 - val_loss: 3.5578 - val_accuracy: 0.4000\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7591 - accuracy: 0.7978 - val_loss: 4.2790 - val_accuracy: 0.4000\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 164ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7672 - accuracy: 0.8111 - val_loss: 2.5337 - val_accuracy: 0.5000\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7235 - accuracy: 0.7865 - val_loss: 3.7730 - val_accuracy: 0.4500\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9156 - accuracy: 0.7955 - val_loss: 2.2824 - val_accuracy: 0.3500\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8076 - accuracy: 0.8111 - val_loss: 4.2154 - val_accuracy: 0.3500\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6767 - accuracy: 0.8068 - val_loss: 3.3720 - val_accuracy: 0.4500\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8373 - accuracy: 0.7528 - val_loss: 2.9915 - val_accuracy: 0.5000\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7662 - accuracy: 0.7556 - val_loss: 4.1729 - val_accuracy: 0.2500\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7370 - accuracy: 0.7978 - val_loss: 5.6737 - val_accuracy: 0.3000\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9560 - accuracy: 0.7528 - val_loss: 4.1776 - val_accuracy: 0.3000\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0950 - accuracy: 0.6854 - val_loss: 6.2941 - val_accuracy: 0.3500\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5367 - accuracy: 0.6742 - val_loss: 5.4304 - val_accuracy: 0.2500\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9104 - accuracy: 0.7640 - val_loss: 5.8607 - val_accuracy: 0.2500\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2418 - accuracy: 0.7416 - val_loss: 5.4567 - val_accuracy: 0.2500\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3228 - accuracy: 0.6517 - val_loss: 4.1202 - val_accuracy: 0.2500\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.9903 - accuracy: 0.7978 - val_loss: 4.5284 - val_accuracy: 0.3500\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0947 - accuracy: 0.7000 - val_loss: 6.0170 - val_accuracy: 0.3500\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6729 - accuracy: 0.8539 - val_loss: 7.7088 - val_accuracy: 0.3000\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1215 - accuracy: 0.7303 - val_loss: 2.7783 - val_accuracy: 0.4000\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0017 - accuracy: 0.7865 - val_loss: 4.0869 - val_accuracy: 0.4000\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5546 - accuracy: 0.8539 - val_loss: 2.7269 - val_accuracy: 0.5000\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7046 - accuracy: 0.7978 - val_loss: 6.0823 - val_accuracy: 0.2000\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.3562 - accuracy: 0.8667 - val_loss: 3.5574 - val_accuracy: 0.2500\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.5190 - accuracy: 0.8523 - val_loss: 5.1473 - val_accuracy: 0.2000\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5838 - accuracy: 0.8444 - val_loss: 4.3544 - val_accuracy: 0.5000\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7537 - accuracy: 0.7640 - val_loss: 3.4328 - val_accuracy: 0.5000\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.3183 - accuracy: 0.9101 - val_loss: 3.7568 - val_accuracy: 0.3500\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5568 - accuracy: 0.8539 - val_loss: 5.2584 - val_accuracy: 0.2500\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8576 - accuracy: 0.7640 - val_loss: 3.7877 - val_accuracy: 0.5000\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2751 - accuracy: 0.7303 - val_loss: 6.7171 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfNBvcsukIAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71290ef0-d0be-4766-ee04-5623dc2cf1b0"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Chromagram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder=path_to_folder,preprocessing_function=vgg19.preprocess_input)\n",
        "classifier=VGG_model()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 99 images belonging to 5 classes.\n",
            "Found 22 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "Epoch 1/150\n",
            "9/9 [==============================] - 6s 301ms/step - batch: 4.0000 - size: 9.8889 - loss: 15.5673 - accuracy: 0.2360 - val_loss: 15.1902 - val_accuracy: 0.3500\n",
            "Epoch 2/150\n",
            "9/9 [==============================] - 1s 162ms/step - batch: 4.0000 - size: 9.8889 - loss: 11.7201 - accuracy: 0.1798 - val_loss: 11.8388 - val_accuracy: 0.3500\n",
            "Epoch 3/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 10.2491 - accuracy: 0.2921 - val_loss: 7.9867 - val_accuracy: 0.2500\n",
            "Epoch 4/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 10.0000 - loss: 6.6211 - accuracy: 0.3667 - val_loss: 9.5933 - val_accuracy: 0.2500\n",
            "Epoch 5/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.5690 - accuracy: 0.4382 - val_loss: 8.4198 - val_accuracy: 0.3000\n",
            "Epoch 6/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 3.8539 - accuracy: 0.5000 - val_loss: 6.5888 - val_accuracy: 0.1000\n",
            "Epoch 7/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 5.1310 - accuracy: 0.4333 - val_loss: 9.5478 - val_accuracy: 0.3500\n",
            "Epoch 8/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.7354 - accuracy: 0.3596 - val_loss: 8.7624 - val_accuracy: 0.2500\n",
            "Epoch 9/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 5.4934 - accuracy: 0.4045 - val_loss: 10.0547 - val_accuracy: 0.2500\n",
            "Epoch 10/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 5.5274 - accuracy: 0.4270 - val_loss: 6.9842 - val_accuracy: 0.2500\n",
            "Epoch 11/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.8107 - accuracy: 0.4607 - val_loss: 9.1087 - val_accuracy: 0.4000\n",
            "Epoch 12/150\n",
            "9/9 [==============================] - 1s 156ms/step - batch: 4.0000 - size: 10.0000 - loss: 4.6922 - accuracy: 0.5000 - val_loss: 7.6907 - val_accuracy: 0.2500\n",
            "Epoch 13/150\n",
            "9/9 [==============================] - 1s 143ms/step - batch: 4.0000 - size: 9.7778 - loss: 3.4488 - accuracy: 0.5909 - val_loss: 8.3158 - val_accuracy: 0.3500\n",
            "Epoch 14/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.7444 - accuracy: 0.5889 - val_loss: 11.3927 - val_accuracy: 0.2500\n",
            "Epoch 15/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 3.7287 - accuracy: 0.6023 - val_loss: 9.8015 - val_accuracy: 0.2000\n",
            "Epoch 16/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.3550 - accuracy: 0.5955 - val_loss: 6.1523 - val_accuracy: 0.4500\n",
            "Epoch 17/150\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 10.0000 - loss: 3.2963 - accuracy: 0.5778 - val_loss: 10.0536 - val_accuracy: 0.2500\n",
            "Epoch 18/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.3282 - accuracy: 0.4157 - val_loss: 7.3162 - val_accuracy: 0.3000\n",
            "Epoch 19/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.1927 - accuracy: 0.5056 - val_loss: 7.7178 - val_accuracy: 0.3000\n",
            "Epoch 20/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.3234 - accuracy: 0.4944 - val_loss: 11.3330 - val_accuracy: 0.1000\n",
            "Epoch 21/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.6147 - accuracy: 0.6067 - val_loss: 11.7590 - val_accuracy: 0.2000\n",
            "Epoch 22/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 5.2641 - accuracy: 0.5843 - val_loss: 8.3964 - val_accuracy: 0.3000\n",
            "Epoch 23/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.3684 - accuracy: 0.5506 - val_loss: 12.2374 - val_accuracy: 0.3000\n",
            "Epoch 24/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 3.0553 - accuracy: 0.6556 - val_loss: 12.6094 - val_accuracy: 0.2500\n",
            "Epoch 25/150\n",
            "9/9 [==============================] - 1s 121ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.2352 - accuracy: 0.5955 - val_loss: 12.2617 - val_accuracy: 0.2500\n",
            "Epoch 26/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.1727 - accuracy: 0.6404 - val_loss: 11.5247 - val_accuracy: 0.3000\n",
            "Epoch 27/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.8016 - accuracy: 0.6180 - val_loss: 10.5279 - val_accuracy: 0.2500\n",
            "Epoch 28/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.8751 - accuracy: 0.6180 - val_loss: 10.1460 - val_accuracy: 0.3500\n",
            "Epoch 29/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 5.2283 - accuracy: 0.5843 - val_loss: 10.7142 - val_accuracy: 0.4000\n",
            "Epoch 30/150\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.3176 - accuracy: 0.6292 - val_loss: 8.6760 - val_accuracy: 0.4000\n",
            "Epoch 31/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.3766 - accuracy: 0.6404 - val_loss: 6.0933 - val_accuracy: 0.5000\n",
            "Epoch 32/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.2493 - accuracy: 0.6404 - val_loss: 6.4698 - val_accuracy: 0.4500\n",
            "Epoch 33/150\n",
            "9/9 [==============================] - 1s 145ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.6388 - accuracy: 0.6742 - val_loss: 11.7955 - val_accuracy: 0.4500\n",
            "Epoch 34/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.0990 - accuracy: 0.6556 - val_loss: 5.0781 - val_accuracy: 0.5500\n",
            "Epoch 35/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5515 - accuracy: 0.7978 - val_loss: 7.4749 - val_accuracy: 0.4000\n",
            "Epoch 36/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.1290 - accuracy: 0.7528 - val_loss: 6.3830 - val_accuracy: 0.6500\n",
            "Epoch 37/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 2.1660 - accuracy: 0.6818 - val_loss: 7.4947 - val_accuracy: 0.4500\n",
            "Epoch 38/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0711 - accuracy: 0.7416 - val_loss: 9.8069 - val_accuracy: 0.2500\n",
            "Epoch 39/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.7227 - accuracy: 0.7000 - val_loss: 15.8118 - val_accuracy: 0.3500\n",
            "Epoch 40/150\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.7009 - accuracy: 0.6742 - val_loss: 8.4290 - val_accuracy: 0.4500\n",
            "Epoch 41/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.0455 - accuracy: 0.6180 - val_loss: 9.6109 - val_accuracy: 0.4000\n",
            "Epoch 42/150\n",
            "9/9 [==============================] - 1s 156ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6842 - accuracy: 0.7528 - val_loss: 6.7783 - val_accuracy: 0.3500\n",
            "Epoch 43/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.8316 - accuracy: 0.7333 - val_loss: 11.1267 - val_accuracy: 0.2000\n",
            "Epoch 44/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.4661 - accuracy: 0.7416 - val_loss: 12.2225 - val_accuracy: 0.4000\n",
            "Epoch 45/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.7108 - accuracy: 0.7079 - val_loss: 9.2162 - val_accuracy: 0.4000\n",
            "Epoch 46/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 3.0436 - accuracy: 0.7273 - val_loss: 13.1051 - val_accuracy: 0.3500\n",
            "Epoch 47/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.5324 - accuracy: 0.7640 - val_loss: 11.0820 - val_accuracy: 0.2500\n",
            "Epoch 48/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.6897 - accuracy: 0.7079 - val_loss: 16.4160 - val_accuracy: 0.3000\n",
            "Epoch 49/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.2457 - accuracy: 0.7111 - val_loss: 7.2352 - val_accuracy: 0.3500\n",
            "Epoch 50/150\n",
            "9/9 [==============================] - 1s 124ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3427 - accuracy: 0.7753 - val_loss: 10.7447 - val_accuracy: 0.4000\n",
            "Epoch 51/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9207 - accuracy: 0.7416 - val_loss: 9.6051 - val_accuracy: 0.4000\n",
            "Epoch 52/150\n",
            "9/9 [==============================] - 1s 159ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2541 - accuracy: 0.7528 - val_loss: 11.5752 - val_accuracy: 0.2500\n",
            "Epoch 53/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0570 - accuracy: 0.8667 - val_loss: 8.4603 - val_accuracy: 0.4500\n",
            "Epoch 54/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.7095 - accuracy: 0.8523 - val_loss: 10.6645 - val_accuracy: 0.3500\n",
            "Epoch 55/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.2077 - accuracy: 0.8111 - val_loss: 11.2916 - val_accuracy: 0.3500\n",
            "Epoch 56/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3931 - accuracy: 0.7753 - val_loss: 11.8153 - val_accuracy: 0.3500\n",
            "Epoch 57/150\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.0646 - accuracy: 0.7955 - val_loss: 10.3776 - val_accuracy: 0.3000\n",
            "Epoch 58/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0890 - accuracy: 0.8222 - val_loss: 11.4888 - val_accuracy: 0.3000\n",
            "Epoch 59/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0762 - accuracy: 0.7865 - val_loss: 14.2856 - val_accuracy: 0.3000\n",
            "Epoch 60/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.5896 - accuracy: 0.7416 - val_loss: 11.0777 - val_accuracy: 0.3000\n",
            "Epoch 61/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2548 - accuracy: 0.8427 - val_loss: 9.3267 - val_accuracy: 0.3500\n",
            "Epoch 62/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1747 - accuracy: 0.7865 - val_loss: 8.3212 - val_accuracy: 0.3500\n",
            "Epoch 63/150\n",
            "9/9 [==============================] - 1s 142ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0461 - accuracy: 0.8315 - val_loss: 8.4700 - val_accuracy: 0.4000\n",
            "Epoch 64/150\n",
            "9/9 [==============================] - 1s 136ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9674 - accuracy: 0.8333 - val_loss: 12.9581 - val_accuracy: 0.1500\n",
            "Epoch 65/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.4674 - accuracy: 0.7727 - val_loss: 8.0424 - val_accuracy: 0.5000\n",
            "Epoch 66/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.1125 - accuracy: 0.8111 - val_loss: 8.8787 - val_accuracy: 0.4000\n",
            "Epoch 67/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3538 - accuracy: 0.7978 - val_loss: 10.4192 - val_accuracy: 0.3500\n",
            "Epoch 68/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.7028 - accuracy: 0.7528 - val_loss: 11.0254 - val_accuracy: 0.2500\n",
            "Epoch 69/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1040 - accuracy: 0.7865 - val_loss: 13.2768 - val_accuracy: 0.4000\n",
            "Epoch 70/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1810 - accuracy: 0.8315 - val_loss: 8.9475 - val_accuracy: 0.3000\n",
            "Epoch 71/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3585 - accuracy: 0.8202 - val_loss: 7.9243 - val_accuracy: 0.5000\n",
            "Epoch 72/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5610 - accuracy: 0.7865 - val_loss: 7.4981 - val_accuracy: 0.5500\n",
            "Epoch 73/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.9438 - accuracy: 0.7222 - val_loss: 12.3548 - val_accuracy: 0.3500\n",
            "Epoch 74/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.8161 - accuracy: 0.7416 - val_loss: 12.0142 - val_accuracy: 0.3000\n",
            "Epoch 75/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6113 - accuracy: 0.7978 - val_loss: 13.8277 - val_accuracy: 0.3000\n",
            "Epoch 76/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.5758 - accuracy: 0.7841 - val_loss: 12.8863 - val_accuracy: 0.2500\n",
            "Epoch 77/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.8460 - accuracy: 0.7978 - val_loss: 11.2238 - val_accuracy: 0.4000\n",
            "Epoch 78/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8964 - accuracy: 0.7753 - val_loss: 10.7845 - val_accuracy: 0.4000\n",
            "Epoch 79/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.0785 - accuracy: 0.7889 - val_loss: 9.4088 - val_accuracy: 0.3500\n",
            "Epoch 80/150\n",
            "9/9 [==============================] - 1s 123ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2997 - accuracy: 0.8315 - val_loss: 10.1209 - val_accuracy: 0.3500\n",
            "Epoch 81/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2596 - accuracy: 0.8090 - val_loss: 11.1610 - val_accuracy: 0.3500\n",
            "Epoch 82/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0059 - accuracy: 0.7079 - val_loss: 19.9179 - val_accuracy: 0.2500\n",
            "Epoch 83/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 10.0000 - loss: 3.1238 - accuracy: 0.7444 - val_loss: 10.9362 - val_accuracy: 0.4000\n",
            "Epoch 84/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.8757 - accuracy: 0.7727 - val_loss: 9.1603 - val_accuracy: 0.4000\n",
            "Epoch 85/150\n",
            "9/9 [==============================] - 1s 138ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.1076 - accuracy: 0.8556 - val_loss: 10.0103 - val_accuracy: 0.4500\n",
            "Epoch 86/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.7896 - accuracy: 0.8295 - val_loss: 10.7113 - val_accuracy: 0.4000\n",
            "Epoch 87/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.6326 - accuracy: 0.8889 - val_loss: 13.7104 - val_accuracy: 0.3000\n",
            "Epoch 88/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9146 - accuracy: 0.8182 - val_loss: 8.3212 - val_accuracy: 0.4000\n",
            "Epoch 89/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0700 - accuracy: 0.8000 - val_loss: 12.7474 - val_accuracy: 0.2500\n",
            "Epoch 90/150\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1801 - accuracy: 0.8090 - val_loss: 7.7273 - val_accuracy: 0.3500\n",
            "Epoch 91/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2812 - accuracy: 0.7865 - val_loss: 14.9960 - val_accuracy: 0.5000\n",
            "Epoch 92/150\n",
            "9/9 [==============================] - 1s 151ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.0164 - accuracy: 0.7416 - val_loss: 10.3152 - val_accuracy: 0.3000\n",
            "Epoch 93/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.6532 - accuracy: 0.8778 - val_loss: 15.2791 - val_accuracy: 0.3500\n",
            "Epoch 94/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.8770 - accuracy: 0.8750 - val_loss: 14.0112 - val_accuracy: 0.3500\n",
            "Epoch 95/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.9914 - accuracy: 0.8778 - val_loss: 13.8797 - val_accuracy: 0.3500\n",
            "Epoch 96/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5905 - accuracy: 0.7865 - val_loss: 10.3202 - val_accuracy: 0.3500\n",
            "Epoch 97/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3734 - accuracy: 0.8427 - val_loss: 13.1145 - val_accuracy: 0.3500\n",
            "Epoch 98/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.9570 - accuracy: 0.8539 - val_loss: 8.7203 - val_accuracy: 0.4500\n",
            "Epoch 99/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1067 - accuracy: 0.8427 - val_loss: 10.8086 - val_accuracy: 0.3500\n",
            "Epoch 100/150\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6363 - accuracy: 0.8652 - val_loss: 17.2877 - val_accuracy: 0.2500\n",
            "Epoch 101/150\n",
            "9/9 [==============================] - 1s 130ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.4698 - accuracy: 0.7303 - val_loss: 16.1947 - val_accuracy: 0.3000\n",
            "Epoch 102/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.1955 - accuracy: 0.6966 - val_loss: 14.5361 - val_accuracy: 0.3500\n",
            "Epoch 103/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.8889 - loss: 3.0540 - accuracy: 0.6854 - val_loss: 18.0618 - val_accuracy: 0.3500\n",
            "Epoch 104/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 4.4827 - accuracy: 0.6854 - val_loss: 16.9744 - val_accuracy: 0.3000\n",
            "Epoch 105/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.4349 - accuracy: 0.7778 - val_loss: 14.5388 - val_accuracy: 0.3500\n",
            "Epoch 106/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0793 - accuracy: 0.8427 - val_loss: 9.4661 - val_accuracy: 0.3000\n",
            "Epoch 107/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1730 - accuracy: 0.8090 - val_loss: 14.0491 - val_accuracy: 0.3000\n",
            "Epoch 108/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4099 - accuracy: 0.8427 - val_loss: 12.1384 - val_accuracy: 0.3500\n",
            "Epoch 109/150\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.8100 - accuracy: 0.7978 - val_loss: 17.4600 - val_accuracy: 0.1500\n",
            "Epoch 110/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6382 - accuracy: 0.8090 - val_loss: 14.9657 - val_accuracy: 0.4500\n",
            "Epoch 111/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3447 - accuracy: 0.8090 - val_loss: 14.5428 - val_accuracy: 0.4500\n",
            "Epoch 112/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.1177 - accuracy: 0.7978 - val_loss: 16.4373 - val_accuracy: 0.2500\n",
            "Epoch 113/150\n",
            "9/9 [==============================] - 1s 146ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.5879 - accuracy: 0.7753 - val_loss: 12.4018 - val_accuracy: 0.4000\n",
            "Epoch 114/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 2.4249 - accuracy: 0.7303 - val_loss: 11.6168 - val_accuracy: 0.3500\n",
            "Epoch 115/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.7942 - accuracy: 0.8889 - val_loss: 17.5475 - val_accuracy: 0.1500\n",
            "Epoch 116/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.9300 - accuracy: 0.9318 - val_loss: 10.5492 - val_accuracy: 0.4000\n",
            "Epoch 117/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.6998 - accuracy: 0.8090 - val_loss: 13.8657 - val_accuracy: 0.2500\n",
            "Epoch 118/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8999 - accuracy: 0.8778 - val_loss: 13.2132 - val_accuracy: 0.3000\n",
            "Epoch 119/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0607 - accuracy: 0.8876 - val_loss: 11.5856 - val_accuracy: 0.4000\n",
            "Epoch 120/150\n",
            "9/9 [==============================] - 1s 127ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8108 - accuracy: 0.9213 - val_loss: 14.5094 - val_accuracy: 0.3000\n",
            "Epoch 121/150\n",
            "9/9 [==============================] - 1s 129ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0329 - accuracy: 0.8315 - val_loss: 13.6692 - val_accuracy: 0.3000\n",
            "Epoch 122/150\n",
            "9/9 [==============================] - 1s 154ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0290 - accuracy: 0.8764 - val_loss: 11.4772 - val_accuracy: 0.3000\n",
            "Epoch 123/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0445 - accuracy: 0.8667 - val_loss: 15.8929 - val_accuracy: 0.4500\n",
            "Epoch 124/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.4442 - accuracy: 0.9432 - val_loss: 10.2053 - val_accuracy: 0.4500\n",
            "Epoch 125/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0479 - accuracy: 0.8764 - val_loss: 12.9895 - val_accuracy: 0.3500\n",
            "Epoch 126/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.2038 - accuracy: 0.8202 - val_loss: 11.8490 - val_accuracy: 0.3000\n",
            "Epoch 127/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.5998 - accuracy: 0.8444 - val_loss: 25.9006 - val_accuracy: 0.2000\n",
            "Epoch 128/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.7778 - loss: 2.8171 - accuracy: 0.7614 - val_loss: 19.1247 - val_accuracy: 0.2500\n",
            "Epoch 129/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 2.2036 - accuracy: 0.7556 - val_loss: 11.1160 - val_accuracy: 0.3000\n",
            "Epoch 130/150\n",
            "9/9 [==============================] - 1s 122ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.4172 - accuracy: 0.8652 - val_loss: 11.5799 - val_accuracy: 0.4000\n",
            "Epoch 131/150\n",
            "9/9 [==============================] - 1s 135ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.7200 - accuracy: 0.8989 - val_loss: 15.3310 - val_accuracy: 0.3500\n",
            "Epoch 132/150\n",
            "9/9 [==============================] - 1s 152ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5378 - accuracy: 0.8652 - val_loss: 11.3276 - val_accuracy: 0.4500\n",
            "Epoch 133/150\n",
            "9/9 [==============================] - 1s 147ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.6073 - accuracy: 0.8876 - val_loss: 11.8746 - val_accuracy: 0.3500\n",
            "Epoch 134/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.8271 - accuracy: 0.8667 - val_loss: 11.8806 - val_accuracy: 0.4000\n",
            "Epoch 135/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.6660 - accuracy: 0.9091 - val_loss: 17.2550 - val_accuracy: 0.3000\n",
            "Epoch 136/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3372 - accuracy: 0.8090 - val_loss: 11.0193 - val_accuracy: 0.2500\n",
            "Epoch 137/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.5527 - accuracy: 0.8333 - val_loss: 12.8990 - val_accuracy: 0.4500\n",
            "Epoch 138/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5521 - accuracy: 0.8539 - val_loss: 15.5186 - val_accuracy: 0.2500\n",
            "Epoch 139/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.5825 - accuracy: 0.8539 - val_loss: 14.0076 - val_accuracy: 0.4000\n",
            "Epoch 140/150\n",
            "9/9 [==============================] - 1s 126ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.0774 - accuracy: 0.8652 - val_loss: 11.5136 - val_accuracy: 0.3000\n",
            "Epoch 141/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.5727 - accuracy: 0.9101 - val_loss: 15.1500 - val_accuracy: 0.3000\n",
            "Epoch 142/150\n",
            "9/9 [==============================] - 1s 153ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8103 - accuracy: 0.8989 - val_loss: 15.8533 - val_accuracy: 0.2000\n",
            "Epoch 143/150\n",
            "9/9 [==============================] - 1s 148ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.5665 - accuracy: 0.8778 - val_loss: 13.2215 - val_accuracy: 0.5000\n",
            "Epoch 144/150\n",
            "9/9 [==============================] - 1s 132ms/step - batch: 4.0000 - size: 9.7778 - loss: 0.8729 - accuracy: 0.8750 - val_loss: 8.2145 - val_accuracy: 0.4000\n",
            "Epoch 145/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.1586 - accuracy: 0.9101 - val_loss: 13.2421 - val_accuracy: 0.4000\n",
            "Epoch 146/150\n",
            "9/9 [==============================] - 1s 133ms/step - batch: 4.0000 - size: 9.8889 - loss: 0.8982 - accuracy: 0.8989 - val_loss: 13.6014 - val_accuracy: 0.3500\n",
            "Epoch 147/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 10.0000 - loss: 0.3620 - accuracy: 0.9222 - val_loss: 13.5618 - val_accuracy: 0.3500\n",
            "Epoch 148/150\n",
            "9/9 [==============================] - 1s 134ms/step - batch: 4.0000 - size: 9.8889 - loss: 1.3783 - accuracy: 0.8315 - val_loss: 14.2308 - val_accuracy: 0.3500\n",
            "Epoch 149/150\n",
            "9/9 [==============================] - 1s 131ms/step - batch: 4.0000 - size: 9.7778 - loss: 1.4604 - accuracy: 0.8409 - val_loss: 11.9985 - val_accuracy: 0.3500\n",
            "Epoch 150/150\n",
            "9/9 [==============================] - 1s 125ms/step - batch: 4.0000 - size: 10.0000 - loss: 1.0439 - accuracy: 0.8889 - val_loss: 13.1134 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7zX6UhdpmrG",
        "outputId": "50853d50-d3da-4f16-c990-27ec46ee928d"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Chromagram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder=path_to_folder)\n",
        "classifier=phono_net_arch()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 111 images belonging to 5 classes.\n",
            "Found 10 images belonging to 5 classes.\n",
            "Epoch 1/150\n",
            "11/11 [==============================] - 7s 217ms/step - batch: 5.0000 - size: 9.1818 - loss: 5.7082 - accuracy: 0.1881 - val_loss: 1.6916 - val_accuracy: 0.2000\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 1s 126ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6320 - accuracy: 0.1881 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6092 - accuracy: 0.1584 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6090 - accuracy: 0.2455 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.1485 - val_loss: 1.6041 - val_accuracy: 0.2000\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6399 - accuracy: 0.2772 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6257 - accuracy: 0.2376 - val_loss: 1.5998 - val_accuracy: 0.3000\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6081 - accuracy: 0.2391 - val_loss: 1.6305 - val_accuracy: 0.2000\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6089 - accuracy: 0.2091 - val_loss: 1.6098 - val_accuracy: 0.2000\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6108 - accuracy: 0.2376 - val_loss: 1.6096 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6076 - accuracy: 0.2475 - val_loss: 1.6304 - val_accuracy: 0.1000\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6111 - accuracy: 0.2079 - val_loss: 1.6181 - val_accuracy: 0.1000\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6089 - accuracy: 0.2182 - val_loss: 1.5911 - val_accuracy: 0.3000\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6054 - accuracy: 0.2391 - val_loss: 1.5512 - val_accuracy: 0.3000\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6076 - accuracy: 0.2277 - val_loss: 1.5912 - val_accuracy: 0.2000\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6103 - accuracy: 0.2178 - val_loss: 1.6673 - val_accuracy: 0.3000\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6087 - accuracy: 0.2277 - val_loss: 1.5442 - val_accuracy: 0.2000\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.2277 - val_loss: 1.5994 - val_accuracy: 0.2000\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6111 - accuracy: 0.2376 - val_loss: 1.6637 - val_accuracy: 0.2000\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6098 - accuracy: 0.2091 - val_loss: 1.6119 - val_accuracy: 0.1000\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6051 - accuracy: 0.2574 - val_loss: 1.6164 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6064 - accuracy: 0.2178 - val_loss: 1.6151 - val_accuracy: 0.3000\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6038 - accuracy: 0.2673 - val_loss: 1.6402 - val_accuracy: 0.1000\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6100 - accuracy: 0.2376 - val_loss: 1.6146 - val_accuracy: 0.1000\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5976 - accuracy: 0.2871 - val_loss: 1.6245 - val_accuracy: 0.5000\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6048 - accuracy: 0.1545 - val_loss: 1.6065 - val_accuracy: 0.1000\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5858 - accuracy: 0.2500 - val_loss: 1.6006 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 1s 126ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5933 - accuracy: 0.2376 - val_loss: 1.5957 - val_accuracy: 0.3000\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 1s 126ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5996 - accuracy: 0.2273 - val_loss: 1.6130 - val_accuracy: 0.1000\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.7995 - accuracy: 0.2871 - val_loss: 3.0470 - val_accuracy: 0.3000\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6988 - accuracy: 0.2178 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6055 - accuracy: 0.2475 - val_loss: 1.6340 - val_accuracy: 0.1000\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6131 - accuracy: 0.1881 - val_loss: 1.6099 - val_accuracy: 0.2000\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6108 - accuracy: 0.2717 - val_loss: 1.6107 - val_accuracy: 0.1000\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6081 - accuracy: 0.2273 - val_loss: 1.6267 - val_accuracy: 0.2000\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 1s 115ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6091 - accuracy: 0.2178 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 1s 116ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6071 - accuracy: 0.2475 - val_loss: 1.6106 - val_accuracy: 0.2000\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 1s 124ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6079 - accuracy: 0.2178 - val_loss: 1.6099 - val_accuracy: 0.2000\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6067 - accuracy: 0.2079 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6039 - accuracy: 0.2091 - val_loss: 1.6100 - val_accuracy: 0.2000\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5983 - accuracy: 0.2717 - val_loss: 1.6101 - val_accuracy: 0.2000\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6089 - accuracy: 0.1909 - val_loss: 1.6101 - val_accuracy: 0.2000\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6024 - accuracy: 0.2178 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.2673 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6103 - accuracy: 0.2277 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6086 - accuracy: 0.1980 - val_loss: 1.6033 - val_accuracy: 0.3000\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6171 - accuracy: 0.2178 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6015 - accuracy: 0.2277 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6087 - accuracy: 0.2178 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6106 - accuracy: 0.1980 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6051 - accuracy: 0.2545 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6118 - accuracy: 0.2277 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 1s 109ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5972 - accuracy: 0.2391 - val_loss: 1.6104 - val_accuracy: 0.2000\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6079 - accuracy: 0.2364 - val_loss: 1.6104 - val_accuracy: 0.2000\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6102 - accuracy: 0.2065 - val_loss: 1.6105 - val_accuracy: 0.2000\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6134 - accuracy: 0.1881 - val_loss: 1.6104 - val_accuracy: 0.2000\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6057 - accuracy: 0.2364 - val_loss: 1.6104 - val_accuracy: 0.2000\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6045 - accuracy: 0.2475 - val_loss: 1.6105 - val_accuracy: 0.2000\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6079 - accuracy: 0.2079 - val_loss: 1.6105 - val_accuracy: 0.2000\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6048 - accuracy: 0.2376 - val_loss: 1.6105 - val_accuracy: 0.2000\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6056 - accuracy: 0.2475 - val_loss: 1.6106 - val_accuracy: 0.2000\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6026 - accuracy: 0.1980 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6032 - accuracy: 0.2079 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6048 - accuracy: 0.2455 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6147 - accuracy: 0.2174 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6038 - accuracy: 0.2376 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6049 - accuracy: 0.2636 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6141 - accuracy: 0.2079 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6084 - accuracy: 0.2277 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6143 - accuracy: 0.1683 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6004 - accuracy: 0.2277 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6008 - accuracy: 0.2475 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6016 - accuracy: 0.2178 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5995 - accuracy: 0.2376 - val_loss: 1.6110 - val_accuracy: 0.2000\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6111 - accuracy: 0.2178 - val_loss: 1.6111 - val_accuracy: 0.2000\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6034 - accuracy: 0.1980 - val_loss: 1.6111 - val_accuracy: 0.2000\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6033 - accuracy: 0.2364 - val_loss: 1.6111 - val_accuracy: 0.2000\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6020 - accuracy: 0.2079 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6083 - accuracy: 0.2772 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6190 - accuracy: 0.1881 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5979 - accuracy: 0.2277 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6060 - accuracy: 0.2376 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6079 - accuracy: 0.2277 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6077 - accuracy: 0.2277 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6108 - accuracy: 0.2079 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6020 - accuracy: 0.2364 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6000 - accuracy: 0.2609 - val_loss: 1.6113 - val_accuracy: 0.2000\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6093 - accuracy: 0.1980 - val_loss: 1.6114 - val_accuracy: 0.2000\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6085 - accuracy: 0.2091 - val_loss: 1.6114 - val_accuracy: 0.2000\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 1s 123ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5949 - accuracy: 0.2772 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6111 - accuracy: 0.1980 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6064 - accuracy: 0.2178 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6041 - accuracy: 0.2574 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6059 - accuracy: 0.1980 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6106 - accuracy: 0.2079 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6053 - accuracy: 0.2376 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6042 - accuracy: 0.2277 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6092 - accuracy: 0.2178 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6062 - accuracy: 0.2178 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6023 - accuracy: 0.2376 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6108 - accuracy: 0.2273 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6028 - accuracy: 0.2376 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 1s 109ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6039 - accuracy: 0.2065 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6051 - accuracy: 0.2475 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6091 - accuracy: 0.2091 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5964 - accuracy: 0.2277 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6097 - accuracy: 0.2079 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6020 - accuracy: 0.2376 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6048 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 1s 123ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6077 - accuracy: 0.2178 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6048 - accuracy: 0.2079 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6171 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5948 - accuracy: 0.2545 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6229 - accuracy: 0.2079 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6056 - accuracy: 0.2283 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6033 - accuracy: 0.2636 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6200 - accuracy: 0.1683 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6125 - accuracy: 0.2772 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6037 - accuracy: 0.1881 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6142 - accuracy: 0.2277 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6007 - accuracy: 0.2178 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6015 - accuracy: 0.2475 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6175 - accuracy: 0.1980 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5934 - accuracy: 0.2574 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6100 - accuracy: 0.2182 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6027 - accuracy: 0.2391 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6101 - accuracy: 0.2000 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5940 - accuracy: 0.2500 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6025 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6086 - accuracy: 0.2182 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.1980 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6051 - accuracy: 0.2376 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6162 - accuracy: 0.2376 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6046 - accuracy: 0.1980 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6124 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5955 - accuracy: 0.2574 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6131 - accuracy: 0.2079 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5997 - accuracy: 0.2574 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5996 - accuracy: 0.1881 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5958 - accuracy: 0.2475 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6090 - accuracy: 0.2079 - val_loss: 1.6123 - val_accuracy: 0.2000\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5983 - accuracy: 0.2079 - val_loss: 1.6124 - val_accuracy: 0.2000\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5984 - accuracy: 0.2475 - val_loss: 1.6124 - val_accuracy: 0.2000\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6066 - accuracy: 0.2182 - val_loss: 1.6125 - val_accuracy: 0.2000\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6066 - accuracy: 0.2182 - val_loss: 1.6126 - val_accuracy: 0.2000\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6006 - accuracy: 0.2178 - val_loss: 1.6127 - val_accuracy: 0.2000\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5952 - accuracy: 0.2174 - val_loss: 1.6128 - val_accuracy: 0.2000\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6111 - accuracy: 0.2475 - val_loss: 1.6128 - val_accuracy: 0.2000\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6009 - accuracy: 0.2079 - val_loss: 1.6128 - val_accuracy: 0.2000\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6047 - accuracy: 0.2545 - val_loss: 1.6128 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlK-woXMsLix"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdnyID3tsGtP"
      },
      "source": [
        "# Training on Spectogram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRkKgfifsIrz",
        "outputId": "076e3ae8-2d7a-4139-c471-d681b7963783"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Spectogram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder)\n",
        "classifier=deep_conv()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 111 images belonging to 5 classes.\n",
            "Found 10 images belonging to 5 classes.\n",
            "Epoch 1/150\n",
            "11/11 [==============================] - 22s 605ms/step - batch: 5.0000 - size: 9.1818 - loss: 229.5444 - accuracy: 0.1980 - val_loss: 11.6024 - val_accuracy: 0.2000\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 3.4381 - accuracy: 0.1980 - val_loss: 1.5851 - val_accuracy: 0.2000\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6193 - accuracy: 0.1386 - val_loss: 1.6216 - val_accuracy: 0.4000\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6244 - accuracy: 0.2574 - val_loss: 1.6098 - val_accuracy: 0.2000\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6493 - accuracy: 0.1683 - val_loss: 1.6413 - val_accuracy: 0.1000\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6106 - accuracy: 0.2091 - val_loss: 1.6088 - val_accuracy: 0.2000\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6112 - accuracy: 0.1087 - val_loss: 1.6096 - val_accuracy: 0.2000\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6077 - accuracy: 0.2455 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6074 - accuracy: 0.1782 - val_loss: 1.6101 - val_accuracy: 0.3000\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6103 - accuracy: 0.2079 - val_loss: 1.6103 - val_accuracy: 0.2000\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6117 - accuracy: 0.2283 - val_loss: 1.6173 - val_accuracy: 0.2000\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6054 - accuracy: 0.2182 - val_loss: 1.6078 - val_accuracy: 0.2000\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6194 - accuracy: 0.2364 - val_loss: 1.6100 - val_accuracy: 0.2000\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 1s 126ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6091 - accuracy: 0.1957 - val_loss: 1.6099 - val_accuracy: 0.2000\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6129 - accuracy: 0.1980 - val_loss: 1.6098 - val_accuracy: 0.2000\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6104 - accuracy: 0.2277 - val_loss: 1.6077 - val_accuracy: 0.3000\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6073 - accuracy: 0.1881 - val_loss: 1.6099 - val_accuracy: 0.1000\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6054 - accuracy: 0.2818 - val_loss: 1.6096 - val_accuracy: 0.2000\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6089 - accuracy: 0.2475 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6077 - accuracy: 0.2178 - val_loss: 1.6050 - val_accuracy: 0.3000\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6105 - accuracy: 0.1485 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6032 - accuracy: 0.2574 - val_loss: 1.6149 - val_accuracy: 0.3000\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6070 - accuracy: 0.2079 - val_loss: 1.6086 - val_accuracy: 0.2000\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6145 - accuracy: 0.2376 - val_loss: 1.5633 - val_accuracy: 0.3000\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6060 - accuracy: 0.2273 - val_loss: 1.6097 - val_accuracy: 0.2000\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6372 - accuracy: 0.2174 - val_loss: 1.6127 - val_accuracy: 0.2000\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6024 - accuracy: 0.2178 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6054 - accuracy: 0.2455 - val_loss: 1.6104 - val_accuracy: 0.2000\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 1s 109ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6062 - accuracy: 0.2065 - val_loss: 1.6084 - val_accuracy: 0.2000\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6128 - accuracy: 0.2475 - val_loss: 1.6100 - val_accuracy: 0.2000\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6045 - accuracy: 0.2364 - val_loss: 1.6113 - val_accuracy: 0.2000\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5961 - accuracy: 0.2500 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6137 - accuracy: 0.1818 - val_loss: 1.6185 - val_accuracy: 0.2000\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.1980 - val_loss: 1.6076 - val_accuracy: 0.2000\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6096 - accuracy: 0.2475 - val_loss: 1.6081 - val_accuracy: 0.2000\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6213 - accuracy: 0.2376 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6057 - accuracy: 0.2376 - val_loss: 1.6114 - val_accuracy: 0.2000\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6055 - accuracy: 0.2376 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6135 - accuracy: 0.2376 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6048 - accuracy: 0.2079 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6059 - accuracy: 0.2273 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 1s 108ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6195 - accuracy: 0.2391 - val_loss: 1.6130 - val_accuracy: 0.2000\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6086 - accuracy: 0.1818 - val_loss: 1.6111 - val_accuracy: 0.2000\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6169 - accuracy: 0.2277 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 1s 109ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6119 - accuracy: 0.2609 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6093 - accuracy: 0.2182 - val_loss: 1.6097 - val_accuracy: 0.2000\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6076 - accuracy: 0.2178 - val_loss: 1.6106 - val_accuracy: 0.2000\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6053 - accuracy: 0.2376 - val_loss: 1.6106 - val_accuracy: 0.2000\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6056 - accuracy: 0.2475 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6177 - accuracy: 0.1980 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6048 - accuracy: 0.2277 - val_loss: 1.6106 - val_accuracy: 0.2000\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6039 - accuracy: 0.2545 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 1s 107ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6000 - accuracy: 0.1957 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6012 - accuracy: 0.2673 - val_loss: 1.6112 - val_accuracy: 0.2000\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6090 - accuracy: 0.2376 - val_loss: 1.6114 - val_accuracy: 0.2000\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6127 - accuracy: 0.1455 - val_loss: 1.6089 - val_accuracy: 0.2000\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6064 - accuracy: 0.2475 - val_loss: 1.6113 - val_accuracy: 0.2000\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6057 - accuracy: 0.2277 - val_loss: 1.6114 - val_accuracy: 0.2000\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6033 - accuracy: 0.2277 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5999 - accuracy: 0.2376 - val_loss: 1.6116 - val_accuracy: 0.2000\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6060 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 1s 124ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.1980 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6002 - accuracy: 0.2574 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6184 - accuracy: 0.2079 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6004 - accuracy: 0.2277 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6074 - accuracy: 0.2364 - val_loss: 1.6123 - val_accuracy: 0.2000\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5996 - accuracy: 0.2277 - val_loss: 1.6131 - val_accuracy: 0.2000\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5940 - accuracy: 0.2283 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6097 - accuracy: 0.2079 - val_loss: 1.6137 - val_accuracy: 0.2000\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6043 - accuracy: 0.2455 - val_loss: 1.6133 - val_accuracy: 0.2000\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6027 - accuracy: 0.2079 - val_loss: 1.6133 - val_accuracy: 0.2000\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 1s 115ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6189 - accuracy: 0.2277 - val_loss: 1.6130 - val_accuracy: 0.2000\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5968 - accuracy: 0.2475 - val_loss: 1.6130 - val_accuracy: 0.2000\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 1s 124ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6028 - accuracy: 0.2277 - val_loss: 1.6132 - val_accuracy: 0.2000\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6034 - accuracy: 0.2277 - val_loss: 1.6135 - val_accuracy: 0.2000\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6126 - accuracy: 0.1980 - val_loss: 1.6134 - val_accuracy: 0.2000\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5942 - accuracy: 0.2079 - val_loss: 1.6135 - val_accuracy: 0.2000\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6137 - accuracy: 0.2364 - val_loss: 1.6142 - val_accuracy: 0.2000\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 1s 108ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5801 - accuracy: 0.2826 - val_loss: 1.6140 - val_accuracy: 0.2000\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6092 - accuracy: 0.2178 - val_loss: 1.6141 - val_accuracy: 0.2000\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6032 - accuracy: 0.1818 - val_loss: 1.6147 - val_accuracy: 0.2000\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5961 - accuracy: 0.2609 - val_loss: 1.6149 - val_accuracy: 0.2000\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6065 - accuracy: 0.2182 - val_loss: 1.6149 - val_accuracy: 0.2000\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5974 - accuracy: 0.2376 - val_loss: 1.6151 - val_accuracy: 0.2000\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5976 - accuracy: 0.2376 - val_loss: 1.6156 - val_accuracy: 0.2000\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 1s 125ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.2178 - val_loss: 1.6157 - val_accuracy: 0.2000\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6052 - accuracy: 0.2273 - val_loss: 1.6158 - val_accuracy: 0.2000\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 1s 108ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6043 - accuracy: 0.1957 - val_loss: 1.6157 - val_accuracy: 0.2000\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6126 - accuracy: 0.2673 - val_loss: 1.6153 - val_accuracy: 0.2000\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6280 - accuracy: 0.1584 - val_loss: 1.6149 - val_accuracy: 0.2000\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5973 - accuracy: 0.2636 - val_loss: 1.6139 - val_accuracy: 0.2000\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6023 - accuracy: 0.2574 - val_loss: 1.6142 - val_accuracy: 0.2000\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6140 - accuracy: 0.2079 - val_loss: 1.6141 - val_accuracy: 0.2000\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6106 - accuracy: 0.2475 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5992 - accuracy: 0.1881 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 1s 115ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6070 - accuracy: 0.2277 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 1s 123ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5969 - accuracy: 0.2376 - val_loss: 1.6141 - val_accuracy: 0.2000\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6088 - accuracy: 0.2079 - val_loss: 1.6142 - val_accuracy: 0.2000\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6063 - accuracy: 0.2376 - val_loss: 1.6143 - val_accuracy: 0.2000\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6205 - accuracy: 0.1980 - val_loss: 1.6136 - val_accuracy: 0.2000\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6019 - accuracy: 0.2475 - val_loss: 1.6134 - val_accuracy: 0.2000\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6036 - accuracy: 0.2277 - val_loss: 1.6133 - val_accuracy: 0.2000\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6087 - accuracy: 0.2574 - val_loss: 1.6134 - val_accuracy: 0.2000\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6053 - accuracy: 0.1818 - val_loss: 1.6135 - val_accuracy: 0.2000\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6081 - accuracy: 0.2178 - val_loss: 1.6133 - val_accuracy: 0.2000\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6163 - accuracy: 0.2376 - val_loss: 1.6132 - val_accuracy: 0.2000\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6174 - accuracy: 0.2178 - val_loss: 1.6130 - val_accuracy: 0.2000\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6020 - accuracy: 0.2376 - val_loss: 1.6127 - val_accuracy: 0.2000\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 1s 125ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6016 - accuracy: 0.2376 - val_loss: 1.6128 - val_accuracy: 0.2000\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6002 - accuracy: 0.2079 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6107 - accuracy: 0.2364 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5972 - accuracy: 0.2178 - val_loss: 1.6129 - val_accuracy: 0.2000\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 1s 112ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6021 - accuracy: 0.2065 - val_loss: 1.6133 - val_accuracy: 0.2000\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6069 - accuracy: 0.2475 - val_loss: 1.6134 - val_accuracy: 0.2000\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6050 - accuracy: 0.2364 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6145 - accuracy: 0.2283 - val_loss: 1.6137 - val_accuracy: 0.2000\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5901 - accuracy: 0.2475 - val_loss: 1.6136 - val_accuracy: 0.2000\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6029 - accuracy: 0.2091 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6256 - accuracy: 0.2277 - val_loss: 1.6137 - val_accuracy: 0.2000\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 1s 113ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6076 - accuracy: 0.2178 - val_loss: 1.6132 - val_accuracy: 0.2000\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6045 - accuracy: 0.2273 - val_loss: 1.6127 - val_accuracy: 0.2000\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6174 - accuracy: 0.2391 - val_loss: 1.6126 - val_accuracy: 0.2000\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6073 - accuracy: 0.2376 - val_loss: 1.6125 - val_accuracy: 0.2000\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 1s 123ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6187 - accuracy: 0.1782 - val_loss: 1.6123 - val_accuracy: 0.2000\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5999 - accuracy: 0.2376 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6161 - accuracy: 0.1818 - val_loss: 1.6123 - val_accuracy: 0.2000\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6046 - accuracy: 0.2574 - val_loss: 1.6121 - val_accuracy: 0.2000\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6078 - accuracy: 0.2277 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5973 - accuracy: 0.2673 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6067 - accuracy: 0.2079 - val_loss: 1.6123 - val_accuracy: 0.2000\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6003 - accuracy: 0.2277 - val_loss: 1.6125 - val_accuracy: 0.2000\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6165 - accuracy: 0.2277 - val_loss: 1.6124 - val_accuracy: 0.2000\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6188 - accuracy: 0.2178 - val_loss: 1.6120 - val_accuracy: 0.2000\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6082 - accuracy: 0.1980 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6049 - accuracy: 0.2475 - val_loss: 1.6117 - val_accuracy: 0.2000\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6066 - accuracy: 0.2636 - val_loss: 1.6119 - val_accuracy: 0.2000\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 1s 111ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6143 - accuracy: 0.1957 - val_loss: 1.6118 - val_accuracy: 0.2000\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6209 - accuracy: 0.2178 - val_loss: 1.6115 - val_accuracy: 0.2000\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 1s 126ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6049 - accuracy: 0.2455 - val_loss: 1.6113 - val_accuracy: 0.2000\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 1s 121ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6192 - accuracy: 0.1782 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 1s 107ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6133 - accuracy: 0.2500 - val_loss: 1.6102 - val_accuracy: 0.2000\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6048 - accuracy: 0.2273 - val_loss: 1.6113 - val_accuracy: 0.2000\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6024 - accuracy: 0.2475 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 1s 114ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6095 - accuracy: 0.2277 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6044 - accuracy: 0.2277 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6049 - accuracy: 0.2364 - val_loss: 1.6111 - val_accuracy: 0.2000\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6167 - accuracy: 0.2079 - val_loss: 1.6109 - val_accuracy: 0.2000\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 1s 110ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6153 - accuracy: 0.2065 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6020 - accuracy: 0.2818 - val_loss: 1.6107 - val_accuracy: 0.2000\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6050 - accuracy: 0.1782 - val_loss: 1.6110 - val_accuracy: 0.2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyViHr7xsNQa",
        "outputId": "1008585a-d178-40f7-dfa0-0283014b427b"
      },
      "source": [
        "path_to_folder='/content/drive/MyDrive/IMG_DATA_RAAGA/Spectogram'\n",
        "\n",
        "train_generator,validation_generator=load_data(path_to_folder=path_to_folder,preprocessing_function=resnet.preprocess_input)\n",
        "classifier=res_net_model()\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 111 images belonging to 5 classes.\n",
            "Found 10 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "Epoch 1/150\n",
            "11/11 [==============================] - 7s 181ms/step - batch: 5.0000 - size: 9.1818 - loss: 4.3359 - accuracy: 0.1782 - val_loss: 12.2268 - val_accuracy: 0.3000\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 2s 151ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.7941 - accuracy: 0.1782 - val_loss: 95.3968 - val_accuracy: 0.2000\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.6942 - accuracy: 0.2574 - val_loss: 98.3185 - val_accuracy: 0.2000\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 3.6323 - accuracy: 0.1584 - val_loss: 913.5980 - val_accuracy: 0.2000\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 2.3947 - accuracy: 0.2182 - val_loss: 153.2292 - val_accuracy: 0.3000\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.1388 - accuracy: 0.1683 - val_loss: 130.4709 - val_accuracy: 0.2000\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 8.3636 - loss: 2.5350 - accuracy: 0.1630 - val_loss: 37.1620 - val_accuracy: 0.2000\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 2s 145ms/step - batch: 5.0000 - size: 10.0000 - loss: 2.1611 - accuracy: 0.2000 - val_loss: 17.5379 - val_accuracy: 0.1000\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.8516 - accuracy: 0.2065 - val_loss: 27.6735 - val_accuracy: 0.2000\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 10.0000 - loss: 2.0138 - accuracy: 0.2182 - val_loss: 8.5334 - val_accuracy: 0.2000\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6928 - accuracy: 0.2475 - val_loss: 4.7269 - val_accuracy: 0.1000\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.8172 - accuracy: 0.2178 - val_loss: 6.7105 - val_accuracy: 0.2000\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.7386 - accuracy: 0.2475 - val_loss: 3.2471 - val_accuracy: 0.3000\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6811 - accuracy: 0.2475 - val_loss: 2.2721 - val_accuracy: 0.2000\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 2s 151ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6530 - accuracy: 0.2727 - val_loss: 1.8142 - val_accuracy: 0.4000\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.6802 - accuracy: 0.2065 - val_loss: 2.1318 - val_accuracy: 0.2000\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.7239 - accuracy: 0.2871 - val_loss: 2.8954 - val_accuracy: 0.3000\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4877 - accuracy: 0.2970 - val_loss: 2.2598 - val_accuracy: 0.3000\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.8648 - accuracy: 0.2277 - val_loss: 1.8986 - val_accuracy: 0.2000\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5277 - accuracy: 0.3069 - val_loss: 1.6532 - val_accuracy: 0.2000\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.6254 - accuracy: 0.2273 - val_loss: 1.5800 - val_accuracy: 0.2000\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4916 - accuracy: 0.3168 - val_loss: 1.0762 - val_accuracy: 0.7000\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5108 - accuracy: 0.2970 - val_loss: 1.7583 - val_accuracy: 0.3000\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.7283 - accuracy: 0.3069 - val_loss: 1.9556 - val_accuracy: 0.4000\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5300 - accuracy: 0.3168 - val_loss: 1.5645 - val_accuracy: 0.3000\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5825 - accuracy: 0.2970 - val_loss: 1.6911 - val_accuracy: 0.4000\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5677 - accuracy: 0.2970 - val_loss: 1.8446 - val_accuracy: 0.3000\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.4746 - accuracy: 0.3364 - val_loss: 1.3674 - val_accuracy: 0.4000\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4668 - accuracy: 0.3168 - val_loss: 1.3940 - val_accuracy: 0.4000\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 1s 117ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5836 - accuracy: 0.3043 - val_loss: 1.5757 - val_accuracy: 0.2000\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5044 - accuracy: 0.3818 - val_loss: 1.7620 - val_accuracy: 0.3000\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5931 - accuracy: 0.3564 - val_loss: 1.8337 - val_accuracy: 0.3000\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5257 - accuracy: 0.3564 - val_loss: 1.3845 - val_accuracy: 0.5000\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 1s 120ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.4333 - accuracy: 0.3043 - val_loss: 1.1554 - val_accuracy: 0.4000\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5649 - accuracy: 0.3273 - val_loss: 1.1651 - val_accuracy: 0.5000\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4829 - accuracy: 0.3069 - val_loss: 1.2746 - val_accuracy: 0.4000\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4248 - accuracy: 0.3663 - val_loss: 1.2190 - val_accuracy: 0.6000\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4087 - accuracy: 0.3861 - val_loss: 1.3893 - val_accuracy: 0.3000\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5407 - accuracy: 0.3366 - val_loss: 1.5038 - val_accuracy: 0.1000\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3314 - accuracy: 0.3663 - val_loss: 1.4425 - val_accuracy: 0.4000\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6485 - accuracy: 0.3168 - val_loss: 1.4171 - val_accuracy: 0.5000\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.4768 - accuracy: 0.3091 - val_loss: 1.4880 - val_accuracy: 0.3000\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5055 - accuracy: 0.3663 - val_loss: 1.6609 - val_accuracy: 0.3000\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4354 - accuracy: 0.3465 - val_loss: 1.8463 - val_accuracy: 0.3000\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3438 - accuracy: 0.3861 - val_loss: 1.2903 - val_accuracy: 0.5000\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4481 - accuracy: 0.3564 - val_loss: 1.6064 - val_accuracy: 0.4000\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4932 - accuracy: 0.3465 - val_loss: 1.2580 - val_accuracy: 0.5000\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5553 - accuracy: 0.3465 - val_loss: 1.6890 - val_accuracy: 0.4000\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4380 - accuracy: 0.3168 - val_loss: 1.6929 - val_accuracy: 0.4000\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 2s 155ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.3777 - accuracy: 0.3727 - val_loss: 1.3775 - val_accuracy: 0.4000\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.3587 - accuracy: 0.4565 - val_loss: 1.3290 - val_accuracy: 0.3000\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3840 - accuracy: 0.4653 - val_loss: 1.4179 - val_accuracy: 0.5000\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.3879 - accuracy: 0.3727 - val_loss: 1.5704 - val_accuracy: 0.5000\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2893 - accuracy: 0.4554 - val_loss: 2.1933 - val_accuracy: 0.4000\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 1s 124ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5176 - accuracy: 0.4565 - val_loss: 1.7948 - val_accuracy: 0.3000\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4184 - accuracy: 0.4059 - val_loss: 1.7767 - val_accuracy: 0.3000\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.3128 - accuracy: 0.4364 - val_loss: 1.9813 - val_accuracy: 0.4000\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2939 - accuracy: 0.4752 - val_loss: 1.3981 - val_accuracy: 0.3000\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3574 - accuracy: 0.4455 - val_loss: 1.3127 - val_accuracy: 0.5000\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4835 - accuracy: 0.4257 - val_loss: 1.0184 - val_accuracy: 0.5000\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4283 - accuracy: 0.3762 - val_loss: 1.4784 - val_accuracy: 0.5000\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 2s 153ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2748 - accuracy: 0.4356 - val_loss: 1.6891 - val_accuracy: 0.4000\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2774 - accuracy: 0.4752 - val_loss: 1.1917 - val_accuracy: 0.5000\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2059 - accuracy: 0.4752 - val_loss: 2.5699 - val_accuracy: 0.3000\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3636 - accuracy: 0.3960 - val_loss: 1.8737 - val_accuracy: 0.3000\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2633 - accuracy: 0.5050 - val_loss: 1.9434 - val_accuracy: 0.3000\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1463 - accuracy: 0.4818 - val_loss: 1.7766 - val_accuracy: 0.4000\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2414 - accuracy: 0.5050 - val_loss: 2.2789 - val_accuracy: 0.2000\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5018 - accuracy: 0.3861 - val_loss: 1.4499 - val_accuracy: 0.6000\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2850 - accuracy: 0.4257 - val_loss: 2.6659 - val_accuracy: 0.3000\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3345 - accuracy: 0.3564 - val_loss: 2.1512 - val_accuracy: 0.2000\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2165 - accuracy: 0.4356 - val_loss: 1.2962 - val_accuracy: 0.6000\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2626 - accuracy: 0.3960 - val_loss: 1.6443 - val_accuracy: 0.2000\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 2s 157ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1218 - accuracy: 0.5091 - val_loss: 2.3145 - val_accuracy: 0.4000\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.0871 - accuracy: 0.5761 - val_loss: 2.3536 - val_accuracy: 0.3000\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1233 - accuracy: 0.5091 - val_loss: 2.5391 - val_accuracy: 0.3000\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4192 - accuracy: 0.4653 - val_loss: 5.9399 - val_accuracy: 0.3000\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.4823 - accuracy: 0.3913 - val_loss: 3.5948 - val_accuracy: 0.3000\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1398 - accuracy: 0.4851 - val_loss: 1.5439 - val_accuracy: 0.5000\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0684 - accuracy: 0.4455 - val_loss: 1.6727 - val_accuracy: 0.5000\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0986 - accuracy: 0.5545 - val_loss: 2.5312 - val_accuracy: 0.3000\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.3222 - accuracy: 0.4727 - val_loss: 1.3459 - val_accuracy: 0.4000\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3603 - accuracy: 0.4653 - val_loss: 2.2599 - val_accuracy: 0.3000\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3187 - accuracy: 0.4653 - val_loss: 2.1953 - val_accuracy: 0.6000\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3032 - accuracy: 0.5050 - val_loss: 2.2143 - val_accuracy: 0.3000\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3264 - accuracy: 0.4257 - val_loss: 3.5487 - val_accuracy: 0.5000\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1758 - accuracy: 0.4455 - val_loss: 3.2205 - val_accuracy: 0.4000\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.3698 - accuracy: 0.5326 - val_loss: 1.7152 - val_accuracy: 0.6000\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9402 - accuracy: 0.6337 - val_loss: 3.0188 - val_accuracy: 0.5000\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9998 - accuracy: 0.5842 - val_loss: 2.8933 - val_accuracy: 0.3000\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2270 - accuracy: 0.5545 - val_loss: 1.4966 - val_accuracy: 0.4000\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2140 - accuracy: 0.4158 - val_loss: 2.7861 - val_accuracy: 0.4000\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1665 - accuracy: 0.5091 - val_loss: 2.4777 - val_accuracy: 0.2000\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0746 - accuracy: 0.5545 - val_loss: 1.5755 - val_accuracy: 0.5000\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2712 - accuracy: 0.5644 - val_loss: 1.4485 - val_accuracy: 0.4000\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1736 - accuracy: 0.5149 - val_loss: 2.2144 - val_accuracy: 0.3000\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1751 - accuracy: 0.5050 - val_loss: 2.6177 - val_accuracy: 0.2000\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2750 - accuracy: 0.5347 - val_loss: 2.0408 - val_accuracy: 0.3000\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1326 - accuracy: 0.5743 - val_loss: 1.7566 - val_accuracy: 0.4000\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0486 - accuracy: 0.5545 - val_loss: 3.4558 - val_accuracy: 0.4000\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1406 - accuracy: 0.5446 - val_loss: 3.7261 - val_accuracy: 0.3000\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9939 - accuracy: 0.6139 - val_loss: 2.0531 - val_accuracy: 0.3000\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0119 - accuracy: 0.6091 - val_loss: 1.9771 - val_accuracy: 0.3000\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.0013 - accuracy: 0.5543 - val_loss: 2.7529 - val_accuracy: 0.2000\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0967 - accuracy: 0.5842 - val_loss: 2.0279 - val_accuracy: 0.4000\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0547 - accuracy: 0.5636 - val_loss: 3.7632 - val_accuracy: 0.4000\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9340 - accuracy: 0.6337 - val_loss: 1.7198 - val_accuracy: 0.5000\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3174 - accuracy: 0.5545 - val_loss: 3.0046 - val_accuracy: 0.3000\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9654 - accuracy: 0.5941 - val_loss: 1.8477 - val_accuracy: 0.4000\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 2s 153ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8613 - accuracy: 0.5941 - val_loss: 2.1853 - val_accuracy: 0.5000\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1731 - accuracy: 0.5743 - val_loss: 1.3370 - val_accuracy: 0.5000\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1264 - accuracy: 0.5842 - val_loss: 1.5401 - val_accuracy: 0.4000\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1843 - accuracy: 0.5248 - val_loss: 1.6651 - val_accuracy: 0.4000\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0349 - accuracy: 0.5636 - val_loss: 1.2626 - val_accuracy: 0.6000\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.8300 - accuracy: 0.6522 - val_loss: 2.3198 - val_accuracy: 0.4000\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1059 - accuracy: 0.5545 - val_loss: 3.9245 - val_accuracy: 0.2000\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0218 - accuracy: 0.5273 - val_loss: 6.7993 - val_accuracy: 0.3000\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9561 - accuracy: 0.6535 - val_loss: 2.5962 - val_accuracy: 0.4000\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0074 - accuracy: 0.5149 - val_loss: 1.8188 - val_accuracy: 0.4000\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7672 - accuracy: 0.7030 - val_loss: 2.0178 - val_accuracy: 0.4000\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8371 - accuracy: 0.6733 - val_loss: 1.7519 - val_accuracy: 0.5000\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0998 - accuracy: 0.6436 - val_loss: 1.9158 - val_accuracy: 0.4000\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9792 - accuracy: 0.6238 - val_loss: 3.5460 - val_accuracy: 0.3000\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.1387 - accuracy: 0.5909 - val_loss: 2.1404 - val_accuracy: 0.4000\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9926 - accuracy: 0.6436 - val_loss: 3.9628 - val_accuracy: 0.3000\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.9066 - accuracy: 0.6304 - val_loss: 2.6421 - val_accuracy: 0.2000\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.8446 - accuracy: 0.6909 - val_loss: 1.5572 - val_accuracy: 0.6000\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 1s 125ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.3160 - accuracy: 0.6196 - val_loss: 2.1667 - val_accuracy: 0.4000\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 1s 143ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7609 - accuracy: 0.6535 - val_loss: 5.1022 - val_accuracy: 0.2000\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.7313 - accuracy: 0.6909 - val_loss: 3.5897 - val_accuracy: 0.3000\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7002 - accuracy: 0.7327 - val_loss: 3.5318 - val_accuracy: 0.2000\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9334 - accuracy: 0.7129 - val_loss: 3.5981 - val_accuracy: 0.2000\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2916 - accuracy: 0.6238 - val_loss: 11.8507 - val_accuracy: 0.4000\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3674 - accuracy: 0.6040 - val_loss: 35.0470 - val_accuracy: 0.4000\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1052 - accuracy: 0.5743 - val_loss: 84.6524 - val_accuracy: 0.4000\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0774 - accuracy: 0.6000 - val_loss: 11.6982 - val_accuracy: 0.2000\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9680 - accuracy: 0.6337 - val_loss: 23.7292 - val_accuracy: 0.3000\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1683 - accuracy: 0.6040 - val_loss: 15.5433 - val_accuracy: 0.2000\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.4775 - accuracy: 0.5435 - val_loss: 6.6127 - val_accuracy: 0.3000\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1318 - accuracy: 0.5149 - val_loss: 3.6565 - val_accuracy: 0.6000\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0506 - accuracy: 0.6238 - val_loss: 2.9446 - val_accuracy: 0.4000\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0544 - accuracy: 0.5545 - val_loss: 1.8073 - val_accuracy: 0.7000\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9546 - accuracy: 0.6337 - val_loss: 2.7251 - val_accuracy: 0.3000\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9651 - accuracy: 0.6337 - val_loss: 2.6965 - val_accuracy: 0.3000\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8678 - accuracy: 0.6733 - val_loss: 5.5307 - val_accuracy: 0.6000\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7206 - accuracy: 0.6535 - val_loss: 2.6921 - val_accuracy: 0.4000\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8952 - accuracy: 0.7228 - val_loss: 2.5055 - val_accuracy: 0.5000\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7705 - accuracy: 0.7426 - val_loss: 2.5440 - val_accuracy: 0.3000\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.7813 - accuracy: 0.7273 - val_loss: 1.7511 - val_accuracy: 0.5000\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9946 - accuracy: 0.5941 - val_loss: 2.3066 - val_accuracy: 0.3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fME4fBtMsbLG",
        "outputId": "e9202853-6f73-4a43-a8d6-6ead3368d37a"
      },
      "source": [
        "model_history=classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs = nb_epochs,\n",
        "    # callbacks=[tensorboard_callback]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "11/11 [==============================] - 2s 152ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6384 - accuracy: 0.7327 - val_loss: 3.1825 - val_accuracy: 0.3000\n",
            "Epoch 2/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8115 - accuracy: 0.7228 - val_loss: 3.6518 - val_accuracy: 0.2000\n",
            "Epoch 3/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9091 - accuracy: 0.5941 - val_loss: 3.6407 - val_accuracy: 0.4000\n",
            "Epoch 4/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7778 - accuracy: 0.7327 - val_loss: 3.6704 - val_accuracy: 0.4000\n",
            "Epoch 5/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7559 - accuracy: 0.7723 - val_loss: 2.0829 - val_accuracy: 0.6000\n",
            "Epoch 6/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.8441 - accuracy: 0.6455 - val_loss: 2.2732 - val_accuracy: 0.4000\n",
            "Epoch 7/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7900 - accuracy: 0.6931 - val_loss: 2.7753 - val_accuracy: 0.5000\n",
            "Epoch 8/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.1003 - accuracy: 0.7500 - val_loss: 1.5153 - val_accuracy: 0.5000\n",
            "Epoch 9/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.8488 - accuracy: 0.6727 - val_loss: 2.8139 - val_accuracy: 0.6000\n",
            "Epoch 10/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7608 - accuracy: 0.7426 - val_loss: 1.3578 - val_accuracy: 0.4000\n",
            "Epoch 11/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8833 - accuracy: 0.6337 - val_loss: 3.7635 - val_accuracy: 0.5000\n",
            "Epoch 12/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7782 - accuracy: 0.6634 - val_loss: 3.0955 - val_accuracy: 0.5000\n",
            "Epoch 13/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5861 - accuracy: 0.7624 - val_loss: 2.4451 - val_accuracy: 0.3000\n",
            "Epoch 14/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5701 - accuracy: 0.7921 - val_loss: 4.3476 - val_accuracy: 0.5000\n",
            "Epoch 15/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1736 - accuracy: 0.7129 - val_loss: 4.1540 - val_accuracy: 0.6000\n",
            "Epoch 16/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8398 - accuracy: 0.7228 - val_loss: 5.4649 - val_accuracy: 0.5000\n",
            "Epoch 17/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9606 - accuracy: 0.6733 - val_loss: 4.5096 - val_accuracy: 0.4000\n",
            "Epoch 18/150\n",
            "11/11 [==============================] - 1s 144ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.8686 - accuracy: 0.6545 - val_loss: 3.2710 - val_accuracy: 0.4000\n",
            "Epoch 19/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.2371 - accuracy: 0.7065 - val_loss: 4.2859 - val_accuracy: 0.5000\n",
            "Epoch 20/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8319 - accuracy: 0.7327 - val_loss: 1.9443 - val_accuracy: 0.6000\n",
            "Epoch 21/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0431 - accuracy: 0.7182 - val_loss: 2.2243 - val_accuracy: 0.6000\n",
            "Epoch 22/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1471 - accuracy: 0.6931 - val_loss: 7.6201 - val_accuracy: 0.4000\n",
            "Epoch 23/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8168 - accuracy: 0.6832 - val_loss: 7.5706 - val_accuracy: 0.3000\n",
            "Epoch 24/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9651 - accuracy: 0.6436 - val_loss: 8.3535 - val_accuracy: 0.4000\n",
            "Epoch 25/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8892 - accuracy: 0.7723 - val_loss: 10.1346 - val_accuracy: 0.3000\n",
            "Epoch 26/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9336 - accuracy: 0.6238 - val_loss: 6.3954 - val_accuracy: 0.3000\n",
            "Epoch 27/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7632 - accuracy: 0.7327 - val_loss: 3.1420 - val_accuracy: 0.5000\n",
            "Epoch 28/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0309 - accuracy: 0.7921 - val_loss: 2.0399 - val_accuracy: 0.6000\n",
            "Epoch 29/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6216 - accuracy: 0.7525 - val_loss: 1.9929 - val_accuracy: 0.5000\n",
            "Epoch 30/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8130 - accuracy: 0.8020 - val_loss: 2.8081 - val_accuracy: 0.5000\n",
            "Epoch 31/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.7239 - accuracy: 0.7545 - val_loss: 1.3808 - val_accuracy: 0.5000\n",
            "Epoch 32/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.7317 - accuracy: 0.7717 - val_loss: 1.6512 - val_accuracy: 0.5000\n",
            "Epoch 33/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.7293 - accuracy: 0.7636 - val_loss: 1.4221 - val_accuracy: 0.7000\n",
            "Epoch 34/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6816 - accuracy: 0.8218 - val_loss: 3.0062 - val_accuracy: 0.4000\n",
            "Epoch 35/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6359 - accuracy: 0.7723 - val_loss: 2.0181 - val_accuracy: 0.5000\n",
            "Epoch 36/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7193 - accuracy: 0.7228 - val_loss: 2.1825 - val_accuracy: 0.5000\n",
            "Epoch 37/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5716 - accuracy: 0.8218 - val_loss: 2.1989 - val_accuracy: 0.5000\n",
            "Epoch 38/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0938 - accuracy: 0.7525 - val_loss: 5.7350 - val_accuracy: 0.2000\n",
            "Epoch 39/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.4990 - accuracy: 0.7921 - val_loss: 14.4778 - val_accuracy: 0.2000\n",
            "Epoch 40/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.5731 - accuracy: 0.8091 - val_loss: 5.8930 - val_accuracy: 0.3000\n",
            "Epoch 41/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6558 - accuracy: 0.7723 - val_loss: 5.5513 - val_accuracy: 0.5000\n",
            "Epoch 42/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2100 - accuracy: 0.7624 - val_loss: 4.4415 - val_accuracy: 0.5000\n",
            "Epoch 43/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7746 - accuracy: 0.7030 - val_loss: 7.2093 - val_accuracy: 0.1000\n",
            "Epoch 44/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0422 - accuracy: 0.7624 - val_loss: 8.3547 - val_accuracy: 0.2000\n",
            "Epoch 45/150\n",
            "11/11 [==============================] - 1s 122ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.9054 - accuracy: 0.6630 - val_loss: 8.2725 - val_accuracy: 0.3000\n",
            "Epoch 46/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0680 - accuracy: 0.6040 - val_loss: 4.8713 - val_accuracy: 0.2000\n",
            "Epoch 47/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0011 - accuracy: 0.6818 - val_loss: 4.6376 - val_accuracy: 0.4000\n",
            "Epoch 48/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8721 - accuracy: 0.7228 - val_loss: 4.6066 - val_accuracy: 0.4000\n",
            "Epoch 49/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9926 - accuracy: 0.7030 - val_loss: 4.2032 - val_accuracy: 0.5000\n",
            "Epoch 50/150\n",
            "11/11 [==============================] - 1s 144ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6192 - accuracy: 0.7822 - val_loss: 6.7461 - val_accuracy: 0.4000\n",
            "Epoch 51/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5374 - accuracy: 0.7822 - val_loss: 6.9774 - val_accuracy: 0.3000\n",
            "Epoch 52/150\n",
            "11/11 [==============================] - 1s 143ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5907 - accuracy: 0.8317 - val_loss: 6.8130 - val_accuracy: 0.2000\n",
            "Epoch 53/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0620 - accuracy: 0.7228 - val_loss: 5.9149 - val_accuracy: 0.5000\n",
            "Epoch 54/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1427 - accuracy: 0.6733 - val_loss: 5.3410 - val_accuracy: 0.5000\n",
            "Epoch 55/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5429 - accuracy: 0.6535 - val_loss: 6.0238 - val_accuracy: 0.3000\n",
            "Epoch 56/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.6298 - accuracy: 0.7455 - val_loss: 13.1758 - val_accuracy: 0.2000\n",
            "Epoch 57/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8187 - accuracy: 0.7426 - val_loss: 10.7193 - val_accuracy: 0.2000\n",
            "Epoch 58/150\n",
            "11/11 [==============================] - 1s 118ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.5267 - accuracy: 0.8152 - val_loss: 4.3554 - val_accuracy: 0.3000\n",
            "Epoch 59/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.5547 - accuracy: 0.7455 - val_loss: 5.1167 - val_accuracy: 0.4000\n",
            "Epoch 60/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8386 - accuracy: 0.7624 - val_loss: 3.8150 - val_accuracy: 0.5000\n",
            "Epoch 61/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0281 - accuracy: 0.6832 - val_loss: 6.5355 - val_accuracy: 0.4000\n",
            "Epoch 62/150\n",
            "11/11 [==============================] - 2s 155ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.6273 - accuracy: 0.8182 - val_loss: 5.9043 - val_accuracy: 0.5000\n",
            "Epoch 63/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7245 - accuracy: 0.7030 - val_loss: 5.9358 - val_accuracy: 0.4000\n",
            "Epoch 64/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7531 - accuracy: 0.7327 - val_loss: 5.1231 - val_accuracy: 0.3000\n",
            "Epoch 65/150\n",
            "11/11 [==============================] - 1s 119ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.7374 - accuracy: 0.8261 - val_loss: 3.9213 - val_accuracy: 0.4000\n",
            "Epoch 66/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.9852 - accuracy: 0.6818 - val_loss: 4.5686 - val_accuracy: 0.5000\n",
            "Epoch 67/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0866 - accuracy: 0.7921 - val_loss: 4.9259 - val_accuracy: 0.5000\n",
            "Epoch 68/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.5962 - accuracy: 0.8043 - val_loss: 6.0943 - val_accuracy: 0.4000\n",
            "Epoch 69/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.6322 - accuracy: 0.7636 - val_loss: 5.6668 - val_accuracy: 0.5000\n",
            "Epoch 70/150\n",
            "11/11 [==============================] - 1s 125ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.5477 - accuracy: 0.8043 - val_loss: 6.6736 - val_accuracy: 0.4000\n",
            "Epoch 71/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.4955 - accuracy: 0.8182 - val_loss: 5.1664 - val_accuracy: 0.3000\n",
            "Epoch 72/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6084 - accuracy: 0.7822 - val_loss: 3.0029 - val_accuracy: 0.6000\n",
            "Epoch 73/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5425 - accuracy: 0.7921 - val_loss: 3.8441 - val_accuracy: 0.3000\n",
            "Epoch 74/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5791 - accuracy: 0.8614 - val_loss: 2.0386 - val_accuracy: 0.5000\n",
            "Epoch 75/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5018 - accuracy: 0.8218 - val_loss: 3.3340 - val_accuracy: 0.4000\n",
            "Epoch 76/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9143 - accuracy: 0.7921 - val_loss: 6.3545 - val_accuracy: 0.3000\n",
            "Epoch 77/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.9762 - accuracy: 0.7182 - val_loss: 7.4618 - val_accuracy: 0.2000\n",
            "Epoch 78/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7973 - accuracy: 0.7525 - val_loss: 5.7956 - val_accuracy: 0.3000\n",
            "Epoch 79/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0291 - accuracy: 0.7129 - val_loss: 8.1596 - val_accuracy: 0.3000\n",
            "Epoch 80/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0664 - accuracy: 0.6634 - val_loss: 7.5955 - val_accuracy: 0.4000\n",
            "Epoch 81/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8510 - accuracy: 0.7129 - val_loss: 9.7854 - val_accuracy: 0.3000\n",
            "Epoch 82/150\n",
            "11/11 [==============================] - 1s 130ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7394 - accuracy: 0.7030 - val_loss: 7.3500 - val_accuracy: 0.3000\n",
            "Epoch 83/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0402 - accuracy: 0.8119 - val_loss: 6.8668 - val_accuracy: 0.3000\n",
            "Epoch 84/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7156 - accuracy: 0.7822 - val_loss: 2.7339 - val_accuracy: 0.3000\n",
            "Epoch 85/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6766 - accuracy: 0.7525 - val_loss: 4.7440 - val_accuracy: 0.3000\n",
            "Epoch 86/150\n",
            "11/11 [==============================] - 1s 143ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6410 - accuracy: 0.8119 - val_loss: 3.2042 - val_accuracy: 0.5000\n",
            "Epoch 87/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.9702 - accuracy: 0.6931 - val_loss: 5.1293 - val_accuracy: 0.3000\n",
            "Epoch 88/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0721 - accuracy: 0.6634 - val_loss: 7.8670 - val_accuracy: 0.4000\n",
            "Epoch 89/150\n",
            "11/11 [==============================] - 2s 150ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.3762 - accuracy: 0.8455 - val_loss: 5.3355 - val_accuracy: 0.3000\n",
            "Epoch 90/150\n",
            "11/11 [==============================] - 1s 134ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5651 - accuracy: 0.8119 - val_loss: 5.7701 - val_accuracy: 0.4000\n",
            "Epoch 91/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6046 - accuracy: 0.7624 - val_loss: 3.6622 - val_accuracy: 0.5000\n",
            "Epoch 92/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5363 - accuracy: 0.8416 - val_loss: 5.4049 - val_accuracy: 0.3000\n",
            "Epoch 93/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0422 - accuracy: 0.8020 - val_loss: 8.7183 - val_accuracy: 0.2000\n",
            "Epoch 94/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.8833 - accuracy: 0.7723 - val_loss: 4.9226 - val_accuracy: 0.3000\n",
            "Epoch 95/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5587 - accuracy: 0.7391 - val_loss: 7.5777 - val_accuracy: 0.5000\n",
            "Epoch 96/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.8701 - accuracy: 0.7364 - val_loss: 6.9797 - val_accuracy: 0.3000\n",
            "Epoch 97/150\n",
            "11/11 [==============================] - 1s 131ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1047 - accuracy: 0.7525 - val_loss: 8.6212 - val_accuracy: 0.4000\n",
            "Epoch 98/150\n",
            "11/11 [==============================] - 2s 158ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.6380 - accuracy: 0.7636 - val_loss: 3.7542 - val_accuracy: 0.5000\n",
            "Epoch 99/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.4226 - accuracy: 0.8614 - val_loss: 5.0149 - val_accuracy: 0.3000\n",
            "Epoch 100/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 8.3636 - loss: 1.5481 - accuracy: 0.8587 - val_loss: 6.2002 - val_accuracy: 0.3000\n",
            "Epoch 101/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.4190 - accuracy: 0.6909 - val_loss: 4.1073 - val_accuracy: 0.4000\n",
            "Epoch 102/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.5697 - accuracy: 0.7500 - val_loss: 3.0863 - val_accuracy: 0.4000\n",
            "Epoch 103/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.3968 - accuracy: 0.8273 - val_loss: 10.2724 - val_accuracy: 0.3000\n",
            "Epoch 104/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1091 - accuracy: 0.7723 - val_loss: 2.4388 - val_accuracy: 0.3000\n",
            "Epoch 105/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.7386 - accuracy: 0.7327 - val_loss: 3.1942 - val_accuracy: 0.4000\n",
            "Epoch 106/150\n",
            "11/11 [==============================] - 2s 151ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.5261 - accuracy: 0.8317 - val_loss: 3.4381 - val_accuracy: 0.3000\n",
            "Epoch 107/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.2317 - accuracy: 0.8218 - val_loss: 4.6771 - val_accuracy: 0.5000\n",
            "Epoch 108/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0407 - accuracy: 0.8119 - val_loss: 3.2066 - val_accuracy: 0.5000\n",
            "Epoch 109/150\n",
            "11/11 [==============================] - 1s 143ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4754 - accuracy: 0.6634 - val_loss: 3.5497 - val_accuracy: 0.5000\n",
            "Epoch 110/150\n",
            "11/11 [==============================] - 2s 154ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.5650 - accuracy: 0.7525 - val_loss: 3.5582 - val_accuracy: 0.3000\n",
            "Epoch 111/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.5386 - accuracy: 0.6436 - val_loss: 14.6108 - val_accuracy: 0.5000\n",
            "Epoch 112/150\n",
            "11/11 [==============================] - 1s 141ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.9222 - accuracy: 0.6832 - val_loss: 72.4347 - val_accuracy: 0.3000\n",
            "Epoch 113/150\n",
            "11/11 [==============================] - 2s 145ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.7949 - accuracy: 0.7273 - val_loss: 113.6819 - val_accuracy: 0.4000\n",
            "Epoch 114/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 3.2435 - accuracy: 0.6139 - val_loss: 32.6412 - val_accuracy: 0.3000\n",
            "Epoch 115/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.1481 - accuracy: 0.7129 - val_loss: 39.9665 - val_accuracy: 0.3000\n",
            "Epoch 116/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.4061 - accuracy: 0.6436 - val_loss: 21.2197 - val_accuracy: 0.2000\n",
            "Epoch 117/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 8.3636 - loss: 2.5492 - accuracy: 0.5652 - val_loss: 4.9452 - val_accuracy: 0.3000\n",
            "Epoch 118/150\n",
            "11/11 [==============================] - 2s 147ms/step - batch: 5.0000 - size: 10.0000 - loss: 2.0198 - accuracy: 0.6455 - val_loss: 5.9283 - val_accuracy: 0.2000\n",
            "Epoch 119/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.0902 - accuracy: 0.6733 - val_loss: 4.5490 - val_accuracy: 0.3000\n",
            "Epoch 120/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.2778 - accuracy: 0.7822 - val_loss: 4.9499 - val_accuracy: 0.4000\n",
            "Epoch 121/150\n",
            "11/11 [==============================] - 1s 142ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.8368 - accuracy: 0.7030 - val_loss: 19.9803 - val_accuracy: 0.2000\n",
            "Epoch 122/150\n",
            "11/11 [==============================] - 2s 164ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.3115 - accuracy: 0.7364 - val_loss: 18.6281 - val_accuracy: 0.3000\n",
            "Epoch 123/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 8.3636 - loss: 2.2600 - accuracy: 0.6848 - val_loss: 43.8956 - val_accuracy: 0.2000\n",
            "Epoch 124/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.3853 - accuracy: 0.7129 - val_loss: 9.4916 - val_accuracy: 0.2000\n",
            "Epoch 125/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.1294 - accuracy: 0.6931 - val_loss: 20.2962 - val_accuracy: 0.5000\n",
            "Epoch 126/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.5689 - accuracy: 0.6636 - val_loss: 23.9343 - val_accuracy: 0.3000\n",
            "Epoch 127/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.9743 - accuracy: 0.5941 - val_loss: 2.2289 - val_accuracy: 0.5000\n",
            "Epoch 128/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 3.0252 - accuracy: 0.6535 - val_loss: 25.7753 - val_accuracy: 0.2000\n",
            "Epoch 129/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.3779 - accuracy: 0.6238 - val_loss: 6.6981 - val_accuracy: 0.5000\n",
            "Epoch 130/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.8590 - accuracy: 0.5743 - val_loss: 8.5500 - val_accuracy: 0.2000\n",
            "Epoch 131/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.4746 - accuracy: 0.6832 - val_loss: 14.4830 - val_accuracy: 0.1000\n",
            "Epoch 132/150\n",
            "11/11 [==============================] - 1s 135ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.3982 - accuracy: 0.6535 - val_loss: 10.5266 - val_accuracy: 0.1000\n",
            "Epoch 133/150\n",
            "11/11 [==============================] - 1s 139ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.6702 - accuracy: 0.6832 - val_loss: 8.3924 - val_accuracy: 0.5000\n",
            "Epoch 134/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.4497 - accuracy: 0.7624 - val_loss: 24.5492 - val_accuracy: 0.3000\n",
            "Epoch 135/150\n",
            "11/11 [==============================] - 1s 140ms/step - batch: 5.0000 - size: 9.1818 - loss: 3.4618 - accuracy: 0.6337 - val_loss: 31.5404 - val_accuracy: 0.6000\n",
            "Epoch 136/150\n",
            "11/11 [==============================] - 1s 137ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.1844 - accuracy: 0.6832 - val_loss: 32.8849 - val_accuracy: 0.2000\n",
            "Epoch 137/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.0993 - accuracy: 0.7273 - val_loss: 53.4504 - val_accuracy: 0.1000\n",
            "Epoch 138/150\n",
            "11/11 [==============================] - 1s 128ms/step - batch: 5.0000 - size: 8.3636 - loss: 2.7971 - accuracy: 0.6413 - val_loss: 22.7233 - val_accuracy: 0.3000\n",
            "Epoch 139/150\n",
            "11/11 [==============================] - 2s 151ms/step - batch: 5.0000 - size: 10.0000 - loss: 2.3914 - accuracy: 0.6909 - val_loss: 50.0346 - val_accuracy: 0.3000\n",
            "Epoch 140/150\n",
            "11/11 [==============================] - 1s 127ms/step - batch: 5.0000 - size: 8.3636 - loss: 2.0247 - accuracy: 0.6304 - val_loss: 37.1262 - val_accuracy: 0.5000\n",
            "Epoch 141/150\n",
            "11/11 [==============================] - 2s 149ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.4426 - accuracy: 0.7455 - val_loss: 53.9472 - val_accuracy: 0.1000\n",
            "Epoch 142/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.4338 - accuracy: 0.6535 - val_loss: 71.7526 - val_accuracy: 0.1000\n",
            "Epoch 143/150\n",
            "11/11 [==============================] - 1s 138ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.0689 - accuracy: 0.7525 - val_loss: 58.5173 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/150\n",
            "11/11 [==============================] - 1s 132ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3847 - accuracy: 0.7129 - val_loss: 13.3172 - val_accuracy: 0.2000\n",
            "Epoch 145/150\n",
            "11/11 [==============================] - 1s 133ms/step - batch: 5.0000 - size: 9.1818 - loss: 1.3095 - accuracy: 0.7030 - val_loss: 5.9231 - val_accuracy: 0.2000\n",
            "Epoch 146/150\n",
            "11/11 [==============================] - 2s 151ms/step - batch: 5.0000 - size: 9.1818 - loss: 0.6308 - accuracy: 0.7723 - val_loss: 6.9721 - val_accuracy: 0.2000\n",
            "Epoch 147/150\n",
            "11/11 [==============================] - 1s 136ms/step - batch: 5.0000 - size: 9.1818 - loss: 2.0982 - accuracy: 0.7426 - val_loss: 4.5644 - val_accuracy: 0.4000\n",
            "Epoch 148/150\n",
            "11/11 [==============================] - 2s 148ms/step - batch: 5.0000 - size: 10.0000 - loss: 1.2264 - accuracy: 0.7273 - val_loss: 4.0340 - val_accuracy: 0.5000\n",
            "Epoch 149/150\n",
            "11/11 [==============================] - 1s 129ms/step - batch: 5.0000 - size: 8.3636 - loss: 0.8855 - accuracy: 0.7935 - val_loss: 5.6602 - val_accuracy: 0.4000\n",
            "Epoch 150/150\n",
            "11/11 [==============================] - 2s 146ms/step - batch: 5.0000 - size: 10.0000 - loss: 0.6164 - accuracy: 0.8364 - val_loss: 5.5119 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhT3-Be8t-Sm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}