{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast Cancer Attention Based(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nupursjsu/Advanced-Deep-Learning/blob/master/Project/Breast_Cancer_Attention_Based(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4HWMps35Chu",
        "outputId": "d8d9051a-27cb-415e-97e3-95deb40d2473"
      },
      "source": [
        "!pip install -U scipy==1.2.0\n",
        "from scipy.misc import imsave"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 68.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.18.5)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrbP0RTqY--O",
        "outputId": "ddc77c7f-c228-4724-93a0-4a711aaff52c"
      },
      "source": [
        "!gdown --id 1kLevdRmyykFfaiUt0A3uSFCRog-mOWSJ"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kLevdRmyykFfaiUt0A3uSFCRog-mOWSJ\n",
            "To: /content/combined.zip\n",
            "4.21GB [01:02, 67.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBYGZZTHZl8w"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/combined.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/combined')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHKqZzeRa1ab",
        "outputId": "69bfe001-9254-4649-914d-96cb348550ca"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 23 01:42:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJOwZXW1c1uo",
        "outputId": "75adea89-41b1-4417-97ef-92d41b09a3ac"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 18.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9llx4V9XUJH"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "from tqdm.autonotebook import tqdm\n",
        "# dir structure would be: data/class_name(0 and 1)/dir_containing_img/img\n",
        "class PatchMethod(torch.utils.data.Dataset):\n",
        "    def __init__(self, root = 'Desktop/screenshots/', mode = 'train', transform = None):\n",
        "        self.root = root\n",
        "        self.mode = mode\n",
        "        self.raw_samples = glob.glob(root + '/*/*')\n",
        "        # print(self.raw_samples)\n",
        "        self.samples = []\n",
        "        for raw_sample in self.raw_samples:\n",
        "            self.samples.append((raw_sample, int(raw_sample.split('/')[-2])))\n",
        "            # print(raw_sample,int(raw_sample.split('/')[-2]))\n",
        "        # print(self.samples)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'train':\n",
        "            random.shuffle(self.samples)\n",
        "            \n",
        "        image_dir, label = self.samples[index]\n",
        "        images = glob.glob(image_dir)\n",
        "        # images = glob.glob(image_dir + '/*')\n",
        "        \n",
        "        t = transforms.Compose([transforms.CenterCrop((448,700))]) #centercropping to 1200 to generate 9 400x400 patches\n",
        "        \n",
        "        transformations = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "        array = []\n",
        "        \n",
        "        for i, image_path in enumerate(images):\n",
        "            # print(image_path)\n",
        "            image = Image.open(image_path)\n",
        "            image = np.array(t(image))\n",
        "            # print(image.shape)\n",
        "            # image = np.array(image)\n",
        "            r, c, _ = image.shape\n",
        "            # print(\"image.shape\",image.shape)\n",
        "            for i in range(0,28*16,28):\n",
        "                for j in range(0,28*25,28):\n",
        "                    array.append(transformations(image[i:i+28, j:j+28, :]))\n",
        "#                     array.append(transformations(image[i:i+400, j:j+400, :]).float())\n",
        "#                     array.append(image[i:i+400, j:j+400, :])\n",
        "                    # if (i+400 < r) and (j+400 < c):\n",
        "                        # array.append(transformations(image[i:i+400, j:j+400, :]).float())\n",
        "                        # array.append(image[i:i+400, j:j+400, :])\n",
        "                    \n",
        "                    \n",
        "        array = tuple(array)\n",
        "        # print(\"################### array ###################\")\n",
        "        # print(array)\n",
        "        array = torch.stack(array, 0)\n",
        "        \n",
        "        return (array, label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3ADeJ3LapiS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.L = 500\n",
        "        self.D = 128\n",
        "        self.K = 1\n",
        "        self.feature_extractor_part1 = nn.Sequential(\n",
        "            \n",
        "            # torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "            nn.Conv2d(3, 20, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(20, 50, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.feature_extractor_part2 = nn.Sequential(\n",
        "            nn.Linear(50 * 4 * 4, self.L),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.L, self.D),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.D, self.K)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L*self.K, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('in forward')\n",
        "        # print('========================')\n",
        "        # print(x.shape)\n",
        "        x = x.squeeze(0)\n",
        "        # print(x.shape)\n",
        "        # print('========================')\n",
        "        # print(x)\n",
        "        H = self.feature_extractor_part1(x)\n",
        "        H = H.view(-1, 50 * 4 * 4)\n",
        "        H = self.feature_extractor_part2(H)  # NxL\n",
        "\n",
        "        A = self.attention(H)  # NxK\n",
        "        A = torch.transpose(A, 1, 0)  # KxN\n",
        "        A = F.softmax(A, dim=1)  # softmax over N\n",
        "\n",
        "        M = torch.mm(A, H)  # KxL\n",
        "\n",
        "        Y_prob = self.classifier(M)\n",
        "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
        "\n",
        "        return Y_prob, Y_hat, A\n",
        "\n",
        "    # AUXILIARY METHODS\n",
        "    def calculate_classification_error(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        _, Y_hat, _ = self.forward(X)\n",
        "        # error = 1. - Y_hat.eq(Y).cpu().float().mean().data[0]\n",
        "        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n",
        "\n",
        "        return error, Y_hat\n",
        "\n",
        "    def calculate_objective(self, X, Y):\n",
        "        Y = Y.float()\n",
        "        # print(X,Y)\n",
        "        Y_prob, _, A = self.forward(X)\n",
        "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
        "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n",
        "\n",
        "        return neg_log_likelihood, A"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDakyGtNY9Zy"
      },
      "source": [
        "data_path_train='/content/combined/combined/train'\n",
        "data_path_test='/content/combined/combined/test'\n",
        "data = PatchMethod(root = data_path_train)\n",
        "val_data = PatchMethod(root = data_path_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NURcvOY9cpeo"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "# from scipy.misc import imsave\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# from dataloader import MnistBags\n",
        "# from amil_model import Attention\n",
        "\n",
        "# from __future__ import print_function, division\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "import argparse"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XXODk2yaMwB"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(data, shuffle = True, batch_size = 1\n",
        "                                )\n",
        "test_loader = torch.utils.data.DataLoader(val_data, shuffle = False, num_workers = 6, batch_size = 1)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, shuffle = False, num_workers = 6, batch_size = 1)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDy8PYsae2p"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Attention().to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QqWHZKbcHbi"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), weight_decay=10e-5)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSjxw83WcZpX"
      },
      "source": [
        "def train(epoch):\n",
        "    # progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=256)\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    train_loss = 0.\n",
        "    train_error = 0.\n",
        "    correct_label_pred = 0\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        \n",
        "        \n",
        "        bag_label = label[0]\n",
        "        data, bag_label = data.cuda(), bag_label.cuda()\n",
        "        data, bag_label = Variable(data), Variable(bag_label)\n",
        "        data = data.squeeze(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # calculate loss and metrics\n",
        "        \n",
        "        loss, _ = model.calculate_objective(data, bag_label)\n",
        "        train_loss += loss.data[0]\n",
        "        error, predicted_label_train = model.calculate_classification_error(data, bag_label)\n",
        "        # print(\"bag_label,predicted_label_train\",bag_label,predicted_label_train)\n",
        "        # print(int(bag_label) == int(predicted_label_train))\n",
        "        correct_label_pred += (int(bag_label) == int(predicted_label_train))\n",
        "        # exit()\n",
        "        train_error += error\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # step\n",
        "        optimizer.step()\n",
        "        # print(correct_label_pred)\n",
        "        # print(len(train_loader))\n",
        "        # print(batch_idx)\n",
        "      \n",
        "    # calculate loss and error for epoch\n",
        "    train_loss /= len(train_loader)\n",
        "    train_error /= len(train_loader)\n",
        "    train_acc = (1 - train_error)*100\n",
        "\n",
        "    writer.add_scalar('data/train_acc', train_acc, epoch)\n",
        "    writer.add_scalar('data/train_error', train_error, epoch)\n",
        "    writer.add_scalar('data/train_loss', train_loss, epoch)\n",
        "\n",
        "    result_train = 'Epoch: {}, Loss: {:.4f}, Train error: {:.4f}, Train accuracy: {:.2f}'.format(epoch, train_loss.cpu().numpy()[0], train_error, train_acc)\n",
        "\n",
        "    print(result_train)\n",
        "    return result_train\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0.\n",
        "    test_error = 0.\n",
        "    for batch_idx, (data, label) in enumerate(test_loader):\n",
        "        # print(label)\n",
        "        # print((data[0].shape))\n",
        "\n",
        "        bag_label = label[0]\n",
        "        instance_labels = label[0]\n",
        "        data, bag_label = data.cuda(), bag_label.cuda()\n",
        "        data, bag_label = Variable(data), Variable(bag_label)\n",
        "        loss, attention_weights = model.calculate_objective(data, bag_label)\n",
        "        test_loss += loss.data[0]\n",
        "        error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
        "        test_error += error\n",
        "\n",
        "        visualization_attention(data[0],attention_weights[0],batch_idx,epoch)\n",
        "        if batch_idx < 1:  # plot bag labels and instance labels for first 5 bags\n",
        "            bag_level = (bag_label.cpu().data.numpy(), int(predicted_label.cpu().data.numpy()))\n",
        "            # print(bag_level)\n",
        "            # print(instance_labels)\n",
        "            # visualization_attention(data[0],attention_weights[0],batch_idx,epoch)\n",
        "            # print(\"attention_weights.shape\",attention_weights.shape)\n",
        "            # instance_level = list(zip(instance_labels.numpy().tolist(),\n",
        "            #                      np.round(attention_weights.cpu().data.numpy(), decimals=3).tolist()))\n",
        "\n",
        "            # print('\\nTrue Bag Label, Predicted Bag Label: {}\\n'\n",
        "            #       'True Instance Labels, Attention Weights: {}'.format(bag_level, instance_level))\n",
        "\n",
        "    test_error /= len(test_loader)\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = (1 - test_error)*100    \n",
        "\n",
        "    writer.add_scalar('data/test_acc', test_acc, epoch)\n",
        "    writer.add_scalar('data/test_error', test_error, epoch)\n",
        "    writer.add_scalar('data/test_loss', test_loss, epoch)\n",
        "    result_test = 'Epoch: {}, Loss: {:.4f}, test error: {:.4f}, test accuracy: {:.2f}'.format(epoch, test_loss.cpu().numpy()[0], test_error, test_acc)\n",
        "    print(result_test)\n",
        "    return result_test\n",
        "    # print('Test Set, Loss: {:.4f}, Test error: {:.4f}'.format(test_loss.cpu().numpy()[0], test_error))\n",
        "\n",
        "def visualization_attention(data,attention_weights,batch_idx,epoch):\n",
        "    img_save_dir = './AMIL_visualization/epoch_{}'.format(epoch)\n",
        "    img_save_name = img_save_dir + '/test_epoch_{}_no_{}.png'.format(epoch,batch_idx)\n",
        "    if not os.path.exists(img_save_dir):\n",
        "        os.makedirs(img_save_dir)\n",
        "\n",
        "    data = data.cpu().data.numpy()\n",
        "    attention_weights = attention_weights.cpu().data.numpy()\n",
        "    # print(\"data.shape\",data.shape)\n",
        "    # print(\"attention_weights\",attention_weights.shape)\n",
        "    attention_weights = attention_weights/np.max(attention_weights)\n",
        "    complete_image=np.zeros((3,480,700))\n",
        "    for height_no in range(16):\n",
        "        for width_no in range(25):\n",
        "            complete_image[:,height_no*28:height_no*28+28, width_no*28:width_no*28+28] = data[height_no*25+width_no,:,:,:] * attention_weights[height_no*25+width_no]\n",
        "    complete_image = complete_image.transpose((1,2,0))\n",
        "    imsave(img_save_name,complete_image)\n",
        "    # weighted_images_list = data * attention_weights\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76eXSZrCdYks",
        "outputId": "3915e7b2-019d-4b98-adc0-acc6ce82b8cf"
      },
      "source": [
        "save_name_txt = \"save_string.txt\"\n",
        "writer = SummaryWriter()\n",
        "model_file = open(save_name_txt,\"w\") \n",
        "for epoch in range(1, 5 + 1):\n",
        "        print('----------Start Training----------')\n",
        "        train_result = train(epoch)\n",
        "        print('----------Start Testing----------')\n",
        "        test_result = test(epoch)\n",
        "        model_file.write(test_result + '\\n')\n",
        "        model_file.write(train_result + '\\n')\n",
        "model_file.close()\n",
        "torch.save(model.state_dict(),\"AMIL_Breakthis_state_dict.pt\")\n",
        "torch.save(model ,\"AMIL_Breakthis_model.pt\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Start Training----------\n",
            "Epoch: 1, Loss: 4.3904, Train error: 0.3882, Train accuracy: 61.18\n",
            "----------Start Testing----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 7.8903, test error: 0.6854, test accuracy: 31.46\n",
            "----------Start Training----------\n",
            "Epoch: 2, Loss: 7.8744, Train error: 0.6840, Train accuracy: 31.60\n",
            "----------Start Testing----------\n",
            "Epoch: 2, Loss: 7.9198, test error: 0.6880, test accuracy: 31.20\n",
            "----------Start Training----------\n",
            "Epoch: 3, Loss: 5.4338, Train error: 0.4763, Train accuracy: 52.37\n",
            "----------Start Testing----------\n",
            "Epoch: 3, Loss: 3.5849, test error: 0.3114, test accuracy: 68.86\n",
            "----------Start Training----------\n",
            "Epoch: 4, Loss: 1.4049, Train error: 0.3139, Train accuracy: 68.61\n",
            "----------Start Testing----------\n",
            "Epoch: 4, Loss: 0.6363, test error: 0.3318, test accuracy: 66.82\n",
            "----------Start Training----------\n",
            "Epoch: 5, Loss: 3.6044, Train error: 0.3623, Train accuracy: 63.77\n",
            "----------Start Testing----------\n",
            "Epoch: 5, Loss: 7.9198, test error: 0.6880, test accuracy: 31.20\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}