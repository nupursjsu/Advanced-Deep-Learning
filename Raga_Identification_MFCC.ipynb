{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raga_Identification_MFCC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZAmVO1Yg9MPpURIyP55nl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nupursjsu/Advanced-Deep-Learning/blob/master/Raga_Identification_MFCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deQNon6dA1GJ"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isTK4Lu0NLsc",
        "outputId": "e60644cc-4175-4101-81e2-63b2b8693c23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iPYVypEOM_-"
      },
      "source": [
        "#Some important commands\n",
        "\n",
        "# !gdown --id 1OwgxRgeH2sqVB4-szobd16ClItJtyFo2\n",
        "\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/RagaDatasetNew.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/processed')\n",
        "\n",
        "# !find . -name \".DS_Store\" -delete\n",
        "\n",
        "# !rm -rf /content/processed/__MACOSX"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsX0KJLEA3oo"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Raga_Data/data_10.json\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV6h1VUuA7Fm"
      },
      "source": [
        "def load_data(data_path):\n",
        "    \"\"\"Loads training dataset from json file.\n",
        "\n",
        "        :param data_path (str): Path to json file containing data\n",
        "        :return X (ndarray): Inputs\n",
        "        :return y (ndarray): Targets\n",
        "    \"\"\"\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"mfcc\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qL_Uf1DA9Gf"
      },
      "source": [
        "def plot_history(history):\n",
        "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
        "\n",
        "        :param history: Training history of model\n",
        "        :return:\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMJbjaYlA_uI"
      },
      "source": [
        "def prepare_datasets(test_size, validation_size):\n",
        "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
        "\n",
        "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
        "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
        "\n",
        "    :return X_train (ndarray): Input training set\n",
        "    :return X_validation (ndarray): Input validation set\n",
        "    :return X_test (ndarray): Input test set\n",
        "    :return y_train (ndarray): Target training set\n",
        "    :return y_validation (ndarray): Target validation set\n",
        "    :return y_test (ndarray): Target test set\n",
        "    \"\"\"\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(DATA_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBNoSzm2BGoV"
      },
      "source": [
        "def build_model(input_shape):\n",
        "    \"\"\"Generates RNN-LSTM model\n",
        "\n",
        "    :param input_shape (tuple): Shape of input set\n",
        "    :return model: RNN-LSTM model\n",
        "    \"\"\"\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 2 LSTM layers\n",
        "    model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(keras.layers.GRU(64))\n",
        "\n",
        "    # dense layer\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbETc1A6BLsG",
        "outputId": "0a65ba9b-d866-4c1d-a3cd-a9b555033697"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # get train, validation, test splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2]) # 130, 13\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=800)\n",
        "\n",
        "    # plot accuracy/error for training and validation\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 130, 64)           19968     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 49,413\n",
            "Trainable params: 49,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/800\n",
            "27/27 [==============================] - 33s 52ms/step - loss: 1.6561 - accuracy: 0.1664 - val_loss: 1.5712 - val_accuracy: 0.2727\n",
            "Epoch 2/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5998 - accuracy: 0.2738 - val_loss: 1.5337 - val_accuracy: 0.3732\n",
            "Epoch 3/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5788 - accuracy: 0.2868 - val_loss: 1.5191 - val_accuracy: 0.3971\n",
            "Epoch 4/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5706 - accuracy: 0.3183 - val_loss: 1.5048 - val_accuracy: 0.3971\n",
            "Epoch 5/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5664 - accuracy: 0.3214 - val_loss: 1.4991 - val_accuracy: 0.3971\n",
            "Epoch 6/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5213 - accuracy: 0.3705 - val_loss: 1.4930 - val_accuracy: 0.3971\n",
            "Epoch 7/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5431 - accuracy: 0.3300 - val_loss: 1.4895 - val_accuracy: 0.3923\n",
            "Epoch 8/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5413 - accuracy: 0.3261 - val_loss: 1.4864 - val_accuracy: 0.3923\n",
            "Epoch 9/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5222 - accuracy: 0.3316 - val_loss: 1.4879 - val_accuracy: 0.3923\n",
            "Epoch 10/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5342 - accuracy: 0.3350 - val_loss: 1.4866 - val_accuracy: 0.4019\n",
            "Epoch 11/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5152 - accuracy: 0.3380 - val_loss: 1.4865 - val_accuracy: 0.4019\n",
            "Epoch 12/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5112 - accuracy: 0.3430 - val_loss: 1.4795 - val_accuracy: 0.3971\n",
            "Epoch 13/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5225 - accuracy: 0.3366 - val_loss: 1.4779 - val_accuracy: 0.3971\n",
            "Epoch 14/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.4949 - accuracy: 0.3704 - val_loss: 1.4738 - val_accuracy: 0.3923\n",
            "Epoch 15/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.5001 - accuracy: 0.3356 - val_loss: 1.4719 - val_accuracy: 0.3971\n",
            "Epoch 16/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.5138 - accuracy: 0.3345 - val_loss: 1.4704 - val_accuracy: 0.3971\n",
            "Epoch 17/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4887 - accuracy: 0.3459 - val_loss: 1.4679 - val_accuracy: 0.3923\n",
            "Epoch 18/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4795 - accuracy: 0.3616 - val_loss: 1.4684 - val_accuracy: 0.3971\n",
            "Epoch 19/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4915 - accuracy: 0.3553 - val_loss: 1.4625 - val_accuracy: 0.3971\n",
            "Epoch 20/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.4604 - accuracy: 0.3633 - val_loss: 1.4598 - val_accuracy: 0.3923\n",
            "Epoch 21/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4538 - accuracy: 0.3870 - val_loss: 1.4600 - val_accuracy: 0.4019\n",
            "Epoch 22/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4533 - accuracy: 0.3691 - val_loss: 1.4588 - val_accuracy: 0.3971\n",
            "Epoch 23/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.4250 - accuracy: 0.4043 - val_loss: 1.4538 - val_accuracy: 0.3923\n",
            "Epoch 24/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4452 - accuracy: 0.3842 - val_loss: 1.4526 - val_accuracy: 0.4067\n",
            "Epoch 25/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4331 - accuracy: 0.3744 - val_loss: 1.4539 - val_accuracy: 0.4258\n",
            "Epoch 26/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4080 - accuracy: 0.4250 - val_loss: 1.4458 - val_accuracy: 0.4211\n",
            "Epoch 27/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4113 - accuracy: 0.3928 - val_loss: 1.4411 - val_accuracy: 0.4354\n",
            "Epoch 28/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.4588 - accuracy: 0.3606 - val_loss: 1.4368 - val_accuracy: 0.4306\n",
            "Epoch 29/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.4378 - accuracy: 0.3697 - val_loss: 1.4346 - val_accuracy: 0.4306\n",
            "Epoch 30/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3995 - accuracy: 0.4150 - val_loss: 1.4229 - val_accuracy: 0.4258\n",
            "Epoch 31/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.3978 - accuracy: 0.4112 - val_loss: 1.4199 - val_accuracy: 0.4450\n",
            "Epoch 32/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3911 - accuracy: 0.4179 - val_loss: 1.4137 - val_accuracy: 0.4450\n",
            "Epoch 33/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3753 - accuracy: 0.4315 - val_loss: 1.4106 - val_accuracy: 0.4545\n",
            "Epoch 34/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.3824 - accuracy: 0.4099 - val_loss: 1.4099 - val_accuracy: 0.4641\n",
            "Epoch 35/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3646 - accuracy: 0.4339 - val_loss: 1.4141 - val_accuracy: 0.4689\n",
            "Epoch 36/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3476 - accuracy: 0.4471 - val_loss: 1.4098 - val_accuracy: 0.4641\n",
            "Epoch 37/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.3471 - accuracy: 0.4658 - val_loss: 1.4001 - val_accuracy: 0.4833\n",
            "Epoch 38/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.3498 - accuracy: 0.4426 - val_loss: 1.3951 - val_accuracy: 0.4785\n",
            "Epoch 39/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.3412 - accuracy: 0.4353 - val_loss: 1.3889 - val_accuracy: 0.5024\n",
            "Epoch 40/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.3010 - accuracy: 0.4650 - val_loss: 1.3832 - val_accuracy: 0.4976\n",
            "Epoch 41/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2774 - accuracy: 0.5098 - val_loss: 1.3767 - val_accuracy: 0.4880\n",
            "Epoch 42/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2978 - accuracy: 0.4691 - val_loss: 1.3751 - val_accuracy: 0.4976\n",
            "Epoch 43/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.2941 - accuracy: 0.4936 - val_loss: 1.3785 - val_accuracy: 0.4880\n",
            "Epoch 44/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2775 - accuracy: 0.4706 - val_loss: 1.3789 - val_accuracy: 0.4785\n",
            "Epoch 45/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2761 - accuracy: 0.4921 - val_loss: 1.3693 - val_accuracy: 0.4928\n",
            "Epoch 46/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.2728 - accuracy: 0.5135 - val_loss: 1.3713 - val_accuracy: 0.4880\n",
            "Epoch 47/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2503 - accuracy: 0.5050 - val_loss: 1.3656 - val_accuracy: 0.4785\n",
            "Epoch 48/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2295 - accuracy: 0.5148 - val_loss: 1.3628 - val_accuracy: 0.4833\n",
            "Epoch 49/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2327 - accuracy: 0.5168 - val_loss: 1.3620 - val_accuracy: 0.5024\n",
            "Epoch 50/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2645 - accuracy: 0.5207 - val_loss: 1.3546 - val_accuracy: 0.4928\n",
            "Epoch 51/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.2105 - accuracy: 0.5382 - val_loss: 1.3585 - val_accuracy: 0.4737\n",
            "Epoch 52/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.2087 - accuracy: 0.5243 - val_loss: 1.3570 - val_accuracy: 0.4785\n",
            "Epoch 53/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.2301 - accuracy: 0.5237 - val_loss: 1.3546 - val_accuracy: 0.4976\n",
            "Epoch 54/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.1998 - accuracy: 0.5408 - val_loss: 1.3542 - val_accuracy: 0.4880\n",
            "Epoch 55/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1972 - accuracy: 0.5363 - val_loss: 1.3436 - val_accuracy: 0.4928\n",
            "Epoch 56/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1686 - accuracy: 0.5394 - val_loss: 1.3426 - val_accuracy: 0.4976\n",
            "Epoch 57/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1635 - accuracy: 0.5469 - val_loss: 1.3449 - val_accuracy: 0.4880\n",
            "Epoch 58/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1849 - accuracy: 0.5037 - val_loss: 1.3487 - val_accuracy: 0.4833\n",
            "Epoch 59/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.1302 - accuracy: 0.5798 - val_loss: 1.3455 - val_accuracy: 0.4593\n",
            "Epoch 60/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.1398 - accuracy: 0.5583 - val_loss: 1.3389 - val_accuracy: 0.4976\n",
            "Epoch 61/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1216 - accuracy: 0.5691 - val_loss: 1.3433 - val_accuracy: 0.4593\n",
            "Epoch 62/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1087 - accuracy: 0.5976 - val_loss: 1.3444 - val_accuracy: 0.4641\n",
            "Epoch 63/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0928 - accuracy: 0.5969 - val_loss: 1.3373 - val_accuracy: 0.4689\n",
            "Epoch 64/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.1112 - accuracy: 0.5596 - val_loss: 1.3432 - val_accuracy: 0.4641\n",
            "Epoch 65/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0631 - accuracy: 0.5817 - val_loss: 1.3426 - val_accuracy: 0.4641\n",
            "Epoch 66/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0685 - accuracy: 0.5866 - val_loss: 1.3407 - val_accuracy: 0.4785\n",
            "Epoch 67/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0127 - accuracy: 0.6232 - val_loss: 1.3433 - val_accuracy: 0.4641\n",
            "Epoch 68/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0327 - accuracy: 0.5974 - val_loss: 1.3410 - val_accuracy: 0.4689\n",
            "Epoch 69/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0747 - accuracy: 0.5931 - val_loss: 1.3393 - val_accuracy: 0.4737\n",
            "Epoch 70/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9767 - accuracy: 0.6604 - val_loss: 1.3410 - val_accuracy: 0.4737\n",
            "Epoch 71/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0131 - accuracy: 0.5982 - val_loss: 1.3400 - val_accuracy: 0.4641\n",
            "Epoch 72/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 1.0039 - accuracy: 0.6262 - val_loss: 1.3592 - val_accuracy: 0.4593\n",
            "Epoch 73/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.9845 - accuracy: 0.6404 - val_loss: 1.3512 - val_accuracy: 0.4641\n",
            "Epoch 74/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 1.0144 - accuracy: 0.6508 - val_loss: 1.3628 - val_accuracy: 0.4402\n",
            "Epoch 75/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9359 - accuracy: 0.6309 - val_loss: 1.3545 - val_accuracy: 0.4545\n",
            "Epoch 76/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9350 - accuracy: 0.6524 - val_loss: 1.3462 - val_accuracy: 0.4450\n",
            "Epoch 77/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9643 - accuracy: 0.6395 - val_loss: 1.3497 - val_accuracy: 0.4545\n",
            "Epoch 78/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9122 - accuracy: 0.6516 - val_loss: 1.3461 - val_accuracy: 0.4737\n",
            "Epoch 79/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9091 - accuracy: 0.6584 - val_loss: 1.3515 - val_accuracy: 0.4545\n",
            "Epoch 80/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.9001 - accuracy: 0.6526 - val_loss: 1.3662 - val_accuracy: 0.4545\n",
            "Epoch 81/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.8914 - accuracy: 0.6784 - val_loss: 1.3568 - val_accuracy: 0.4689\n",
            "Epoch 82/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8966 - accuracy: 0.6674 - val_loss: 1.3734 - val_accuracy: 0.4498\n",
            "Epoch 83/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.9181 - accuracy: 0.6630 - val_loss: 1.3628 - val_accuracy: 0.4593\n",
            "Epoch 84/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8878 - accuracy: 0.6673 - val_loss: 1.3940 - val_accuracy: 0.4306\n",
            "Epoch 85/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.9187 - accuracy: 0.6465 - val_loss: 1.3708 - val_accuracy: 0.4737\n",
            "Epoch 86/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8817 - accuracy: 0.6690 - val_loss: 1.3762 - val_accuracy: 0.4593\n",
            "Epoch 87/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8270 - accuracy: 0.6855 - val_loss: 1.3747 - val_accuracy: 0.4641\n",
            "Epoch 88/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.8427 - accuracy: 0.6771 - val_loss: 1.3666 - val_accuracy: 0.4737\n",
            "Epoch 89/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8560 - accuracy: 0.6894 - val_loss: 1.3602 - val_accuracy: 0.4737\n",
            "Epoch 90/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8358 - accuracy: 0.7035 - val_loss: 1.3777 - val_accuracy: 0.4689\n",
            "Epoch 91/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.8216 - accuracy: 0.6821 - val_loss: 1.3625 - val_accuracy: 0.4976\n",
            "Epoch 92/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.8573 - accuracy: 0.6689 - val_loss: 1.3981 - val_accuracy: 0.4737\n",
            "Epoch 93/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8295 - accuracy: 0.6805 - val_loss: 1.3672 - val_accuracy: 0.4641\n",
            "Epoch 94/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8475 - accuracy: 0.6891 - val_loss: 1.3832 - val_accuracy: 0.4737\n",
            "Epoch 95/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7520 - accuracy: 0.7072 - val_loss: 1.3765 - val_accuracy: 0.4689\n",
            "Epoch 96/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.8119 - accuracy: 0.6930 - val_loss: 1.3923 - val_accuracy: 0.4785\n",
            "Epoch 97/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.7966 - accuracy: 0.7111 - val_loss: 1.3710 - val_accuracy: 0.4833\n",
            "Epoch 98/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7543 - accuracy: 0.7329 - val_loss: 1.3901 - val_accuracy: 0.4880\n",
            "Epoch 99/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.7312 - accuracy: 0.7454 - val_loss: 1.3954 - val_accuracy: 0.4689\n",
            "Epoch 100/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7720 - accuracy: 0.7238 - val_loss: 1.4231 - val_accuracy: 0.4976\n",
            "Epoch 101/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7463 - accuracy: 0.7422 - val_loss: 1.4224 - val_accuracy: 0.4833\n",
            "Epoch 102/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7199 - accuracy: 0.7525 - val_loss: 1.4045 - val_accuracy: 0.4833\n",
            "Epoch 103/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6908 - accuracy: 0.7449 - val_loss: 1.4141 - val_accuracy: 0.4928\n",
            "Epoch 104/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.7001 - accuracy: 0.7522 - val_loss: 1.4080 - val_accuracy: 0.4785\n",
            "Epoch 105/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6559 - accuracy: 0.7710 - val_loss: 1.4154 - val_accuracy: 0.4737\n",
            "Epoch 106/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.6973 - accuracy: 0.7762 - val_loss: 1.4121 - val_accuracy: 0.4785\n",
            "Epoch 107/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.7687 - val_loss: 1.4240 - val_accuracy: 0.4928\n",
            "Epoch 108/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6989 - accuracy: 0.7410 - val_loss: 1.4080 - val_accuracy: 0.5120\n",
            "Epoch 109/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.6321 - accuracy: 0.7645 - val_loss: 1.4097 - val_accuracy: 0.4880\n",
            "Epoch 110/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6437 - accuracy: 0.7771 - val_loss: 1.4303 - val_accuracy: 0.4785\n",
            "Epoch 111/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6488 - accuracy: 0.7514 - val_loss: 1.4160 - val_accuracy: 0.4928\n",
            "Epoch 112/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6926 - accuracy: 0.7442 - val_loss: 1.4306 - val_accuracy: 0.4833\n",
            "Epoch 113/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.7756 - val_loss: 1.4435 - val_accuracy: 0.4880\n",
            "Epoch 114/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6758 - accuracy: 0.7468 - val_loss: 1.4336 - val_accuracy: 0.5024\n",
            "Epoch 115/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6872 - accuracy: 0.7411 - val_loss: 1.4280 - val_accuracy: 0.4928\n",
            "Epoch 116/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6701 - accuracy: 0.7540 - val_loss: 1.4704 - val_accuracy: 0.4976\n",
            "Epoch 117/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6216 - accuracy: 0.8000 - val_loss: 1.4385 - val_accuracy: 0.5120\n",
            "Epoch 118/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5659 - accuracy: 0.8042 - val_loss: 1.4468 - val_accuracy: 0.5024\n",
            "Epoch 119/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6127 - accuracy: 0.7964 - val_loss: 1.4363 - val_accuracy: 0.5120\n",
            "Epoch 120/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.6335 - accuracy: 0.7583 - val_loss: 1.4509 - val_accuracy: 0.5072\n",
            "Epoch 121/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5785 - accuracy: 0.7940 - val_loss: 1.4693 - val_accuracy: 0.5167\n",
            "Epoch 122/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5566 - accuracy: 0.8209 - val_loss: 1.4783 - val_accuracy: 0.5024\n",
            "Epoch 123/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5581 - accuracy: 0.7993 - val_loss: 1.4679 - val_accuracy: 0.5215\n",
            "Epoch 124/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5461 - accuracy: 0.8146 - val_loss: 1.4424 - val_accuracy: 0.5263\n",
            "Epoch 125/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5858 - accuracy: 0.8101 - val_loss: 1.4675 - val_accuracy: 0.5359\n",
            "Epoch 126/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5852 - accuracy: 0.7929 - val_loss: 1.4803 - val_accuracy: 0.5263\n",
            "Epoch 127/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.5371 - accuracy: 0.8244 - val_loss: 1.5057 - val_accuracy: 0.5167\n",
            "Epoch 128/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5658 - accuracy: 0.8132 - val_loss: 1.5061 - val_accuracy: 0.5215\n",
            "Epoch 129/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5382 - accuracy: 0.8055 - val_loss: 1.5097 - val_accuracy: 0.5120\n",
            "Epoch 130/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5521 - accuracy: 0.8102 - val_loss: 1.4975 - val_accuracy: 0.5072\n",
            "Epoch 131/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5005 - accuracy: 0.8301 - val_loss: 1.5234 - val_accuracy: 0.5263\n",
            "Epoch 132/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5092 - accuracy: 0.8160 - val_loss: 1.5308 - val_accuracy: 0.5072\n",
            "Epoch 133/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4942 - accuracy: 0.8416 - val_loss: 1.5238 - val_accuracy: 0.5311\n",
            "Epoch 134/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4868 - accuracy: 0.8447 - val_loss: 1.5515 - val_accuracy: 0.5120\n",
            "Epoch 135/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4899 - accuracy: 0.8147 - val_loss: 1.5591 - val_accuracy: 0.5215\n",
            "Epoch 136/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5291 - accuracy: 0.8279 - val_loss: 1.5524 - val_accuracy: 0.5311\n",
            "Epoch 137/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4906 - accuracy: 0.8265 - val_loss: 1.5413 - val_accuracy: 0.5311\n",
            "Epoch 138/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4704 - accuracy: 0.8489 - val_loss: 1.5602 - val_accuracy: 0.5167\n",
            "Epoch 139/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4727 - accuracy: 0.8462 - val_loss: 1.5658 - val_accuracy: 0.5263\n",
            "Epoch 140/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4247 - accuracy: 0.8693 - val_loss: 1.5771 - val_accuracy: 0.5359\n",
            "Epoch 141/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4843 - accuracy: 0.8103 - val_loss: 1.5915 - val_accuracy: 0.5311\n",
            "Epoch 142/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4571 - accuracy: 0.8534 - val_loss: 1.5815 - val_accuracy: 0.5263\n",
            "Epoch 143/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4329 - accuracy: 0.8595 - val_loss: 1.5924 - val_accuracy: 0.5311\n",
            "Epoch 144/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.8434 - val_loss: 1.6009 - val_accuracy: 0.5215\n",
            "Epoch 145/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.8515 - val_loss: 1.5995 - val_accuracy: 0.5311\n",
            "Epoch 146/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8652 - val_loss: 1.6234 - val_accuracy: 0.5215\n",
            "Epoch 147/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8791 - val_loss: 1.6395 - val_accuracy: 0.5311\n",
            "Epoch 148/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4770 - accuracy: 0.8365 - val_loss: 1.5641 - val_accuracy: 0.5455\n",
            "Epoch 149/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4502 - accuracy: 0.8680 - val_loss: 1.5708 - val_accuracy: 0.5263\n",
            "Epoch 150/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.8552 - val_loss: 1.5780 - val_accuracy: 0.5311\n",
            "Epoch 151/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4333 - accuracy: 0.8582 - val_loss: 1.5901 - val_accuracy: 0.5407\n",
            "Epoch 152/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4435 - accuracy: 0.8539 - val_loss: 1.6077 - val_accuracy: 0.5263\n",
            "Epoch 153/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8789 - val_loss: 1.6146 - val_accuracy: 0.5120\n",
            "Epoch 154/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8882 - val_loss: 1.6511 - val_accuracy: 0.5359\n",
            "Epoch 155/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3545 - accuracy: 0.8841 - val_loss: 1.6627 - val_accuracy: 0.5502\n",
            "Epoch 156/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3446 - accuracy: 0.8950 - val_loss: 1.6709 - val_accuracy: 0.5263\n",
            "Epoch 157/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3467 - accuracy: 0.8885 - val_loss: 1.6874 - val_accuracy: 0.5311\n",
            "Epoch 158/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.8969 - val_loss: 1.7013 - val_accuracy: 0.5407\n",
            "Epoch 159/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3600 - accuracy: 0.8855 - val_loss: 1.7095 - val_accuracy: 0.5072\n",
            "Epoch 160/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3298 - accuracy: 0.8975 - val_loss: 1.7160 - val_accuracy: 0.5215\n",
            "Epoch 161/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.3931 - accuracy: 0.8645 - val_loss: 1.7166 - val_accuracy: 0.5311\n",
            "Epoch 162/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3537 - accuracy: 0.8805 - val_loss: 1.7504 - val_accuracy: 0.5263\n",
            "Epoch 163/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3719 - accuracy: 0.8765 - val_loss: 1.7486 - val_accuracy: 0.5359\n",
            "Epoch 164/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3235 - accuracy: 0.8983 - val_loss: 1.7495 - val_accuracy: 0.5359\n",
            "Epoch 165/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3743 - accuracy: 0.8614 - val_loss: 1.7096 - val_accuracy: 0.5167\n",
            "Epoch 166/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8836 - val_loss: 1.7448 - val_accuracy: 0.5407\n",
            "Epoch 167/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.3187 - accuracy: 0.8828 - val_loss: 1.7617 - val_accuracy: 0.5455\n",
            "Epoch 168/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2735 - accuracy: 0.9179 - val_loss: 1.7706 - val_accuracy: 0.5263\n",
            "Epoch 169/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.8879 - val_loss: 1.7769 - val_accuracy: 0.5215\n",
            "Epoch 170/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 0.8986 - val_loss: 1.7969 - val_accuracy: 0.5359\n",
            "Epoch 171/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3257 - accuracy: 0.8917 - val_loss: 1.8011 - val_accuracy: 0.5359\n",
            "Epoch 172/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3191 - accuracy: 0.9019 - val_loss: 1.8075 - val_accuracy: 0.5311\n",
            "Epoch 173/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3342 - accuracy: 0.9060 - val_loss: 1.8182 - val_accuracy: 0.5263\n",
            "Epoch 174/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.9079 - val_loss: 1.8265 - val_accuracy: 0.5167\n",
            "Epoch 175/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2567 - accuracy: 0.9252 - val_loss: 1.8527 - val_accuracy: 0.5263\n",
            "Epoch 176/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.8833 - val_loss: 1.7897 - val_accuracy: 0.5167\n",
            "Epoch 177/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3433 - accuracy: 0.8829 - val_loss: 1.8009 - val_accuracy: 0.5359\n",
            "Epoch 178/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2648 - accuracy: 0.9142 - val_loss: 1.8317 - val_accuracy: 0.5263\n",
            "Epoch 179/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.2590 - accuracy: 0.9120 - val_loss: 1.8615 - val_accuracy: 0.5215\n",
            "Epoch 180/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3200 - accuracy: 0.9068 - val_loss: 1.8486 - val_accuracy: 0.5215\n",
            "Epoch 181/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2645 - accuracy: 0.9203 - val_loss: 1.8667 - val_accuracy: 0.5263\n",
            "Epoch 182/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2523 - accuracy: 0.9235 - val_loss: 1.8920 - val_accuracy: 0.5167\n",
            "Epoch 183/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2651 - accuracy: 0.9154 - val_loss: 1.9115 - val_accuracy: 0.5120\n",
            "Epoch 184/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2488 - accuracy: 0.9163 - val_loss: 1.9344 - val_accuracy: 0.5215\n",
            "Epoch 185/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2340 - accuracy: 0.9317 - val_loss: 1.9773 - val_accuracy: 0.5120\n",
            "Epoch 186/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2206 - accuracy: 0.9309 - val_loss: 1.9631 - val_accuracy: 0.5311\n",
            "Epoch 187/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2691 - accuracy: 0.9146 - val_loss: 1.9303 - val_accuracy: 0.5215\n",
            "Epoch 188/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2420 - accuracy: 0.9246 - val_loss: 1.9759 - val_accuracy: 0.5215\n",
            "Epoch 189/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.2718 - accuracy: 0.9234 - val_loss: 2.0138 - val_accuracy: 0.5311\n",
            "Epoch 190/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2166 - accuracy: 0.9380 - val_loss: 2.0291 - val_accuracy: 0.5120\n",
            "Epoch 191/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2278 - accuracy: 0.9263 - val_loss: 2.0637 - val_accuracy: 0.5359\n",
            "Epoch 192/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2087 - accuracy: 0.9340 - val_loss: 2.0668 - val_accuracy: 0.5215\n",
            "Epoch 193/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2289 - accuracy: 0.9203 - val_loss: 2.0586 - val_accuracy: 0.5167\n",
            "Epoch 194/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2079 - accuracy: 0.9273 - val_loss: 2.0403 - val_accuracy: 0.5359\n",
            "Epoch 195/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2100 - accuracy: 0.9382 - val_loss: 2.0576 - val_accuracy: 0.5311\n",
            "Epoch 196/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2424 - accuracy: 0.9088 - val_loss: 2.0860 - val_accuracy: 0.5311\n",
            "Epoch 197/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1989 - accuracy: 0.9465 - val_loss: 2.1025 - val_accuracy: 0.5359\n",
            "Epoch 198/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2797 - accuracy: 0.9058 - val_loss: 2.1435 - val_accuracy: 0.4976\n",
            "Epoch 199/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9193 - val_loss: 2.0851 - val_accuracy: 0.5215\n",
            "Epoch 200/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3205 - accuracy: 0.9009 - val_loss: 2.0319 - val_accuracy: 0.5502\n",
            "Epoch 201/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.2282 - accuracy: 0.9280 - val_loss: 2.1071 - val_accuracy: 0.5263\n",
            "Epoch 202/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2294 - accuracy: 0.9301 - val_loss: 2.1064 - val_accuracy: 0.5263\n",
            "Epoch 203/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2227 - accuracy: 0.9246 - val_loss: 2.1037 - val_accuracy: 0.5167\n",
            "Epoch 204/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.1851 - accuracy: 0.9457 - val_loss: 2.1246 - val_accuracy: 0.5263\n",
            "Epoch 205/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1815 - accuracy: 0.9563 - val_loss: 2.1524 - val_accuracy: 0.5215\n",
            "Epoch 206/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1743 - accuracy: 0.9423 - val_loss: 2.1652 - val_accuracy: 0.5167\n",
            "Epoch 207/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1907 - accuracy: 0.9440 - val_loss: 2.2030 - val_accuracy: 0.5263\n",
            "Epoch 208/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1733 - accuracy: 0.9491 - val_loss: 2.2685 - val_accuracy: 0.5263\n",
            "Epoch 209/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1941 - accuracy: 0.9331 - val_loss: 2.2182 - val_accuracy: 0.5263\n",
            "Epoch 210/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9501 - val_loss: 2.2464 - val_accuracy: 0.5215\n",
            "Epoch 211/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1635 - accuracy: 0.9512 - val_loss: 2.2374 - val_accuracy: 0.5024\n",
            "Epoch 212/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.9411 - val_loss: 2.3339 - val_accuracy: 0.5167\n",
            "Epoch 213/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 0.9495 - val_loss: 2.2761 - val_accuracy: 0.5359\n",
            "Epoch 214/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.2034 - accuracy: 0.9269 - val_loss: 2.2521 - val_accuracy: 0.5359\n",
            "Epoch 215/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2072 - accuracy: 0.9395 - val_loss: 2.2598 - val_accuracy: 0.5215\n",
            "Epoch 216/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2025 - accuracy: 0.9409 - val_loss: 2.2349 - val_accuracy: 0.5407\n",
            "Epoch 217/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.1452 - accuracy: 0.9512 - val_loss: 2.2474 - val_accuracy: 0.5455\n",
            "Epoch 218/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1740 - accuracy: 0.9459 - val_loss: 2.2591 - val_accuracy: 0.5263\n",
            "Epoch 219/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2999 - accuracy: 0.9186 - val_loss: 2.3141 - val_accuracy: 0.5215\n",
            "Epoch 220/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9429 - val_loss: 2.2508 - val_accuracy: 0.5167\n",
            "Epoch 221/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2154 - accuracy: 0.9288 - val_loss: 2.2602 - val_accuracy: 0.5120\n",
            "Epoch 222/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.9374 - val_loss: 2.2601 - val_accuracy: 0.5215\n",
            "Epoch 223/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1575 - accuracy: 0.9550 - val_loss: 2.2827 - val_accuracy: 0.5311\n",
            "Epoch 224/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9649 - val_loss: 2.3004 - val_accuracy: 0.5311\n",
            "Epoch 225/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1467 - accuracy: 0.9610 - val_loss: 2.2898 - val_accuracy: 0.5359\n",
            "Epoch 226/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1530 - accuracy: 0.9572 - val_loss: 2.2759 - val_accuracy: 0.5311\n",
            "Epoch 227/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1511 - accuracy: 0.9516 - val_loss: 2.2565 - val_accuracy: 0.5407\n",
            "Epoch 228/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1489 - accuracy: 0.9608 - val_loss: 2.3146 - val_accuracy: 0.5407\n",
            "Epoch 229/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1385 - accuracy: 0.9551 - val_loss: 2.2855 - val_accuracy: 0.5359\n",
            "Epoch 230/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1230 - accuracy: 0.9663 - val_loss: 2.3077 - val_accuracy: 0.5311\n",
            "Epoch 231/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9558 - val_loss: 2.3251 - val_accuracy: 0.5455\n",
            "Epoch 232/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1569 - accuracy: 0.9563 - val_loss: 2.3696 - val_accuracy: 0.5407\n",
            "Epoch 233/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.1491 - accuracy: 0.9559 - val_loss: 2.3909 - val_accuracy: 0.5311\n",
            "Epoch 234/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9584 - val_loss: 2.4041 - val_accuracy: 0.5407\n",
            "Epoch 235/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1408 - accuracy: 0.9582 - val_loss: 2.3966 - val_accuracy: 0.5407\n",
            "Epoch 236/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1429 - accuracy: 0.9659 - val_loss: 2.4667 - val_accuracy: 0.5263\n",
            "Epoch 237/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1524 - accuracy: 0.9509 - val_loss: 2.4177 - val_accuracy: 0.5263\n",
            "Epoch 238/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1344 - accuracy: 0.9599 - val_loss: 2.5054 - val_accuracy: 0.5167\n",
            "Epoch 239/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2043 - accuracy: 0.9393 - val_loss: 2.4399 - val_accuracy: 0.5359\n",
            "Epoch 240/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1924 - accuracy: 0.9340 - val_loss: 2.3677 - val_accuracy: 0.5311\n",
            "Epoch 241/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1441 - accuracy: 0.9570 - val_loss: 2.4050 - val_accuracy: 0.5455\n",
            "Epoch 242/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1263 - accuracy: 0.9634 - val_loss: 2.4183 - val_accuracy: 0.5455\n",
            "Epoch 243/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.9559 - val_loss: 2.4565 - val_accuracy: 0.5407\n",
            "Epoch 244/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1137 - accuracy: 0.9738 - val_loss: 2.5043 - val_accuracy: 0.5359\n",
            "Epoch 245/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1217 - accuracy: 0.9632 - val_loss: 2.4875 - val_accuracy: 0.5311\n",
            "Epoch 246/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1420 - accuracy: 0.9617 - val_loss: 2.5125 - val_accuracy: 0.5407\n",
            "Epoch 247/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9754 - val_loss: 2.5045 - val_accuracy: 0.5167\n",
            "Epoch 248/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1414 - accuracy: 0.9611 - val_loss: 2.5280 - val_accuracy: 0.5455\n",
            "Epoch 249/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1254 - accuracy: 0.9585 - val_loss: 2.4925 - val_accuracy: 0.5502\n",
            "Epoch 250/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.9455 - val_loss: 2.4946 - val_accuracy: 0.5502\n",
            "Epoch 251/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0978 - accuracy: 0.9743 - val_loss: 2.5068 - val_accuracy: 0.5550\n",
            "Epoch 252/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0976 - accuracy: 0.9717 - val_loss: 2.5459 - val_accuracy: 0.5455\n",
            "Epoch 253/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9759 - val_loss: 2.5586 - val_accuracy: 0.5455\n",
            "Epoch 254/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0942 - accuracy: 0.9699 - val_loss: 2.5591 - val_accuracy: 0.5646\n",
            "Epoch 255/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 2.5837 - val_accuracy: 0.5455\n",
            "Epoch 256/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1206 - accuracy: 0.9648 - val_loss: 2.5832 - val_accuracy: 0.5359\n",
            "Epoch 257/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1132 - accuracy: 0.9689 - val_loss: 2.5797 - val_accuracy: 0.5455\n",
            "Epoch 258/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0900 - accuracy: 0.9761 - val_loss: 2.6327 - val_accuracy: 0.5502\n",
            "Epoch 259/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1135 - accuracy: 0.9660 - val_loss: 2.6647 - val_accuracy: 0.5455\n",
            "Epoch 260/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1293 - accuracy: 0.9635 - val_loss: 2.7025 - val_accuracy: 0.5455\n",
            "Epoch 261/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1176 - accuracy: 0.9659 - val_loss: 2.7531 - val_accuracy: 0.5215\n",
            "Epoch 262/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1101 - accuracy: 0.9674 - val_loss: 2.7871 - val_accuracy: 0.5167\n",
            "Epoch 263/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1039 - accuracy: 0.9657 - val_loss: 2.7722 - val_accuracy: 0.5311\n",
            "Epoch 264/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1116 - accuracy: 0.9659 - val_loss: 2.7671 - val_accuracy: 0.5263\n",
            "Epoch 265/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9726 - val_loss: 2.7987 - val_accuracy: 0.5311\n",
            "Epoch 266/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9729 - val_loss: 2.7811 - val_accuracy: 0.5311\n",
            "Epoch 267/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 0.9627 - val_loss: 2.8726 - val_accuracy: 0.5359\n",
            "Epoch 268/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1422 - accuracy: 0.9565 - val_loss: 2.8522 - val_accuracy: 0.5311\n",
            "Epoch 269/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1479 - accuracy: 0.9544 - val_loss: 2.6393 - val_accuracy: 0.5502\n",
            "Epoch 270/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9580 - val_loss: 2.6873 - val_accuracy: 0.5311\n",
            "Epoch 271/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0932 - accuracy: 0.9819 - val_loss: 2.9064 - val_accuracy: 0.5167\n",
            "Epoch 272/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 2.6162 - val_accuracy: 0.5598\n",
            "Epoch 273/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 0.9584 - val_loss: 2.5897 - val_accuracy: 0.5407\n",
            "Epoch 274/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9719 - val_loss: 2.6740 - val_accuracy: 0.5407\n",
            "Epoch 275/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0876 - accuracy: 0.9760 - val_loss: 2.7045 - val_accuracy: 0.5407\n",
            "Epoch 276/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1158 - accuracy: 0.9688 - val_loss: 2.7650 - val_accuracy: 0.5215\n",
            "Epoch 277/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0990 - accuracy: 0.9677 - val_loss: 2.8359 - val_accuracy: 0.5311\n",
            "Epoch 278/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1017 - accuracy: 0.9661 - val_loss: 2.7279 - val_accuracy: 0.5263\n",
            "Epoch 279/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0959 - accuracy: 0.9685 - val_loss: 2.8979 - val_accuracy: 0.5263\n",
            "Epoch 280/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1489 - accuracy: 0.9580 - val_loss: 2.7938 - val_accuracy: 0.5167\n",
            "Epoch 281/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0973 - accuracy: 0.9590 - val_loss: 2.7952 - val_accuracy: 0.5311\n",
            "Epoch 282/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9796 - val_loss: 2.7923 - val_accuracy: 0.5359\n",
            "Epoch 283/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0749 - accuracy: 0.9774 - val_loss: 2.7798 - val_accuracy: 0.5359\n",
            "Epoch 284/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.9806 - val_loss: 2.8288 - val_accuracy: 0.5407\n",
            "Epoch 285/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 2.8417 - val_accuracy: 0.5407\n",
            "Epoch 286/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0650 - accuracy: 0.9853 - val_loss: 2.9081 - val_accuracy: 0.5359\n",
            "Epoch 287/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0576 - accuracy: 0.9889 - val_loss: 2.9111 - val_accuracy: 0.5311\n",
            "Epoch 288/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0729 - accuracy: 0.9796 - val_loss: 2.9350 - val_accuracy: 0.5263\n",
            "Epoch 289/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0791 - accuracy: 0.9797 - val_loss: 2.9095 - val_accuracy: 0.5263\n",
            "Epoch 290/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0853 - accuracy: 0.9718 - val_loss: 2.9852 - val_accuracy: 0.5167\n",
            "Epoch 291/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0658 - accuracy: 0.9730 - val_loss: 2.9737 - val_accuracy: 0.5407\n",
            "Epoch 292/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0821 - accuracy: 0.9711 - val_loss: 2.8247 - val_accuracy: 0.5694\n",
            "Epoch 293/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0996 - accuracy: 0.9704 - val_loss: 3.0230 - val_accuracy: 0.5311\n",
            "Epoch 294/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1416 - accuracy: 0.9615 - val_loss: 2.9618 - val_accuracy: 0.5167\n",
            "Epoch 295/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1093 - accuracy: 0.9542 - val_loss: 3.0832 - val_accuracy: 0.4833\n",
            "Epoch 296/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1498 - accuracy: 0.9495 - val_loss: 2.9293 - val_accuracy: 0.5407\n",
            "Epoch 297/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9789 - val_loss: 2.9030 - val_accuracy: 0.5407\n",
            "Epoch 298/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9676 - val_loss: 2.8037 - val_accuracy: 0.5311\n",
            "Epoch 299/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1029 - accuracy: 0.9751 - val_loss: 2.8718 - val_accuracy: 0.5407\n",
            "Epoch 300/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1003 - accuracy: 0.9793 - val_loss: 2.9252 - val_accuracy: 0.5311\n",
            "Epoch 301/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0643 - accuracy: 0.9882 - val_loss: 2.9283 - val_accuracy: 0.5502\n",
            "Epoch 302/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0660 - accuracy: 0.9809 - val_loss: 2.9523 - val_accuracy: 0.5598\n",
            "Epoch 303/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9854 - val_loss: 2.9863 - val_accuracy: 0.5455\n",
            "Epoch 304/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9894 - val_loss: 3.0079 - val_accuracy: 0.5455\n",
            "Epoch 305/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0603 - accuracy: 0.9871 - val_loss: 3.0204 - val_accuracy: 0.5359\n",
            "Epoch 306/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 3.0268 - val_accuracy: 0.5455\n",
            "Epoch 307/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0557 - accuracy: 0.9880 - val_loss: 3.0463 - val_accuracy: 0.5311\n",
            "Epoch 308/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 3.0713 - val_accuracy: 0.5167\n",
            "Epoch 309/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0504 - accuracy: 0.9868 - val_loss: 3.0730 - val_accuracy: 0.5311\n",
            "Epoch 310/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0608 - accuracy: 0.9778 - val_loss: 3.1228 - val_accuracy: 0.5167\n",
            "Epoch 311/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0596 - accuracy: 0.9875 - val_loss: 3.1659 - val_accuracy: 0.4976\n",
            "Epoch 312/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 3.2999 - val_accuracy: 0.5024\n",
            "Epoch 313/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9895 - val_loss: 3.1868 - val_accuracy: 0.4976\n",
            "Epoch 314/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0565 - accuracy: 0.9893 - val_loss: 3.2377 - val_accuracy: 0.5072\n",
            "Epoch 315/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0522 - accuracy: 0.9900 - val_loss: 3.1904 - val_accuracy: 0.5215\n",
            "Epoch 316/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0474 - accuracy: 0.9903 - val_loss: 3.2005 - val_accuracy: 0.5215\n",
            "Epoch 317/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0463 - accuracy: 0.9906 - val_loss: 3.2666 - val_accuracy: 0.5072\n",
            "Epoch 318/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0598 - accuracy: 0.9817 - val_loss: 3.2314 - val_accuracy: 0.5407\n",
            "Epoch 319/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1255 - accuracy: 0.9645 - val_loss: 3.2476 - val_accuracy: 0.5215\n",
            "Epoch 320/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0995 - accuracy: 0.9719 - val_loss: 3.2234 - val_accuracy: 0.4928\n",
            "Epoch 321/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9790 - val_loss: 3.1169 - val_accuracy: 0.5072\n",
            "Epoch 322/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9917 - val_loss: 2.9175 - val_accuracy: 0.5263\n",
            "Epoch 323/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9894 - val_loss: 3.1168 - val_accuracy: 0.5120\n",
            "Epoch 324/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 3.1116 - val_accuracy: 0.5167\n",
            "Epoch 325/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0612 - accuracy: 0.9834 - val_loss: 3.0308 - val_accuracy: 0.5359\n",
            "Epoch 326/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0361 - accuracy: 0.9918 - val_loss: 3.2114 - val_accuracy: 0.5167\n",
            "Epoch 327/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0439 - accuracy: 0.9880 - val_loss: 3.1703 - val_accuracy: 0.5215\n",
            "Epoch 328/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 3.1944 - val_accuracy: 0.5120\n",
            "Epoch 329/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 3.1848 - val_accuracy: 0.5263\n",
            "Epoch 330/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 3.2360 - val_accuracy: 0.5311\n",
            "Epoch 331/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0341 - accuracy: 0.9939 - val_loss: 3.2383 - val_accuracy: 0.5120\n",
            "Epoch 332/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 3.2649 - val_accuracy: 0.5215\n",
            "Epoch 333/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9948 - val_loss: 3.3284 - val_accuracy: 0.5263\n",
            "Epoch 334/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0442 - accuracy: 0.9910 - val_loss: 3.2869 - val_accuracy: 0.5215\n",
            "Epoch 335/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 3.3211 - val_accuracy: 0.5167\n",
            "Epoch 336/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0371 - accuracy: 0.9928 - val_loss: 3.4288 - val_accuracy: 0.5072\n",
            "Epoch 337/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 3.3902 - val_accuracy: 0.5167\n",
            "Epoch 338/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0384 - accuracy: 0.9932 - val_loss: 3.3562 - val_accuracy: 0.5120\n",
            "Epoch 339/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 3.4075 - val_accuracy: 0.5120\n",
            "Epoch 340/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0416 - accuracy: 0.9898 - val_loss: 3.4042 - val_accuracy: 0.5167\n",
            "Epoch 341/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0382 - accuracy: 0.9908 - val_loss: 3.3587 - val_accuracy: 0.5215\n",
            "Epoch 342/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0311 - accuracy: 0.9936 - val_loss: 3.4792 - val_accuracy: 0.5024\n",
            "Epoch 343/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9930 - val_loss: 3.3679 - val_accuracy: 0.5311\n",
            "Epoch 344/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0384 - accuracy: 0.9918 - val_loss: 3.3601 - val_accuracy: 0.5407\n",
            "Epoch 345/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 3.4755 - val_accuracy: 0.5072\n",
            "Epoch 346/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9863 - val_loss: 3.4491 - val_accuracy: 0.5263\n",
            "Epoch 347/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9697 - val_loss: 3.2541 - val_accuracy: 0.4880\n",
            "Epoch 348/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7034 - accuracy: 0.8300 - val_loss: 3.1569 - val_accuracy: 0.5311\n",
            "Epoch 349/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.7188 - accuracy: 0.8212 - val_loss: 3.0714 - val_accuracy: 0.4976\n",
            "Epoch 350/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.8627 - val_loss: 2.9900 - val_accuracy: 0.4928\n",
            "Epoch 351/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.3222 - accuracy: 0.8976 - val_loss: 2.8332 - val_accuracy: 0.5263\n",
            "Epoch 352/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.2139 - accuracy: 0.9316 - val_loss: 2.8755 - val_accuracy: 0.5263\n",
            "Epoch 353/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9567 - val_loss: 2.9289 - val_accuracy: 0.5024\n",
            "Epoch 354/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0959 - accuracy: 0.9683 - val_loss: 2.9172 - val_accuracy: 0.5120\n",
            "Epoch 355/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0623 - accuracy: 0.9886 - val_loss: 2.9326 - val_accuracy: 0.5263\n",
            "Epoch 356/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0725 - accuracy: 0.9843 - val_loss: 2.9475 - val_accuracy: 0.5263\n",
            "Epoch 357/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0656 - accuracy: 0.9829 - val_loss: 3.0052 - val_accuracy: 0.5167\n",
            "Epoch 358/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0479 - accuracy: 0.9929 - val_loss: 3.0116 - val_accuracy: 0.5311\n",
            "Epoch 359/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0485 - accuracy: 0.9877 - val_loss: 3.0299 - val_accuracy: 0.5311\n",
            "Epoch 360/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 0.9943 - val_loss: 3.0513 - val_accuracy: 0.5263\n",
            "Epoch 361/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 0.9924 - val_loss: 3.0760 - val_accuracy: 0.5215\n",
            "Epoch 362/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0488 - accuracy: 0.9911 - val_loss: 3.0910 - val_accuracy: 0.5263\n",
            "Epoch 363/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0407 - accuracy: 0.9928 - val_loss: 3.0954 - val_accuracy: 0.5311\n",
            "Epoch 364/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0410 - accuracy: 0.9910 - val_loss: 3.1264 - val_accuracy: 0.5311\n",
            "Epoch 365/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0419 - accuracy: 0.9953 - val_loss: 3.1225 - val_accuracy: 0.5311\n",
            "Epoch 366/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0344 - accuracy: 0.9932 - val_loss: 3.1552 - val_accuracy: 0.5215\n",
            "Epoch 367/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0494 - accuracy: 0.9926 - val_loss: 3.1868 - val_accuracy: 0.5263\n",
            "Epoch 368/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0341 - accuracy: 0.9951 - val_loss: 3.1921 - val_accuracy: 0.5359\n",
            "Epoch 369/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9944 - val_loss: 3.2170 - val_accuracy: 0.5359\n",
            "Epoch 370/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0332 - accuracy: 0.9932 - val_loss: 3.2178 - val_accuracy: 0.5359\n",
            "Epoch 371/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0380 - accuracy: 0.9936 - val_loss: 3.2362 - val_accuracy: 0.5407\n",
            "Epoch 372/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9955 - val_loss: 3.2490 - val_accuracy: 0.5407\n",
            "Epoch 373/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 3.2742 - val_accuracy: 0.5359\n",
            "Epoch 374/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0560 - accuracy: 0.9857 - val_loss: 3.2151 - val_accuracy: 0.5407\n",
            "Epoch 375/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0547 - accuracy: 0.9894 - val_loss: 3.2720 - val_accuracy: 0.5263\n",
            "Epoch 376/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.9833 - val_loss: 3.2039 - val_accuracy: 0.5550\n",
            "Epoch 377/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1218 - accuracy: 0.9621 - val_loss: 3.2682 - val_accuracy: 0.5072\n",
            "Epoch 378/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0629 - accuracy: 0.9870 - val_loss: 3.1938 - val_accuracy: 0.5407\n",
            "Epoch 379/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1013 - accuracy: 0.9881 - val_loss: 3.1674 - val_accuracy: 0.5311\n",
            "Epoch 380/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0973 - accuracy: 0.9852 - val_loss: 3.2795 - val_accuracy: 0.5120\n",
            "Epoch 381/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1265 - accuracy: 0.9667 - val_loss: 3.1021 - val_accuracy: 0.5167\n",
            "Epoch 382/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0914 - accuracy: 0.9730 - val_loss: 3.0971 - val_accuracy: 0.5215\n",
            "Epoch 383/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0711 - accuracy: 0.9858 - val_loss: 3.1247 - val_accuracy: 0.5120\n",
            "Epoch 384/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0821 - accuracy: 0.9794 - val_loss: 3.1273 - val_accuracy: 0.5263\n",
            "Epoch 385/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0582 - accuracy: 0.9862 - val_loss: 3.1387 - val_accuracy: 0.5167\n",
            "Epoch 386/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.9855 - val_loss: 3.1629 - val_accuracy: 0.5167\n",
            "Epoch 387/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0624 - accuracy: 0.9888 - val_loss: 3.1803 - val_accuracy: 0.5120\n",
            "Epoch 388/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0702 - accuracy: 0.9862 - val_loss: 3.1916 - val_accuracy: 0.5167\n",
            "Epoch 389/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0448 - accuracy: 0.9900 - val_loss: 3.1924 - val_accuracy: 0.5167\n",
            "Epoch 390/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0585 - accuracy: 0.9860 - val_loss: 3.1761 - val_accuracy: 0.5359\n",
            "Epoch 391/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0599 - accuracy: 0.9861 - val_loss: 3.2026 - val_accuracy: 0.5215\n",
            "Epoch 392/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 0.9821 - val_loss: 3.1868 - val_accuracy: 0.5502\n",
            "Epoch 393/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0706 - accuracy: 0.9865 - val_loss: 3.2507 - val_accuracy: 0.5215\n",
            "Epoch 394/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0775 - accuracy: 0.9823 - val_loss: 3.2515 - val_accuracy: 0.5455\n",
            "Epoch 395/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0546 - accuracy: 0.9899 - val_loss: 3.2793 - val_accuracy: 0.5263\n",
            "Epoch 396/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9918 - val_loss: 3.3001 - val_accuracy: 0.5263\n",
            "Epoch 397/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0505 - accuracy: 0.9897 - val_loss: 3.3024 - val_accuracy: 0.5311\n",
            "Epoch 398/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0457 - accuracy: 0.9888 - val_loss: 3.3154 - val_accuracy: 0.5263\n",
            "Epoch 399/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9961 - val_loss: 3.3065 - val_accuracy: 0.5311\n",
            "Epoch 400/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0460 - accuracy: 0.9917 - val_loss: 3.3346 - val_accuracy: 0.5311\n",
            "Epoch 401/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0358 - accuracy: 0.9930 - val_loss: 3.3543 - val_accuracy: 0.5215\n",
            "Epoch 402/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0323 - accuracy: 0.9925 - val_loss: 3.3858 - val_accuracy: 0.5215\n",
            "Epoch 403/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0453 - accuracy: 0.9905 - val_loss: 3.3594 - val_accuracy: 0.5263\n",
            "Epoch 404/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0428 - accuracy: 0.9897 - val_loss: 3.3821 - val_accuracy: 0.5263\n",
            "Epoch 405/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9903 - val_loss: 3.2781 - val_accuracy: 0.5598\n",
            "Epoch 406/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0469 - accuracy: 0.9892 - val_loss: 3.2505 - val_accuracy: 0.5550\n",
            "Epoch 407/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.3276 - accuracy: 0.9242 - val_loss: 3.2645 - val_accuracy: 0.5455\n",
            "Epoch 408/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1888 - accuracy: 0.9577 - val_loss: 3.2240 - val_accuracy: 0.5455\n",
            "Epoch 409/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1045 - accuracy: 0.9756 - val_loss: 3.2457 - val_accuracy: 0.5598\n",
            "Epoch 410/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0530 - accuracy: 0.9888 - val_loss: 3.2792 - val_accuracy: 0.5502\n",
            "Epoch 411/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 3.2008 - val_accuracy: 0.5455\n",
            "Epoch 412/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9943 - val_loss: 3.2805 - val_accuracy: 0.5407\n",
            "Epoch 413/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0624 - accuracy: 0.9753 - val_loss: 3.4197 - val_accuracy: 0.5167\n",
            "Epoch 414/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0357 - accuracy: 0.9901 - val_loss: 3.2958 - val_accuracy: 0.5407\n",
            "Epoch 415/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0540 - accuracy: 0.9870 - val_loss: 3.3312 - val_accuracy: 0.5455\n",
            "Epoch 416/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0310 - accuracy: 0.9952 - val_loss: 3.3430 - val_accuracy: 0.5502\n",
            "Epoch 417/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 3.3483 - val_accuracy: 0.5502\n",
            "Epoch 418/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9959 - val_loss: 3.3533 - val_accuracy: 0.5455\n",
            "Epoch 419/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 3.3867 - val_accuracy: 0.5407\n",
            "Epoch 420/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 3.4080 - val_accuracy: 0.5455\n",
            "Epoch 421/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 3.4057 - val_accuracy: 0.5502\n",
            "Epoch 422/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0243 - accuracy: 0.9949 - val_loss: 3.4050 - val_accuracy: 0.5502\n",
            "Epoch 423/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9959 - val_loss: 3.4187 - val_accuracy: 0.5455\n",
            "Epoch 424/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.9982 - val_loss: 3.4297 - val_accuracy: 0.5502\n",
            "Epoch 425/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0294 - accuracy: 0.9935 - val_loss: 3.4479 - val_accuracy: 0.5502\n",
            "Epoch 426/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0286 - accuracy: 0.9943 - val_loss: 3.4709 - val_accuracy: 0.5502\n",
            "Epoch 427/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0240 - accuracy: 0.9967 - val_loss: 3.4671 - val_accuracy: 0.5502\n",
            "Epoch 428/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 3.4652 - val_accuracy: 0.5502\n",
            "Epoch 429/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 3.4870 - val_accuracy: 0.5502\n",
            "Epoch 430/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 0.9969 - val_loss: 3.4904 - val_accuracy: 0.5550\n",
            "Epoch 431/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 0.9935 - val_loss: 3.5282 - val_accuracy: 0.5550\n",
            "Epoch 432/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 3.5437 - val_accuracy: 0.5502\n",
            "Epoch 433/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 3.5502 - val_accuracy: 0.5455\n",
            "Epoch 434/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 3.5459 - val_accuracy: 0.5455\n",
            "Epoch 435/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0241 - accuracy: 0.9989 - val_loss: 3.5492 - val_accuracy: 0.5407\n",
            "Epoch 436/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9972 - val_loss: 3.5634 - val_accuracy: 0.5455\n",
            "Epoch 437/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 3.5556 - val_accuracy: 0.5455\n",
            "Epoch 438/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0226 - accuracy: 0.9975 - val_loss: 3.5975 - val_accuracy: 0.5455\n",
            "Epoch 439/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 3.6129 - val_accuracy: 0.5407\n",
            "Epoch 440/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9984 - val_loss: 3.6247 - val_accuracy: 0.5455\n",
            "Epoch 441/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 3.6144 - val_accuracy: 0.5455\n",
            "Epoch 442/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 3.6617 - val_accuracy: 0.5407\n",
            "Epoch 443/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 3.6705 - val_accuracy: 0.5359\n",
            "Epoch 444/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 3.6259 - val_accuracy: 0.5407\n",
            "Epoch 445/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9981 - val_loss: 3.6749 - val_accuracy: 0.5359\n",
            "Epoch 446/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 3.6864 - val_accuracy: 0.5359\n",
            "Epoch 447/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 0.9996 - val_loss: 3.6981 - val_accuracy: 0.5359\n",
            "Epoch 448/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 0.9962 - val_loss: 3.6503 - val_accuracy: 0.5455\n",
            "Epoch 449/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9980 - val_loss: 3.7232 - val_accuracy: 0.5407\n",
            "Epoch 450/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1024 - accuracy: 0.9675 - val_loss: 3.4212 - val_accuracy: 0.5742\n",
            "Epoch 451/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0974 - accuracy: 0.9719 - val_loss: 3.3905 - val_accuracy: 0.5502\n",
            "Epoch 452/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0854 - accuracy: 0.9715 - val_loss: 3.4795 - val_accuracy: 0.5407\n",
            "Epoch 453/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0801 - accuracy: 0.9846 - val_loss: 3.5484 - val_accuracy: 0.5311\n",
            "Epoch 454/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.9864 - val_loss: 3.5546 - val_accuracy: 0.5263\n",
            "Epoch 455/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0426 - accuracy: 0.9917 - val_loss: 3.5550 - val_accuracy: 0.5263\n",
            "Epoch 456/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9945 - val_loss: 3.6068 - val_accuracy: 0.5311\n",
            "Epoch 457/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0256 - accuracy: 0.9960 - val_loss: 3.5980 - val_accuracy: 0.5407\n",
            "Epoch 458/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9943 - val_loss: 3.6575 - val_accuracy: 0.5407\n",
            "Epoch 459/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0242 - accuracy: 0.9956 - val_loss: 3.6766 - val_accuracy: 0.5407\n",
            "Epoch 460/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9945 - val_loss: 3.7212 - val_accuracy: 0.5311\n",
            "Epoch 461/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 3.7187 - val_accuracy: 0.5311\n",
            "Epoch 462/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9983 - val_loss: 3.7471 - val_accuracy: 0.5215\n",
            "Epoch 463/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 3.7695 - val_accuracy: 0.5311\n",
            "Epoch 464/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 3.7986 - val_accuracy: 0.5359\n",
            "Epoch 465/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0209 - accuracy: 0.9983 - val_loss: 3.8212 - val_accuracy: 0.5311\n",
            "Epoch 466/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 3.8030 - val_accuracy: 0.5311\n",
            "Epoch 467/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 3.8265 - val_accuracy: 0.5359\n",
            "Epoch 468/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9998 - val_loss: 3.8608 - val_accuracy: 0.5263\n",
            "Epoch 469/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 3.8723 - val_accuracy: 0.5311\n",
            "Epoch 470/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 3.8052 - val_accuracy: 0.5311\n",
            "Epoch 471/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 0.9976 - val_loss: 3.9442 - val_accuracy: 0.5215\n",
            "Epoch 472/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 3.8213 - val_accuracy: 0.5311\n",
            "Epoch 473/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 3.8628 - val_accuracy: 0.5263\n",
            "Epoch 474/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0344 - accuracy: 0.9930 - val_loss: 3.8489 - val_accuracy: 0.5359\n",
            "Epoch 475/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 3.9112 - val_accuracy: 0.5359\n",
            "Epoch 476/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9970 - val_loss: 3.8767 - val_accuracy: 0.5263\n",
            "Epoch 477/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1642 - accuracy: 0.9612 - val_loss: 3.8303 - val_accuracy: 0.5359\n",
            "Epoch 478/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1449 - accuracy: 0.9611 - val_loss: 3.5740 - val_accuracy: 0.5359\n",
            "Epoch 479/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1092 - accuracy: 0.9680 - val_loss: 3.4342 - val_accuracy: 0.5311\n",
            "Epoch 480/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 0.9672 - val_loss: 3.4885 - val_accuracy: 0.5359\n",
            "Epoch 481/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0763 - accuracy: 0.9712 - val_loss: 3.7087 - val_accuracy: 0.5263\n",
            "Epoch 482/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 3.6963 - val_accuracy: 0.5263\n",
            "Epoch 483/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0221 - accuracy: 0.9975 - val_loss: 3.6535 - val_accuracy: 0.5455\n",
            "Epoch 484/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 3.6983 - val_accuracy: 0.5359\n",
            "Epoch 485/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 3.7261 - val_accuracy: 0.5407\n",
            "Epoch 486/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 3.7444 - val_accuracy: 0.5407\n",
            "Epoch 487/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 3.7810 - val_accuracy: 0.5359\n",
            "Epoch 488/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9979 - val_loss: 3.7650 - val_accuracy: 0.5407\n",
            "Epoch 489/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 3.7919 - val_accuracy: 0.5311\n",
            "Epoch 490/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9984 - val_loss: 3.8083 - val_accuracy: 0.5359\n",
            "Epoch 491/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9997 - val_loss: 3.8067 - val_accuracy: 0.5407\n",
            "Epoch 492/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 3.8192 - val_accuracy: 0.5311\n",
            "Epoch 493/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 3.8437 - val_accuracy: 0.5311\n",
            "Epoch 494/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9978 - val_loss: 3.8868 - val_accuracy: 0.5263\n",
            "Epoch 495/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 3.8818 - val_accuracy: 0.5311\n",
            "Epoch 496/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 3.8836 - val_accuracy: 0.5359\n",
            "Epoch 497/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 0.9996 - val_loss: 3.9042 - val_accuracy: 0.5359\n",
            "Epoch 498/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 3.9548 - val_accuracy: 0.5215\n",
            "Epoch 499/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 3.9321 - val_accuracy: 0.5359\n",
            "Epoch 500/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 3.9550 - val_accuracy: 0.5359\n",
            "Epoch 501/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 3.9825 - val_accuracy: 0.5263\n",
            "Epoch 502/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 3.9704 - val_accuracy: 0.5455\n",
            "Epoch 503/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 3.9897 - val_accuracy: 0.5263\n",
            "Epoch 504/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9999 - val_loss: 3.9665 - val_accuracy: 0.5455\n",
            "Epoch 505/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 4.0402 - val_accuracy: 0.5215\n",
            "Epoch 506/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 3.9874 - val_accuracy: 0.5263\n",
            "Epoch 507/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 4.0050 - val_accuracy: 0.5311\n",
            "Epoch 508/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 4.0363 - val_accuracy: 0.5359\n",
            "Epoch 509/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 4.0327 - val_accuracy: 0.5311\n",
            "Epoch 510/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.9998 - val_loss: 4.0466 - val_accuracy: 0.5311\n",
            "Epoch 511/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 4.1015 - val_accuracy: 0.5311\n",
            "Epoch 512/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 4.1143 - val_accuracy: 0.5359\n",
            "Epoch 513/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 4.1265 - val_accuracy: 0.5311\n",
            "Epoch 514/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 4.1426 - val_accuracy: 0.5263\n",
            "Epoch 515/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.1653 - val_accuracy: 0.5263\n",
            "Epoch 516/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 4.1851 - val_accuracy: 0.5263\n",
            "Epoch 517/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 4.1759 - val_accuracy: 0.5263\n",
            "Epoch 518/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 4.1387 - val_accuracy: 0.5311\n",
            "Epoch 519/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.9996 - val_loss: 4.1961 - val_accuracy: 0.5311\n",
            "Epoch 520/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 4.2154 - val_accuracy: 0.5311\n",
            "Epoch 521/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 4.2270 - val_accuracy: 0.5311\n",
            "Epoch 522/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 4.2072 - val_accuracy: 0.5359\n",
            "Epoch 523/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9996 - val_loss: 4.2655 - val_accuracy: 0.5263\n",
            "Epoch 524/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.0818 - val_accuracy: 0.5502\n",
            "Epoch 525/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 0.9928 - val_loss: 4.1835 - val_accuracy: 0.5359\n",
            "Epoch 526/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 4.1352 - val_accuracy: 0.5407\n",
            "Epoch 527/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 4.0441 - val_accuracy: 0.5455\n",
            "Epoch 528/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 4.2573 - val_accuracy: 0.5311\n",
            "Epoch 529/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0986 - accuracy: 0.9811 - val_loss: 4.3680 - val_accuracy: 0.5263\n",
            "Epoch 530/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3354 - accuracy: 0.9334 - val_loss: 3.9148 - val_accuracy: 0.5072\n",
            "Epoch 531/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.2804 - accuracy: 0.9171 - val_loss: 3.4037 - val_accuracy: 0.5455\n",
            "Epoch 532/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1662 - accuracy: 0.9564 - val_loss: 3.4443 - val_accuracy: 0.5407\n",
            "Epoch 533/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0917 - accuracy: 0.9735 - val_loss: 3.4637 - val_accuracy: 0.5167\n",
            "Epoch 534/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0508 - accuracy: 0.9935 - val_loss: 3.4134 - val_accuracy: 0.5455\n",
            "Epoch 535/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0330 - accuracy: 0.9828 - val_loss: 3.4866 - val_accuracy: 0.5311\n",
            "Epoch 536/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9996 - val_loss: 3.5327 - val_accuracy: 0.5407\n",
            "Epoch 537/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 3.5726 - val_accuracy: 0.5215\n",
            "Epoch 538/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9990 - val_loss: 3.5858 - val_accuracy: 0.5311\n",
            "Epoch 539/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9996 - val_loss: 3.5997 - val_accuracy: 0.5359\n",
            "Epoch 540/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9999 - val_loss: 3.5849 - val_accuracy: 0.5455\n",
            "Epoch 541/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 3.6176 - val_accuracy: 0.5455\n",
            "Epoch 542/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 3.6229 - val_accuracy: 0.5407\n",
            "Epoch 543/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 3.6921 - val_accuracy: 0.5167\n",
            "Epoch 544/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 3.6785 - val_accuracy: 0.5455\n",
            "Epoch 545/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 3.7137 - val_accuracy: 0.5359\n",
            "Epoch 546/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9998 - val_loss: 3.7096 - val_accuracy: 0.5455\n",
            "Epoch 547/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 3.7273 - val_accuracy: 0.5455\n",
            "Epoch 548/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.7596 - val_accuracy: 0.5359\n",
            "Epoch 549/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 3.7851 - val_accuracy: 0.5167\n",
            "Epoch 550/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 3.7181 - val_accuracy: 0.5407\n",
            "Epoch 551/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 3.8891 - val_accuracy: 0.5024\n",
            "Epoch 552/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 0.9950 - val_loss: 3.8312 - val_accuracy: 0.5359\n",
            "Epoch 553/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.8299 - val_accuracy: 0.5359\n",
            "Epoch 554/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.8807 - val_accuracy: 0.5263\n",
            "Epoch 555/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.8688 - val_accuracy: 0.5359\n",
            "Epoch 556/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.8653 - val_accuracy: 0.5311\n",
            "Epoch 557/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 3.9048 - val_accuracy: 0.5263\n",
            "Epoch 558/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 3.8347 - val_accuracy: 0.5502\n",
            "Epoch 559/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.9175 - val_accuracy: 0.5311\n",
            "Epoch 560/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.9162 - val_accuracy: 0.5359\n",
            "Epoch 561/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 3.9400 - val_accuracy: 0.5311\n",
            "Epoch 562/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 3.9431 - val_accuracy: 0.5502\n",
            "Epoch 563/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.9720 - val_accuracy: 0.5407\n",
            "Epoch 564/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.9843 - val_accuracy: 0.5455\n",
            "Epoch 565/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.0217 - val_accuracy: 0.5359\n",
            "Epoch 566/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.9971 - val_accuracy: 0.5359\n",
            "Epoch 567/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.0465 - val_accuracy: 0.5311\n",
            "Epoch 568/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 4.0725 - val_accuracy: 0.5359\n",
            "Epoch 569/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.1029 - val_accuracy: 0.5311\n",
            "Epoch 570/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 4.0794 - val_accuracy: 0.5311\n",
            "Epoch 571/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.0691 - val_accuracy: 0.5359\n",
            "Epoch 572/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.0965 - val_accuracy: 0.5311\n",
            "Epoch 573/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 4.0760 - val_accuracy: 0.5311\n",
            "Epoch 574/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.0905 - val_accuracy: 0.5455\n",
            "Epoch 575/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 4.1073 - val_accuracy: 0.5311\n",
            "Epoch 576/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.1166 - val_accuracy: 0.5455\n",
            "Epoch 577/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 4.1381 - val_accuracy: 0.5359\n",
            "Epoch 578/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 4.1458 - val_accuracy: 0.5359\n",
            "Epoch 579/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 4.1941 - val_accuracy: 0.5120\n",
            "Epoch 580/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.1924 - val_accuracy: 0.5359\n",
            "Epoch 581/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.9949 - val_loss: 4.1818 - val_accuracy: 0.5311\n",
            "Epoch 582/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.2452 - val_accuracy: 0.5215\n",
            "Epoch 583/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 4.1801 - val_accuracy: 0.5359\n",
            "Epoch 584/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.2544 - val_accuracy: 0.5263\n",
            "Epoch 585/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.2881 - val_accuracy: 0.5263\n",
            "Epoch 586/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.2769 - val_accuracy: 0.5311\n",
            "Epoch 587/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.3011 - val_accuracy: 0.5263\n",
            "Epoch 588/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.3123 - val_accuracy: 0.5120\n",
            "Epoch 589/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.3277 - val_accuracy: 0.5167\n",
            "Epoch 590/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 4.3078 - val_accuracy: 0.5311\n",
            "Epoch 591/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.3125 - val_accuracy: 0.5311\n",
            "Epoch 592/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 4.3402 - val_accuracy: 0.5263\n",
            "Epoch 593/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.3379 - val_accuracy: 0.5311\n",
            "Epoch 594/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.3810 - val_accuracy: 0.5215\n",
            "Epoch 595/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.3961 - val_accuracy: 0.5215\n",
            "Epoch 596/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 4.3987 - val_accuracy: 0.5263\n",
            "Epoch 597/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 4.4356 - val_accuracy: 0.5215\n",
            "Epoch 598/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 4.3766 - val_accuracy: 0.5359\n",
            "Epoch 599/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 4.4114 - val_accuracy: 0.5167\n",
            "Epoch 600/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1501 - accuracy: 0.9665 - val_loss: 4.1000 - val_accuracy: 0.5263\n",
            "Epoch 601/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0648 - accuracy: 0.9742 - val_loss: 4.3091 - val_accuracy: 0.4880\n",
            "Epoch 602/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0879 - accuracy: 0.9725 - val_loss: 3.9551 - val_accuracy: 0.5263\n",
            "Epoch 603/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1000 - accuracy: 0.9646 - val_loss: 3.9538 - val_accuracy: 0.5167\n",
            "Epoch 604/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0292 - accuracy: 0.9929 - val_loss: 4.1680 - val_accuracy: 0.4880\n",
            "Epoch 605/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9700 - val_loss: 3.9040 - val_accuracy: 0.5120\n",
            "Epoch 606/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 0.9945 - val_loss: 3.9066 - val_accuracy: 0.5550\n",
            "Epoch 607/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 3.8406 - val_accuracy: 0.5598\n",
            "Epoch 608/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 3.9197 - val_accuracy: 0.5407\n",
            "Epoch 609/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.9996 - val_loss: 3.9325 - val_accuracy: 0.5502\n",
            "Epoch 610/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.9571 - val_accuracy: 0.5502\n",
            "Epoch 611/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 3.9810 - val_accuracy: 0.5550\n",
            "Epoch 612/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 3.9721 - val_accuracy: 0.5550\n",
            "Epoch 613/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.9869 - val_accuracy: 0.5502\n",
            "Epoch 614/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 3.9930 - val_accuracy: 0.5598\n",
            "Epoch 615/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.0221 - val_accuracy: 0.5455\n",
            "Epoch 616/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.0172 - val_accuracy: 0.5598\n",
            "Epoch 617/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.0403 - val_accuracy: 0.5694\n",
            "Epoch 618/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 0.9967 - val_loss: 4.0753 - val_accuracy: 0.5598\n",
            "Epoch 619/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 4.0757 - val_accuracy: 0.5646\n",
            "Epoch 620/800\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.0938 - val_accuracy: 0.5598\n",
            "Epoch 621/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 4.1047 - val_accuracy: 0.5598\n",
            "Epoch 622/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.1324 - val_accuracy: 0.5550\n",
            "Epoch 623/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.1309 - val_accuracy: 0.5550\n",
            "Epoch 624/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.1464 - val_accuracy: 0.5550\n",
            "Epoch 625/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.1723 - val_accuracy: 0.5598\n",
            "Epoch 626/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 4.1828 - val_accuracy: 0.5550\n",
            "Epoch 627/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 4.1676 - val_accuracy: 0.5502\n",
            "Epoch 628/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.1807 - val_accuracy: 0.5550\n",
            "Epoch 629/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.2122 - val_accuracy: 0.5455\n",
            "Epoch 630/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.2372 - val_accuracy: 0.5502\n",
            "Epoch 631/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 4.2425 - val_accuracy: 0.5502\n",
            "Epoch 632/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.2793 - val_accuracy: 0.5359\n",
            "Epoch 633/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.2685 - val_accuracy: 0.5550\n",
            "Epoch 634/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.2702 - val_accuracy: 0.5455\n",
            "Epoch 635/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.3049 - val_accuracy: 0.5359\n",
            "Epoch 636/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.3138 - val_accuracy: 0.5502\n",
            "Epoch 637/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.3073 - val_accuracy: 0.5455\n",
            "Epoch 638/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 4.3323 - val_accuracy: 0.5359\n",
            "Epoch 639/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.3208 - val_accuracy: 0.5502\n",
            "Epoch 640/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.3851 - val_accuracy: 0.5455\n",
            "Epoch 641/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.3952 - val_accuracy: 0.5502\n",
            "Epoch 642/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 4.4109 - val_accuracy: 0.5550\n",
            "Epoch 643/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.3740 - val_accuracy: 0.5502\n",
            "Epoch 644/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 4.3887 - val_accuracy: 0.5502\n",
            "Epoch 645/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.3985 - val_accuracy: 0.5502\n",
            "Epoch 646/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.4088 - val_accuracy: 0.5502\n",
            "Epoch 647/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.4137 - val_accuracy: 0.5455\n",
            "Epoch 648/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.4276 - val_accuracy: 0.5502\n",
            "Epoch 649/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 4.4685 - val_accuracy: 0.5502\n",
            "Epoch 650/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.4678 - val_accuracy: 0.5455\n",
            "Epoch 651/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.4778 - val_accuracy: 0.5502\n",
            "Epoch 652/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.4963 - val_accuracy: 0.5550\n",
            "Epoch 653/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.4915 - val_accuracy: 0.5455\n",
            "Epoch 654/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.5184 - val_accuracy: 0.5502\n",
            "Epoch 655/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.4963 - val_accuracy: 0.5502\n",
            "Epoch 656/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.5176 - val_accuracy: 0.5455\n",
            "Epoch 657/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5126 - val_accuracy: 0.5455\n",
            "Epoch 658/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.5612 - val_accuracy: 0.5407\n",
            "Epoch 659/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.5720 - val_accuracy: 0.5598\n",
            "Epoch 660/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.6008 - val_accuracy: 0.5407\n",
            "Epoch 661/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.6144 - val_accuracy: 0.5455\n",
            "Epoch 662/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.6049 - val_accuracy: 0.5455\n",
            "Epoch 663/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.6294 - val_accuracy: 0.5502\n",
            "Epoch 664/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6451 - val_accuracy: 0.5407\n",
            "Epoch 665/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.6576 - val_accuracy: 0.5407\n",
            "Epoch 666/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.6597 - val_accuracy: 0.5502\n",
            "Epoch 667/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.6688 - val_accuracy: 0.5359\n",
            "Epoch 668/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.6896 - val_accuracy: 0.5407\n",
            "Epoch 669/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.7008 - val_accuracy: 0.5407\n",
            "Epoch 670/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.6981 - val_accuracy: 0.5502\n",
            "Epoch 671/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.7089 - val_accuracy: 0.5455\n",
            "Epoch 672/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.7223 - val_accuracy: 0.5455\n",
            "Epoch 673/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.7458 - val_accuracy: 0.5550\n",
            "Epoch 674/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.7402 - val_accuracy: 0.5455\n",
            "Epoch 675/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 4.7542 - val_accuracy: 0.5311\n",
            "Epoch 676/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.7379 - val_accuracy: 0.5359\n",
            "Epoch 677/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.7451 - val_accuracy: 0.5407\n",
            "Epoch 678/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.7716 - val_accuracy: 0.5598\n",
            "Epoch 679/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.8034 - val_accuracy: 0.5455\n",
            "Epoch 680/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.8245 - val_accuracy: 0.5455\n",
            "Epoch 681/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.8326 - val_accuracy: 0.5455\n",
            "Epoch 682/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.8651 - val_accuracy: 0.5407\n",
            "Epoch 683/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 4.7530 - val_accuracy: 0.5502\n",
            "Epoch 684/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 5.3441 - val_accuracy: 0.4689\n",
            "Epoch 685/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5890 - accuracy: 0.8915 - val_loss: 3.8563 - val_accuracy: 0.5455\n",
            "Epoch 686/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.3089 - accuracy: 0.9280 - val_loss: 4.1336 - val_accuracy: 0.5311\n",
            "Epoch 687/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1416 - accuracy: 0.9676 - val_loss: 4.1369 - val_accuracy: 0.4976\n",
            "Epoch 688/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0940 - accuracy: 0.9738 - val_loss: 4.0302 - val_accuracy: 0.5024\n",
            "Epoch 689/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9849 - val_loss: 4.2619 - val_accuracy: 0.5120\n",
            "Epoch 690/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9918 - val_loss: 3.8418 - val_accuracy: 0.5407\n",
            "Epoch 691/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0146 - accuracy: 0.9991 - val_loss: 3.8093 - val_accuracy: 0.5550\n",
            "Epoch 692/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 3.9553 - val_accuracy: 0.5215\n",
            "Epoch 693/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 3.9521 - val_accuracy: 0.5263\n",
            "Epoch 694/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 3.9358 - val_accuracy: 0.5359\n",
            "Epoch 695/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.9591 - val_accuracy: 0.5359\n",
            "Epoch 696/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.9940 - val_accuracy: 0.5359\n",
            "Epoch 697/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.0067 - val_accuracy: 0.5407\n",
            "Epoch 698/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.0120 - val_accuracy: 0.5455\n",
            "Epoch 699/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.0324 - val_accuracy: 0.5455\n",
            "Epoch 700/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.0282 - val_accuracy: 0.5407\n",
            "Epoch 701/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.0753 - val_accuracy: 0.5359\n",
            "Epoch 702/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.0892 - val_accuracy: 0.5311\n",
            "Epoch 703/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.1000 - val_accuracy: 0.5311\n",
            "Epoch 704/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.1120 - val_accuracy: 0.5407\n",
            "Epoch 705/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.1296 - val_accuracy: 0.5359\n",
            "Epoch 706/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 4.0981 - val_accuracy: 0.5359\n",
            "Epoch 707/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1173 - val_accuracy: 0.5263\n",
            "Epoch 708/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.1953 - val_accuracy: 0.5263\n",
            "Epoch 709/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.1934 - val_accuracy: 0.5263\n",
            "Epoch 710/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.2189 - val_accuracy: 0.5263\n",
            "Epoch 711/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.2353 - val_accuracy: 0.5311\n",
            "Epoch 712/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1958 - val_accuracy: 0.5263\n",
            "Epoch 713/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.2201 - val_accuracy: 0.5311\n",
            "Epoch 714/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.2522 - val_accuracy: 0.5263\n",
            "Epoch 715/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.2311 - val_accuracy: 0.5215\n",
            "Epoch 716/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.2513 - val_accuracy: 0.5263\n",
            "Epoch 717/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.2801 - val_accuracy: 0.5263\n",
            "Epoch 718/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9956 - val_loss: 4.3194 - val_accuracy: 0.5311\n",
            "Epoch 719/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.3179 - val_accuracy: 0.5167\n",
            "Epoch 720/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.3384 - val_accuracy: 0.5215\n",
            "Epoch 721/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.3499 - val_accuracy: 0.5215\n",
            "Epoch 722/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.3662 - val_accuracy: 0.5215\n",
            "Epoch 723/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.3733 - val_accuracy: 0.5263\n",
            "Epoch 724/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 0.9967 - val_loss: 4.3767 - val_accuracy: 0.5215\n",
            "Epoch 725/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.3950 - val_accuracy: 0.5263\n",
            "Epoch 726/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.3715 - val_accuracy: 0.5263\n",
            "Epoch 727/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.4055 - val_accuracy: 0.5311\n",
            "Epoch 728/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.3907 - val_accuracy: 0.5311\n",
            "Epoch 729/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.4145 - val_accuracy: 0.5311\n",
            "Epoch 730/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.4382 - val_accuracy: 0.5311\n",
            "Epoch 731/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.4430 - val_accuracy: 0.5311\n",
            "Epoch 732/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.4402 - val_accuracy: 0.5263\n",
            "Epoch 733/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.4536 - val_accuracy: 0.5359\n",
            "Epoch 734/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.4687 - val_accuracy: 0.5311\n",
            "Epoch 735/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.4663 - val_accuracy: 0.5359\n",
            "Epoch 736/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.4695 - val_accuracy: 0.5407\n",
            "Epoch 737/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.4717 - val_accuracy: 0.5359\n",
            "Epoch 738/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.4824 - val_accuracy: 0.5311\n",
            "Epoch 739/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.4923 - val_accuracy: 0.5359\n",
            "Epoch 740/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.5264 - val_accuracy: 0.5311\n",
            "Epoch 741/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.5426 - val_accuracy: 0.5311\n",
            "Epoch 742/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.5831 - val_accuracy: 0.5311\n",
            "Epoch 743/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.5846 - val_accuracy: 0.5311\n",
            "Epoch 744/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.5838 - val_accuracy: 0.5311\n",
            "Epoch 745/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.6158 - val_accuracy: 0.5311\n",
            "Epoch 746/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.6512 - val_accuracy: 0.5359\n",
            "Epoch 747/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6326 - val_accuracy: 0.5311\n",
            "Epoch 748/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.6371 - val_accuracy: 0.5311\n",
            "Epoch 749/800\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.6434 - val_accuracy: 0.5311\n",
            "Epoch 750/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.6874 - val_accuracy: 0.5311\n",
            "Epoch 751/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.7075 - val_accuracy: 0.5311\n",
            "Epoch 752/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7186 - val_accuracy: 0.5263\n",
            "Epoch 753/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.6810 - val_accuracy: 0.5263\n",
            "Epoch 754/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.6851 - val_accuracy: 0.5215\n",
            "Epoch 755/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.6766 - val_accuracy: 0.5311\n",
            "Epoch 756/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.7052 - val_accuracy: 0.5215\n",
            "Epoch 757/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 4.7380 - val_accuracy: 0.5263\n",
            "Epoch 758/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7239 - val_accuracy: 0.5311\n",
            "Epoch 759/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.7078 - val_accuracy: 0.5359\n",
            "Epoch 760/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7285 - val_accuracy: 0.5359\n",
            "Epoch 761/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.7432 - val_accuracy: 0.5359\n",
            "Epoch 762/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7591 - val_accuracy: 0.5311\n",
            "Epoch 763/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.7714 - val_accuracy: 0.5359\n",
            "Epoch 764/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7653 - val_accuracy: 0.5311\n",
            "Epoch 765/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.8084 - val_accuracy: 0.5263\n",
            "Epoch 766/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.7920 - val_accuracy: 0.5311\n",
            "Epoch 767/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7896 - val_accuracy: 0.5359\n",
            "Epoch 768/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7975 - val_accuracy: 0.5311\n",
            "Epoch 769/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7881 - val_accuracy: 0.5407\n",
            "Epoch 770/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.7883 - val_accuracy: 0.5359\n",
            "Epoch 771/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.8354 - val_accuracy: 0.5263\n",
            "Epoch 772/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.8406 - val_accuracy: 0.5311\n",
            "Epoch 773/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 9.2274e-04 - accuracy: 1.0000 - val_loss: 4.8464 - val_accuracy: 0.5311\n",
            "Epoch 774/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.8949 - val_accuracy: 0.5311\n",
            "Epoch 775/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.8828 - val_accuracy: 0.5311\n",
            "Epoch 776/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.9686 - val_accuracy: 0.5359\n",
            "Epoch 777/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 4.4937 - val_accuracy: 0.5407\n",
            "Epoch 778/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1753 - accuracy: 0.9738 - val_loss: 4.3049 - val_accuracy: 0.5550\n",
            "Epoch 779/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.2064 - accuracy: 0.9470 - val_loss: 4.1990 - val_accuracy: 0.5024\n",
            "Epoch 780/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.1673 - accuracy: 0.9657 - val_loss: 4.0566 - val_accuracy: 0.5167\n",
            "Epoch 781/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.1047 - accuracy: 0.9705 - val_loss: 4.0463 - val_accuracy: 0.5455\n",
            "Epoch 782/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.1086 - accuracy: 0.9782 - val_loss: 4.0961 - val_accuracy: 0.5359\n",
            "Epoch 783/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0460 - accuracy: 0.9885 - val_loss: 3.9170 - val_accuracy: 0.5598\n",
            "Epoch 784/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.9976 - val_loss: 4.0857 - val_accuracy: 0.5502\n",
            "Epoch 785/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 3.9424 - val_accuracy: 0.5598\n",
            "Epoch 786/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 4.0235 - val_accuracy: 0.5598\n",
            "Epoch 787/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.0060 - val_accuracy: 0.5550\n",
            "Epoch 788/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 4.1106 - val_accuracy: 0.5550\n",
            "Epoch 789/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.1118 - val_accuracy: 0.5550\n",
            "Epoch 790/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.1225 - val_accuracy: 0.5550\n",
            "Epoch 791/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.1529 - val_accuracy: 0.5502\n",
            "Epoch 792/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 4.1879 - val_accuracy: 0.5263\n",
            "Epoch 793/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 4.1751 - val_accuracy: 0.5455\n",
            "Epoch 794/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.2101 - val_accuracy: 0.5311\n",
            "Epoch 795/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 4.2403 - val_accuracy: 0.5311\n",
            "Epoch 796/800\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.2369 - val_accuracy: 0.5550\n",
            "Epoch 797/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.2384 - val_accuracy: 0.5502\n",
            "Epoch 798/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.2273 - val_accuracy: 0.5455\n",
            "Epoch 799/800\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.2231 - val_accuracy: 0.5359\n",
            "Epoch 800/800\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.2527 - val_accuracy: 0.5455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11/11 - 0s - loss: 4.1275 - accuracy: 0.5661\n",
            "\n",
            "Test accuracy: 0.5660919547080994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mgTy_B1gAYb"
      },
      "source": [
        "model.save('raga_identification.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYWGo2pQ8LAx",
        "outputId": "dc45959a-6bf8-4ef2-c8d2-baaa6318884d"
      },
      "source": [
        "model.save('my_model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xFgmy7X8W-Z",
        "outputId": "45690971-5bb7-47be-a51c-78a6ae830ce3"
      },
      "source": [
        "!zip -r /content/file.zip /content/my_model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/my_model/ (stored 0%)\n",
            "  adding: content/my_model/saved_model.pb (deflated 89%)\n",
            "  adding: content/my_model/variables/ (stored 0%)\n",
            "  adding: content/my_model/variables/variables.index (deflated 66%)\n",
            "  adding: content/my_model/variables/variables.data-00000-of-00001 (deflated 6%)\n",
            "  adding: content/my_model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iA2Z0YJPe76"
      },
      "source": [
        "# !gdown --id 1OwgxRgeH2sqVB4-szobd16ClItJtyFo2\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/RagaDatasetNew.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/processed')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9v6nZOcPfT"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "\n",
        "DATASET_PATH = \"/content/processed/RagaDatasetNew/Bhairavi/Ajoy Chakrabarty - Bhajan.mp3\"\n",
        "JSON_PATH = \"data_10.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
        "\n",
        "        :param dataset_path (str): Path to dataset\n",
        "        :param json_path (str): Path to json file used to save MFCCs\n",
        "        :param num_mfcc (int): Number of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    data = {\n",
        "        # \"mapping\": [],\n",
        "        # \"labels\": [],\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    signal, sample_rate = librosa.load(dataset_path, sr=SAMPLE_RATE)\n",
        "    \n",
        "    for d in range(num_segments):\n",
        "      print(d)\n",
        "      start = samples_per_segment * d\n",
        "      finish = start + samples_per_segment\n",
        "      mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "      mfcc = mfcc.T\n",
        "      \n",
        "      if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "        data[\"mfcc\"].append(mfcc.tolist())\n",
        "        print(\"{}, segment:{}\".format(dataset_path, d+1))\n",
        "        \n",
        "    with open(json_path, \"w\") as fp:\n",
        "      json.dump(data, fp, indent=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE6e8y9bXDNk",
        "outputId": "87fdfff3-2639-4194-b9a7-a07378201b79"
      },
      "source": [
        "!rm -rf /content/testdata.json\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import keras\n",
        "TESTDATA_PATH = \"/content/Ajoy Chakrabarty - Aahir Bhairon.mp3\"\n",
        "y, sr = librosa.load(TESTDATA_PATH)\n",
        "mfcc = librosa.feature.mfcc(y=y, sr=22050, hop_length=512, n_mfcc=13)\n",
        "mfcc=mfcc.T\n",
        "\n",
        "data = {\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "data[\"mfcc\"].append(mfcc.tolist())\n",
        "\n",
        "X = np.array(data[\"mfcc\"])\n",
        "\n",
        "model = keras.models.load_model('raga_identification.h5')\n",
        "\n",
        "predictions = model.predict(X)\n",
        "class_names[np.argmax(predictions)]\n",
        "# print(X.shape)\n",
        "# model.predict_classes(X)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130, 13), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 25360, 13).\n",
            "(1, 25360, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgAviFEgfxrF",
        "outputId": "111f10a3-bbbd-4c09-cf5b-89342ed0b041"
      },
      "source": [
        "\n",
        "print(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-5.12386658e+02  3.05591404e-01  2.38366023e-01 ... -2.59462535e-01\n",
            "   -1.65725410e-01 -4.82922494e-02]\n",
            "  [-5.07997864e+02  5.89659643e+00  4.37191153e+00 ... -3.99493384e+00\n",
            "   -3.79055762e+00 -3.27707338e+00]\n",
            "  [-4.98861664e+02  1.60117874e+01  9.16501427e+00 ... -7.03584194e+00\n",
            "   -9.38699722e+00 -9.84523010e+00]\n",
            "  ...\n",
            "  [-5.12619385e+02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-5.12619385e+02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-5.12619385e+02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "HKMNDVKkYJzn",
        "outputId": "8fe9ac09-f9f7-4796-aee6-eb2201b60c96"
      },
      "source": [
        "import seaborn as sns\n",
        "mfcc_delta = librosa.feature.delta(mfcc)\n",
        "sns.heatmap(mfcc_delta)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efecb6f7290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gQQCL05gpYL",
        "outputId": "0587caea-7e19-4ae9-9d18-b2896e4a3dd0"
      },
      "source": [
        "model = keras.models.load_model('raga_identification.h5')\n",
        "\n",
        "predictions = model.predict(X)\n",
        "print(X.shape)\n",
        "model.predict_classes(X)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130, 13), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 25360, 13).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130, 13), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 25360, 13).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 25360, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UqxnHzJiijbD",
        "outputId": "a39522a0-b008-42b6-929b-cbf33b7eda80"
      },
      "source": [
        "class_names = ['Ahira bhairav', 'Ba╠äge╠äs╠üri╠ä', 'Bhairavi', 'Bila╠äsakha╠äni╠ä to╠äd╠úi╠ä', 'De╠äs╠ü']\n",
        "\n",
        "class_names[np.argmax(predictions)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ba╠äge╠äs╠üri╠ä'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}